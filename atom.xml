<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>He1o</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2022-08-16T00:54:40.195Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>He1o</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>1. EDA</title>
    <link href="http://example.com/2022/08/12/FeatureEngineering/1.ExploratoryDataAnalysis/"/>
    <id>http://example.com/2022/08/12/FeatureEngineering/1.ExploratoryDataAnalysis/</id>
    <published>2022-08-11T16:00:00.000Z</published>
    <updated>2022-08-16T00:54:40.195Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><h1 id="Exploratory-Data-Analysis"><a href="#Exploratory-Data-Analysis" class="headerlink" title="Exploratory Data Analysis"></a>Exploratory Data Analysis</h1><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><p>数据科学家使用探索性数据分析 (Exploratory Data Analysis) 来分析和调查数据集并总结其主要特征，通常采用数据可视化方法。它有助于确定如何最好地操纵数据源以获得所需的答案，从而使数据科学家更容易发现模式、发现异常、检验假设或检查假设。</p><p>EDA 主要用于查看在正式建模或假设检验任务之外可以揭示哪些数据，并提供对数据集变量及其之间关系的更好理解。它还可以帮助确定您正在考虑用于数据分析的统计技术是否合适。</p><p>EDA 技术最初由美国数学家 John Tukey 在 1970 年代开发，在今天的数据发现过程中仍然是一种广泛使用的方法。</p><p>EDA 的主要目的是帮助在做出任何假设之前查看数据。它可以帮助识别明显的错误，更好地理解数据中的模式，检测异常值或异常事件，找到变量之间的有趣关系。</p><p>EDA 是任何数据分析中重要的第一步。了解异常值出现的位置以及变量之间的关系有助于设计能够产生有意义结果的统计分析。</p><p>数据科学家可以使用探索性分析来确保他们产生的结果是有效的并且适用于任何期望的业务成果和目标。EDA 还通过确认他们提出正确的问题来帮助利益相关者。EDA 可以帮助回答有关标准差、分类变量和置信区间的问题。一旦 EDA 完成并得出见解，它的功能就可以用于更复杂的数据分析或建模，包括机器学习。</p><h2 id="2-数据总览"><a href="#2-数据总览" class="headerlink" title="2. 数据总览"></a>2. 数据总览</h2><p>本文实例数据使用 kaggle 的 Spaceship Titanic 数据集。</p><p>训练数据共有如下字段</p><ul><li>PassengerId - A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always.</li><li>HomePlanet - The planet the passenger departed from, typically their planet of permanent residence.</li><li>CryoSleep - Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins.</li><li>Cabin - The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard.</li><li>Destination - The planet the passenger will be debarking to.</li><li>Age - The age of the passenger.</li><li>VIP - Whether the passenger has paid for special VIP service during the voyage.</li><li>RoomService, FoodCourt, ShoppingMall, Spa, VRDeck - Amount the passenger has billed at each of the Spaceship Titanic’s many luxury amenities.</li><li>Name - The first and last names of the passenger.</li><li>Transported - Whether the passenger was transported to another dimension. This is the target, the column you are trying to predict.</li></ul><p>先导入数据</p><pre><code class="lang-python">import pandas as pdtrain_data = pd.read_csv(&#39;Data/train.csv&#39;)test_data = pd.read_csv(&#39;Data/test.csv&#39;)</code></pre><p>获取数据简明摘要，包括索引 dtype 、列名、非空值和内存使用情况。</p><p>可以看出来大部分字段缺失几乎200条数据，同时存在字符和数字型的数据。</p><pre><code class="lang-python">train_data.info()</code></pre><p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/1.png" alt="info"></p><p>生成描述性统计，包括数据集分布的集中趋势、离散度和形状的统计数据，不包括 NaN 的值，即不包括缺失值。</p><p>% 指的是百分位数，50% 即为中位数。</p><p>由于字符型数据还没有数字化，因此只统计了年龄和和各项消费情况，可以看出消费情况的方差非常大，可见贫富差距很明显。</p><pre><code class="lang-python">train_data.describe()</code></pre><p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/2.png" alt="info"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;h1 id=&quot;Exploratory-Data-Analysis&quot;&gt;&lt;a href=&quot;#Exploratory-Data-Analysis&quot; class=&quot;headerlink&quot; title=&quot;Exploratory Data A</summary>
      
    
    
    
    <category term="Feature Engineering" scheme="http://example.com/categories/Feature-Engineering/"/>
    
    
  </entry>
  
  <entry>
    <title>14. RandomForest</title>
    <link href="http://example.com/2022/07/28/MachineLearning/14.RandomForest/"/>
    <id>http://example.com/2022/07/28/MachineLearning/14.RandomForest/</id>
    <published>2022-07-27T16:00:00.000Z</published>
    <updated>2022-07-28T07:05:20.718Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><h1 id="RandomForest"><a href="#RandomForest" class="headerlink" title="RandomForest"></a>RandomForest</h1><h2 id="1-背景概述"><a href="#1-背景概述" class="headerlink" title="1. 背景概述"></a>1. 背景概述</h2><p>1995 年，随机决策森林的一般方法由 Ho 首次提出。 Ho (1998) 写了许多关于“随机子空间”方法的论文，该方法随机选择特征子集以用于生长每棵树。</p><p>1997 年，在一篇关于书面字符识别的重要论文中，Amit 和 Geman 定义了大量的几何特征，并在这些几何特征的随机选择中搜索每个节点的最佳分割</p><p>2001 年，Leo Breiman 在一篇论文中对随机森林进行了适当的介绍。本文描述了一种使用类似 CART 的程序，结合随机节点优化和装袋来构建不相关树森林的方法。此外，本文结合了几种成分，一些是以前已知的，一些是新的，它们构成了随机森林现代实践的基础，特别是：使用袋外误差作为泛化误差的估计。通过排列测量变量的重要性。该报告还提供了随机森林的第一个理论结果，其为泛化误差的界限，这取决于森林中树木的强度及其相关性。</p><h2 id="2-Bagging"><a href="#2-Bagging" class="headerlink" title="2. Bagging"></a>2. Bagging</h2><p>随机森林是在 bagging 方法上进行改进的。bagging 是一种集成算法，也是通过多个弱分类器进行策略结合，使最终结果好于单个的分类器。</p><p>决策树模型通过贪婪学习算法，具有高度可解释性并且训练快速。但是，单个决策树为了逼近一个复杂的函数，需要使用一个大树。一个大树通常具有高方差并且容易过拟合。</p><p>Bagging 就是解决高方差的一种方法，采用多个树结构然后对输出结果取平均。</p><p>Bagging 主要有两个步骤:</p><ol><li>(Bootstrap) 随机采样，从训练集中有放回的采集 $m$ 个样本，重复 $T$ 次得到对应的采样集，用每个采样集训练一个完整的决策树。</li><li>(Aggregate) 对结果进行聚合输出，如果是回归问题，$T$ 个弱学习器得到的回归结果进行算术平均得到的值为最终的模型输出，输出结果为 $\displaystyle y’ = \frac{1}{T}\sum_{t=1}^T \phi(\mathbf{x})$，如果是分类问题，则 $T$ 个弱学习器投出最多票数的类别为最终类别，$\displaystyle y’ = \argmax_j{k:\phi_k(\mathbf{x})=j}$</li></ol><p>Bagging 也就是 Bootstrap Aggregate 的缩写。</p><p>bagging 具有以下优点： </p><ol><li>高能力——通过使用完整的树，每个模型都能够逼近复杂的函数和决策边界。 </li><li>低方差——假设我们选择了足够多的树，对所有模型的预测进行平均可以减少最终预测的方差</li></ol><p>主要缺点是期望偏差可能会变大，同时平均模型不再易于解释，不能像决策树一样来追踪每一个节点分裂和输出的逻辑。</p><h2 id="3-随机森林"><a href="#3-随机森林" class="headerlink" title="3. 随机森林"></a>3. 随机森林</h2><p>假设每个决策树的预测变量 $\phi(\mathbf{x})$ 具有相同的方差 $\sigma$，同时 $\rho$ 代表两个决策树预测值之间的相关性，因此有</p><script type="math/tex; mode=display">\begin{aligned}    \text{Var}\left(\frac{1}{T}\sum_{t=1}^T \phi(\mathbf{x})\right) &= \frac{1}{ T^2} \sum_{k,m}\text{Cov}(\phi_k, \phi_m)\\    &= \frac{1}{ T^2} \sum_{k\ne m}\text{Cov}(\phi_k, \phi_m)+\frac{1}{ T^2} \sum_{k}\text{Cov}(\phi_k, \phi_k) \\    &= \frac{1}{ T^2}(T^2-T)\rho \sigma^2 +\frac{1}{ T^2}T\sigma \\    &= \rho \sigma^2 + \frac{\sigma^2}{T}(1-\rho)\end{aligned}</script><p>当随着 $T$ 的增加，上式中的第二项会越来越小，但第一项仍然存在。因此 bagging 最终受限于弱学习器之间的相关性。</p><p>随机森林相较于 bagging 更进一步的降低决策树之间的相关性。采用方法是对决策树划分子树的时候，会从节点上所有 $n$ 个特征中选择 $m$ 个部分样本特征，再在这 $m$ 中特征中选择最优的一个特征来做决策树的左右子树划分。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><blockquote><p><a href="https://en.wikipedia.org/wiki/Random_forest#cite_note-kleinberg1990-6">1. Random forest - wiki</a><br><a href="https://link.springer.com/content/pdf/10.1023/A%3A1010933404324.pdf">2. Random Forests - LEO BREIMAN</a><br><a href="http://www.math.snu.ac.kr/~hichoi/machinelearning/lecturenotes/RandomForests.pdf">3. Lecture 10: Random Forests</a><br><a href="https://harvard-iacs.github.io%/2017-CS109A/lectures/lecture15/presentation/lecture15_RandomForest.pdf">4. Lecture #15: Regression Trees &amp; Random Forests</a><br><a href="https://yxzf.github.io/2017/04/xgboost-v2/">5. XGBoost解读(2)—近似分割算法</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;h1 id=&quot;RandomForest&quot;&gt;&lt;a href=&quot;#RandomForest&quot; class=&quot;headerlink&quot; title=&quot;RandomForest&quot;&gt;&lt;/a&gt;RandomForest&lt;/h1&gt;&lt;h2 id=&quot;1</summary>
      
    
    
    
    <category term="Machine learning" scheme="http://example.com/categories/Machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>13. eXtreme Gradient Boosting</title>
    <link href="http://example.com/2022/07/27/MachineLearning/13.eXtremeGradientBoosting/"/>
    <id>http://example.com/2022/07/27/MachineLearning/13.eXtremeGradientBoosting/</id>
    <published>2022-07-26T16:00:00.000Z</published>
    <updated>2022-07-27T09:20:37.141Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><h1 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h1><h2 id="1-背景概述"><a href="#1-背景概述" class="headerlink" title="1. 背景概述"></a>1. 背景概述</h2><p>XGBoost 最初是由 Tianqi Chen 作为分布式（深度）机器学习社区（DMLC）组的一部分的一个研究项目开始的。</p><p>最初，它是作为一个终端应用程序开始的，可以使用 libsvm 配置文件进行配置。在希格斯机器学习挑战赛的获胜解决方案中使用后，它在 ML 竞赛圈中广为人知。</p><p>不久之后，构建了 Python 和 R 包，并且 XGBoost 现在具有 Java、Scala、Julia、Perl 和其他语言的包实现。这为更多的开发人员带来了该库，并促进了它在 Kaggle 社区中的普及，它已被用于大量比赛。</p><h2 id="2-模型算法"><a href="#2-模型算法" class="headerlink" title="2. 模型算法"></a>2. 模型算法</h2><p>给定回归训练数据集：</p><script type="math/tex; mode=display">T=\{(\mathbf x_1,y_1),(\mathbf x_2,y_2),...,(\mathbf x_N,y_N)\}</script><p>其中，${\displaystyle \mathbf x_i\in \mathcal{X}\subseteq R^m}$ 表示实例的特征向量，$y\in \mathcal{Y}\subseteq R$ 。给定实例特征向量$\mathbf x$，输出所属的值 $y$ 。</p><p>假设 $T$ 步得到的集成模型为 </p><script type="math/tex; mode=display">{\hat y}_i=f_T(\mathbf{x})=\sum_{t=1}^T h_t(\mathbf{x}),\qquad h_t\in \mathcal{F}</script><p>其中</p><script type="math/tex; mode=display">\mathcal{F}=\{h(\mathbf{x})=w_{q(\mathbf{x})}\}(q:\mathbb{R}^m\rightarrow K,w\in \mathbb{R}^K)</script><p>是回归树的空间，$q$ 代表将实例映射到叶节点的树结构； $K$ 是叶节点的数量；每个 $h_t$ 都有独立的树结构 $q$ 和叶节点权重 $w$。回归树具有连续的输出值，使用 $w_i$ 代表叶节点 $i$ 的输出。一个实例的最终的预测值是该实例在不同回归树的预测值累加之和。 </p><p>xgboost 定义损失函数为</p><script type="math/tex; mode=display">\mathcal{L}(f)=\sum_il(\hat{y}_i, y_i)+\sum_t \Omega(h_t)</script><p>其中</p><script type="math/tex; mode=display">\Omega(h)=\gamma K + \frac{1}{2}\lambda\|w\|^2</script><p>$l$ 是一个可微的图损失函数，用于衡量预测值 ${\hat y}_i$ 和目标 $y_i$ 之间的差异。$\Omega(h)$ 用来惩罚模型的复杂性，有助于平滑最终学习权重，避免过拟合。</p><p>上面的损失函数包含函数作为参数，无法使用欧几里得空间中传统的优化方法进行优化。加法模型使用前向分步算法进行优化。</p><p>使用 $\hat{y}_i^{(t)}$ 代表第 $t$ 次迭代、第 $i$ 个实例的预测值，因此添加 $h_t$ 最小化如下目标</p><script type="math/tex; mode=display">\mathcal{L}(f)=\sum_il(y_i,\hat{y}_i^{(t-1)}+h_t(\mathbf{x}_i))+\sum_t \Omega(h_t)</script><p>对 $l$ 进行泰勒展开</p><script type="math/tex; mode=display">l(y_i,\hat{y}_i^{(t-1)}+h_t(\mathbf{x}_i))\thickapprox l(y_i,\hat{y}_i^{(t-1)})+g_ih_t(\mathbf{x}_i)+\frac{1}{2}l_ih^2_t(\mathbf{x}_i)</script><p>其中 $g_i,l_i$ 分别为损失函数在 $\hat{y}_i^{(t-1)}$ 的一阶与二阶导数</p><script type="math/tex; mode=display">g_i=\frac{\partial l(y_i,\hat{y}_i^{(t-1)})}{\partial \hat{y}_i^{(t-1)}}\qquad l_i=\frac{\partial l(y_i,\hat{y}_i^{(t-1)})}{\displaystyle \partial^2 \hat{y}_i^{(t-1)}}</script><p>第一项为常数项，同时定义 $I_i=\{i|q(\mathbf{x}_i)=j\}$ 表示叶子结点 $j$ 中的全部实例。因此，损失函数可以重新写为</p><script type="math/tex; mode=display">\begin{aligned}    \tilde{\mathcal{L}}^{(t)}&= \sum_i^n [g_ih_t(\mathbf{x}_i)+\frac{1}{2}l_ih^2_t(\mathbf{x}_i)] + \gamma K + \frac{1}{2}\lambda \sum_{j=1}^Kw_j^2 \\    &= \sum_{j=1}^K [(\sum_{i\in I_j}g_i)w_j + \frac{1}{2}(\sum_{i\in I_j}l_i+\lambda)w_j^2] + \gamma K\end{aligned}</script><p>令上式导数为 $0$，可以求得叶节点 $j$ 的最优输出值为</p><script type="math/tex; mode=display">w_j^\ast=-\frac{\sum_{i\in I_j}g_i}{\sum_{i\in I_j}l_i+\lambda}</script><p>计算出最优的损失函数值</p><script type="math/tex; mode=display">\tilde{\mathcal{L}}^{(t)}(q)=-\frac{1}{2} \sum_{j=1}^K \frac{(\sum_{i\in I_j}g_i)^2}{\sum_{i\in I_j}l_i+\lambda}+\gamma K</script><p>上式用来衡量树结构 $q$ 的质量，相当于决策树中的不纯度函数。</p><p>类似于决策树的生成，不可能枚举每一种树结构，而是采用贪婪的方式生成左右子树。假设 $I_L$ 和 $I_R$ 表示分割后左右节点到的实例集，令 $I=I_L\cup I_R$，拆分后的损失减少为</p><script type="math/tex; mode=display">\mathcal{L}_{split}=\frac{1}{2}\left[ \frac{(\sum_{i\in I_L}g_i)^2}{\sum_{i\in I_L}l_i+\lambda} +\frac{(\sum_{i\in I_R}g_i)^2}{\sum_{i\in I_R}l_i+\lambda}-  \frac{(\sum_{i\in I}g_i)^2}{\sum_{i\in I}l_i+\lambda} \right]-\gamma</script><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><blockquote><p><a href="https://www.kdd.org/kdd2016/papers/files/rfp0697-chenAemb.pdf">1. XGBoost: A Scalable Tree Boosting System</a><br><a href="https://en.wikipedia.org/wiki/XGBoost">2. XGBoost - wiki</a><br><a href="https://zhuanlan.zhihu.com/p/392808684">3. Taylor公式（泰勒公式）通俗+本质详解 - zhihu</a><br><a href="http://datavalley.github.io/2017/09/11/xgboost%E6%BA%90%E7%A0%81%E4%B9%8B%E5%88%86%E4%BD%8D%E7%82%B9">4. xgboost之分位点算法</a><br><a href="https://yxzf.github.io/2017/04/xgboost-v2/">5. XGBoost解读(2)—近似分割算法</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;h1 id=&quot;XGBoost&quot;&gt;&lt;a href=&quot;#XGBoost&quot; class=&quot;headerlink&quot; title=&quot;XGBoost&quot;&gt;&lt;/a&gt;XGBoost&lt;/h1&gt;&lt;h2 id=&quot;1-背景概述&quot;&gt;&lt;a href=&quot;#1-背</summary>
      
    
    
    
    <category term="Machine learning" scheme="http://example.com/categories/Machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>12. Adaptive Boost</title>
    <link href="http://example.com/2022/07/19/MachineLearning/12.GradientBoostingDecisonTree/"/>
    <id>http://example.com/2022/07/19/MachineLearning/12.GradientBoostingDecisonTree/</id>
    <published>2022-07-18T16:00:00.000Z</published>
    <updated>2022-07-22T09:52:29.174Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><h1 id="梯度提升树"><a href="#梯度提升树" class="headerlink" title="梯度提升树"></a>梯度提升树</h1><h2 id="1-背景概述"><a href="#1-背景概述" class="headerlink" title="1. 背景概述"></a>1. 背景概述</h2><p>假定输入与输出的真实关系为 $\mathbf{y}=g(\mathbf{x})$，对于 $T$ 个不同的模型 $h_1(\mathbf{x}),h_2(\mathbf{x}),\dots,h_T(\mathbf{x})$，每个模型的期望错误为</p><script type="math/tex; mode=display">\begin{aligned}    \mathcal R(h_t)&=E_\mathbf{x}\left[\left(h_t(\mathbf{x})-g(\mathbf{x})\right)^2\right]\\    &=E_\mathbf{x}\left[\epsilon_t(\mathbf{x})^2\right]\end{aligned}</script><p>其中 $\epsilon_t(\mathbf{x})=h_t(\mathbf{x})-g(\mathbf{x})$ 表示模型 $t$ 在样本 $\mathbf{x}$ 上的错误。</p><p>因此所有模型的平均错误为</p><script type="math/tex; mode=display">\mathcal R(h)=\frac{1}{T}\sum^T_{t=1}E_\mathbf{x}\left[\epsilon_t(\mathbf{x})^2\right]</script><p>集成学习（Ensemble Learning）就是通过某种策略将多个模型集成起来，通过群体决策来提高决策准确率。集成学习的首要问题是如何集成多个模型，比较常见的方法有平均法、投票法、学习法等。平均法又有算术平均和加权平均。</p><p>基于算术平均的集成模型 $F(\mathbf{x})$ 为</p><script type="math/tex; mode=display">F(\mathbf{x})=\frac{1}{T}\sum_{t=1}^T h_t(\mathbf{x})</script><p><strong>定理 1.</strong> 对于 $T$ 个不同模型 $h_1(\mathbf{x}),h_2(\mathbf{x}),\dots,h_T(\mathbf{x})$，其平均期望错误为 $\overline{\mathcal R}(h)$，基于算术平均的集成模型 $F(\mathbf{x})$ 的期望错误在 $\displaystyle\frac{1}{T}\overline{\mathcal R}(h)$ 和 $\overline{\mathcal R}(h)$ 之间。</p><p>证明：集成模型的期望错误为</p><script type="math/tex; mode=display">\begin{aligned}    \mathcal R(h_t)&=E_\mathbf{x}\left[\left(\frac{1}{T}\sum_{t=1}^T h_t(\mathbf{x})-g(\mathbf{x})\right)^2\right]\\    &=E_\mathbf{x}\left[\left(\frac{1}{T}\sum_{t=1}^T\epsilon_t(\mathbf{x})\right)^2\right]    \\    &=\frac{1}{T^2}E_\mathbf{x}\left[\sum_{t=1}^T\sum_{r=1}^T\epsilon_t(\mathbf{x})\epsilon_r(\mathbf{x})\right]\\    &=\frac{1}{T^2}\sum_{t=1}^T\sum_{r=1}^TE_\mathbf{x}\left[\epsilon_t(\mathbf{x})\epsilon_r(\mathbf{x})\right]\end{aligned}</script><p>其中 $E_\mathbf{x}\left[\epsilon_t(\mathbf{x})\epsilon_r(\mathbf{x})\right]$ 即为两个不用模型错误的相关性。如果两个模型之间错误是不相关的，则 $E_\mathbf{x}\left[\epsilon_t(\mathbf{x})\epsilon_r(\mathbf{x})\right]=0$；如果两个模型之间的错误是相同的，则 $\epsilon_t(\mathbf{x})=\epsilon_r(\mathbf{x})$。因此，可以得到 </p><script type="math/tex; mode=display">\displaystyle\frac{1}{T}\overline{\mathcal R}(h)\le \overline{\mathcal R}(h) \le \overline{\mathcal R}(h)</script><p>从上述公式中可以看出，为了得到更好的集成效果，要求每个模型之间具有一定的差异性，并随着模型数量的增多，其错误率也会下降，并趋于 $0$。</p><p>集成学习的方法可以分为两大类 Bagging 和 Boosting。</p><p><strong>Bagging 类方法</strong> Bagging 类方法是通过随机构造训练样本、随机选择特征等方法来提高每个基模型的独立性，代表性方法有 Bagging 和随机森林等。</p><ul><li>Bagging（Bootstrap Aggregating）是通过不同模型的训练数据集的独立性来提高不同模型之间的独立性。我们在原始训练集上进行有放回的随机采样，得到 $M$ 个比较小的训练集并训练 $M$ 个模型，然后通过投票的方法进行模型集成。</li><li>随机森林（Random Forest）[Breiman, 2001] 是在 Bagging 的基础上再引入了随机特征，进一步提高每个基模型之间的独立性。在随机森林中，每个基模型都是一棵决策树。</li></ul><p><strong>Boosting 类方法</strong> Boosting 类方法是按照一定的顺序来先后训练不同的基模型，每个模型都针对前序模型的错误进行专门训练。根据前序模型的结果，来调整训练样本的权重，从而增加不同基模型之间的差异性。Boosting 类方法是一种非常强大的集成方法，只要基模型的准确率比随机猜测高，就可以通过集成方法来显著地提高集成模型的准确率。 Boosting 类方法的代表性方法有 AdaBoost[Freund et al., 1996] 等。</p><h2 id="2-梯度提升树"><a href="#2-梯度提升树" class="headerlink" title="2. 梯度提升树"></a>2. 梯度提升树</h2><p>提升树运用了 boosting 的思想，并将弱分类器限制为只使用决策树。提升方法实际采用加法模型(即基函数的线性组合)与前向分步算法。</p><p>给定二元分类训练数据集：</p><script type="math/tex; mode=display">T=\{(\mathbf x_1,y_1),(\mathbf x_2,y_2),...,(\mathbf x_N,y_N)\}</script><p>其中，${\displaystyle \mathbf x_i\in \mathcal{X}\subseteq R^n}$ 表示实例的特征向量，$y\in \mathcal{Y}=\{-1,+1\}$ 表示实例的类别，也就是标记（label）。给定实例特征向量$\mathbf x$，输出所属的类 $y$ 。</p><p>假设 $T$ 步得到的集成模型为 </p><script type="math/tex; mode=display">f_T(\mathbf{x})=\sum_{t=1}^T h_t(\mathbf{x})</script><p>因此，第 $t$ 步的模型为</p><script type="math/tex; mode=display">f_t(\mathbf{x})=f_{t-1}(\mathbf{x}) + h_t(\mathbf{x})</script><p>那么第 $t$ 步的总误差为</p><script type="math/tex; mode=display">Loss_t=\sum_\mathbf{x}L(y,f_{t-1}(\mathbf{x}) + h_t(\mathbf{x}))</script><p>$f_{t-1}(\mathbf{x}) + h_t(\mathbf{x})$ 即相当于损失函数的自变量，每一步为了使总误差下降，只需要使 $f_t$ 向负梯度的方向移动即可。因此，每一个新的模型 $h_t(\mathbf{x})$ 拟合上一步损失函数的负梯度</p><script type="math/tex; mode=display">h_t(\mathbf{x})=-\frac{\partial L(y,f_{t-1}(\mathbf{x}))}{\partial f_{t-1}(\mathbf{x})}</script><p>这样第 $t$ 步的模型即为</p><script type="math/tex; mode=display">f_t(\mathbf{x})=f_{t-1}(\mathbf{x}) -\frac{\partial L(y,f_{t-1}(\mathbf{x}))}{\partial f_{t-1}(\mathbf{x})}</script><p>相当于步长为 $1$ 的梯度下降法</p><script type="math/tex; mode=display">\theta_i = \theta_{i-1} -\rho \frac{\partial J}{\partial \theta_{i-1}}</script><h3 id="2-1-GBDT-回归"><a href="#2-1-GBDT-回归" class="headerlink" title="2.1 GBDT 回归"></a>2.1 GBDT 回归</h3><p>如果回归树使用平方误差损失函数</p><script type="math/tex; mode=display">L(y, f(x))=\frac{1}{2}(y-f(x))^2</script><p>第 $t$ 步的模型为</p><script type="math/tex; mode=display">f_t(\mathbf{x})=f_{t-1}(\mathbf{x}) + h_t(\mathbf{x})</script><p>损失变为</p><script type="math/tex; mode=display">L(y, f_{t-1}(\mathbf{x}) + h_t(\mathbf{x}))=(y-f_{t-1}(\mathbf{x}) - h_t(\mathbf{x}))^2</script><p>令 </p><script type="math/tex; mode=display">r=y-f_{t-1}(\mathbf{x})</script><p>$r$ 即为数据的残差，为了使更新后的模型损失尽可能小，$h_t$ 拟合的目标即为数据的残差。</p><p>以上其实是提升树的思想，即拟合残差。从梯度提升树的角度思考，平方误差损失函数的负梯度即为</p><script type="math/tex; mode=display">\frac{\partial L(y, f(\mathbf{x}))}{\partial f(\mathbf{x})}=y-f(\mathbf{x})</script><p>这与残差的结果是一致的。</p><blockquote><p>到底残差是负梯度的特例，还是负梯度是残差的表现形式，还存在疑问</p><p>两种解释</p><ol><li>本质是使损失函数最小化，拟合负梯度使损失函数下降最快。本质是通过累加各个学习器使损失函数减小，而不是使训练样本拟合的更好。rme 损失函数的负梯度恰好是残差。</li><li>本质是拟合残差，减小残差而非拟合负梯度才是求解本质。</li></ol><p>更倾向于第一种解释</p></blockquote><p>平方误差对于异常值的鲁棒性不强，过分关注与异常值。因此，在回归问题中，还具有其他损失函数</p><p><strong>绝对损失</strong></p><script type="math/tex; mode=display">L(y,f)=|y-f|</script><p><strong>Huber 损失</strong> </p><script type="math/tex; mode=display">{\displaystyle L(y,f)={    \begin{cases}        \frac{1}{2}(y-f)^2&|y-f|\le \delta \\        \delta(|y-f|-\delta/2)&|y-f|> \delta    \end{cases}    }}</script><p>在真值为 $5$，预测为 $1.7$ 的情况下，三种损失值分别为 $5.445$、$3.3$、 $1.525(\delta=0.5)$。</p><p>绝对损失的负梯度为</p><script type="math/tex; mode=display">-g(\mathbf{x})=-\frac{\partial L(y, f(\mathbf{x}))}{\partial f(\mathbf{x})}=\text{sign}(y-f(\mathbf{x}))</script><p>Huber 损失的负梯度为</p><script type="math/tex; mode=display">\begin{aligned}    -g(\mathbf{x})&=-\frac{\partial L(y, f(\mathbf{x}))}{\partial f(\mathbf{x})} \\    &={    \begin{cases}        y-f(\mathbf{x})&|y-f|\le \delta \\        \delta\text{sign}(y-f(\mathbf{x}))&|y-f|> \delta    \end{cases}    }\end{aligned}</script><p>对于每一个实例 $\mathbf{x}$ 都可计算出一个负梯度，然后用一个回归树拟合即可，也就是用负梯度的值取代真实值 $y$，再去做训练得到 $h_t$。</p><h3 id="2-1-GBDT-分类"><a href="#2-1-GBDT-分类" class="headerlink" title="2.1 GBDT 分类"></a>2.1 GBDT 分类</h3><p>GBDT 的分类算法从思想上和 GBDT 的回归算法没有区别，但是由于样本输出不是连续的值，而是离散的类别，导致我们无法直接从输出类别去拟合类别输出的误差。</p><p>为了解决这个问题，主要有两个方法，一个是用指数损失函数，此时 GBDT 退化为 Adaboost 算法。另一种方法是用类似于逻辑回归的对数似然损失函数的方法。也就是说，我们用的是类别的预测概率值和真实概率值的差来拟合损失。本文仅讨论用对数似然损失函数的 GBDT 分类。而对于对数似然损失函数，我们又有二元分类和多元分类的区别。</p><p>分类底层还是用的 CART 回归树，没有用到分类树。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><blockquote><p><a href="https://www.cnblogs.com/pinard/p/6140514.html#!comments">1. 梯度提升树(GBDT)原理小结 - 刘建平</a><br><a href="https://projecteuclid.org/download/pdf_1/euclid.aos/1016218223">2. SPECIAL INVITED PAPER ADDITIVE LOGISTIC REGRESSION: A STATISTICAL VIEW OF BOOSTING</a><br><a href="https://statweb.stanford.edu/~jhf/ftp/trebst.pdf">3. Greedy Function Approximation: A Gradient Boosting Machine</a><br><a href="http://www.chengli.io/tutorials/gradient_boosting.pdf">4. A Gentle Introduction to Gradient Boosting</a><br><a href="https://zstevenwu.com/courses/s20/csci5525/resources/slides/lecture17.pdf">5. Lecture 17: Gradient Boosting</a><br><a href="https://www.zhihu.com/question/63560633">6. gbdt的残差为什么用负梯度代替？ - zhihu</a><br><a href="https://en.wikipedia.org/wiki/Gradient_boosting">7. Gradient boosting - wiki</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;h1 id=&quot;梯度提升树&quot;&gt;&lt;a href=&quot;#梯度提升树&quot; class=&quot;headerlink&quot; title=&quot;梯度提升树&quot;&gt;&lt;/a&gt;梯度提升树&lt;/h1&gt;&lt;h2 id=&quot;1-背景概述&quot;&gt;&lt;a href=&quot;#1-背景概述&quot; cla</summary>
      
    
    
    
    <category term="Machine learning" scheme="http://example.com/categories/Machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>Linux</title>
    <link href="http://example.com/2022/07/13/Command/Mac/"/>
    <id>http://example.com/2022/07/13/Command/Mac/</id>
    <published>2022-07-12T16:00:00.000Z</published>
    <updated>2022-07-13T02:40:30.544Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><h1 id="Mac"><a href="#Mac" class="headerlink" title="Mac"></a>Mac</h1><h2 id="1-brew"><a href="#1-brew" class="headerlink" title="1. brew"></a>1. brew</h2><p>我们使用linux下有yum，mac相应的是brew，直接使用中科大源安装brew</p><pre><code class="lang-bash">/usr/bin/ruby -e &quot;$(curl -fsSL https://cdn.jsdelivr.net/gh/ineo6/homebrew-install/install)&quot;#  换源# $ 指返回 brew --repo 的结果cd &quot;$(brew --repo)&quot;git remote set-url origin https://mirrors.ustc.edu.cn/brew.gitcd &quot;$(brew --repo)/Library/Taps/homebrew/homebrew-core&quot; // ? homebrew-caskgit remote set-url origin https://mirrors.ustc.edu.cn/brew.git</code></pre><h2 id="2-问题"><a href="#2-问题" class="headerlink" title="2. 问题"></a>2. 问题</h2><ul><li>import torch 出现如下问题</li></ul><pre><code class="lang-bash">renrendeMacBook-Pro-3:NoteBook_PyTorch renren$ /Library/Frameworks/Python.framework/Versions/3.9/bin/python3.9 /Users/renren/NoteBook/NoteBook_PyTorch/1.tensor.pyTraceback (most recent call last):  File &quot;/Users/renren/NoteBook/NoteBook_PyTorch/1.tensor.py&quot;, line 1, in &lt;module&gt;    import torch  File &quot;/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/__init__.py&quot;, line 202, in &lt;module&gt;    from torch._C import *  # noqa: F403ImportError: dlopen(/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/_C.cpython-39-darwin.so, 2): Library not loaded: @loader_path/../.dylibs/libomp.dylib  Referenced from: /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/lib/libtorch_cpu.dylib  Reason: no suitable image found.  Did find:        /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/lib/../.dylibs/libomp.dylib: cannot load &#39;libomp.dylib&#39; (load command 0x80000034 is unknown)        /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/lib/../.dylibs/libomp.dylib: cannot load &#39;libomp.dylib&#39; (load command 0x80000034 is unknown)# 解决方法brew install libomp</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;h1 id=&quot;Mac&quot;&gt;&lt;a href=&quot;#Mac&quot; class=&quot;headerlink&quot; title=&quot;Mac&quot;&gt;&lt;/a&gt;Mac&lt;/h1&gt;&lt;h2 id=&quot;1-brew&quot;&gt;&lt;a href=&quot;#1-brew&quot; class=&quot;head</summary>
      
    
    
    
    <category term="Command" scheme="http://example.com/categories/Command/"/>
    
    
  </entry>
  
  <entry>
    <title>3. Recurrent Neural Network</title>
    <link href="http://example.com/2022/07/11/DeepLearning/3.RecurrentNeuralNetwork/"/>
    <id>http://example.com/2022/07/11/DeepLearning/3.RecurrentNeuralNetwork/</id>
    <published>2022-07-10T16:00:00.000Z</published>
    <updated>2022-07-13T02:45:04.552Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><h1 id="循环神经网络"><a href="#循环神经网络" class="headerlink" title="循环神经网络"></a>循环神经网络</h1><h2 id="1-历史背景"><a href="#1-历史背景" class="headerlink" title="1. 历史背景"></a>1. 历史背景</h2><p>1986 年由 David Rumelhart 提出，也就是方向传播算法提出的时候。</p><h2 id="2-循环神经网络模型"><a href="#2-循环神经网络模型" class="headerlink" title="2. 循环神经网络模型"></a>2. 循环神经网络模型</h2><p>循环神经网络是一种处理序列数据的神经网络，例如处理语音和文本。循环神经网络和卷积神经网络相同的一点在于共享权重，如同图片中每个不同的区域实际上使用相同的卷积核进行计算，不同时间段的序列数据传入到同一神经网络层。</p><p>循环神经网络与多层感知机的结构更为相似。试想一下，如果用多层感知机对一句话进行标注，假设句子的长度都为 10，那么需要训练 10 个神经网络分别处理不同位置上的单词。而循环神经网络中，不同位置的单词共享一个一个神经网络，也是类似有输入层、隐藏层和输出层，唯一的区别在于，时刻 $t$ 的隐藏层输入 $\mathbf{h}^{(t)}$ 也作为时刻 $t + 1$ 的输入。</p><p>循环神经网络具有如下基本设计：</p><ol><li>每个时间步都有输出，并且隐藏单元之间有循环连接的循环网络。</li><li>每个时间步都产生一个输出，只有当前时刻的输出到下个时刻的隐藏单元之间有循环连接的循环网络</li><li>只有最后一个时间步才有输出，但隐藏单元之间有循环连接的循环网络。</li></ol><h3 id="2-1-前向传播"><a href="#2-1-前向传播" class="headerlink" title="2.1 前向传播"></a>2.1 前向传播</h3><p>我们采用最经典的循环神经网络进行公式推导，即每一个时间步都有输出，且隐藏单元之间有循环连接的循环网络。</p><p>时间步 $t$ 的输入 $\mathbf{x}^{(t)}$，隐藏层输出为 $\mathbf{h}^{(t)}$，损失函数为 $L^{(t)}$，因此有</p><script type="math/tex; mode=display">L^{(t)}=-\mathbf{y}^T\log\mathrm{softmax}\left(V\tanh(W\mathbf{h}^{(t-1)}+U\mathbf{x}^{(t)}+\mathbf{b})+\mathbf{c}\right)</script><blockquote><p>可以发现与多层感知机</p><script type="math/tex; mode=display">L=-\sum_{i=1}^{N}\mathbf{y}_i^T\log\mathrm{softmax}\left(W_2\sigma\left(W_1\mathbf{x}_i+\mathbf{b}_1\right)+\mathbf{b}_2\right)</script><p>仅仅多了一项 $W\mathbf{h}^{(t-1)}$</p></blockquote><p>总的损失是每一步损失之和</p><script type="math/tex; mode=display">L=\sum_t L^{(t)}</script><p>定义中间变量</p><script type="math/tex; mode=display">\mathbf{a}^{(t)}=W\mathbf{h}^{(t-1)}+U\mathbf{x}^{(t)}+\mathbf{b}</script><script type="math/tex; mode=display">\mathbf{h}^{(t)}=\tanh(\mathbf{a}^{(t)})</script><script type="math/tex; mode=display">\boldsymbol{o}^{(t)}=V\mathbf{h}^{(t)}+\mathbf{c}</script><h3 id="2-2-反向传播"><a href="#2-2-反向传播" class="headerlink" title="2.2 反向传播"></a>2.2 反向传播</h3><p>我们已经知道</p><script type="math/tex; mode=display">\frac{\partial L}{\partial \boldsymbol{o}^{(t)}}=\mathrm{softmax}(\boldsymbol{o}^{(t)})-\mathbf{y}_i</script><p>不能直接使用链式法则，因此使用复合法则，即微分与导数的联系</p><script type="math/tex; mode=display">\begin{aligned}    \mathrm{d}L&=\mathrm{tr}\left(\sum_t{\frac{\partial L}{\partial \boldsymbol{o}^{(t)}}}^T\mathrm{d}\boldsymbol{o}^{(t)}\right)\\    &=\mathrm{tr}\left(\sum_t{\frac{\partial L}{\partial \boldsymbol{o}^{(t)}}}^T\mathrm{d}V\mathbf{h}^{(t)}\right)+\mathrm{tr}\left(\sum_t{\frac{\partial L}{\partial \boldsymbol{o}^{(t)}}}^TV\mathrm{d}\mathbf{h}^{(t)}\right)+\mathrm{tr}\left(\sum_t{\frac{\partial L}{\partial \boldsymbol{o}^{(t)}}}^T\mathrm{d}\mathbf{c}\right)\end{aligned}</script><p>由第二项得到</p><script type="math/tex; mode=display">\frac{\partial L}{\partial \mathbf{h}^{(t)}}={V\frac{\partial L}{\partial \boldsymbol{o}^{(t)}}}^T</script><p>进一步地利用复合法则</p><script type="math/tex; mode=display">\begin{aligned}    \mathrm{d}L&=\mathrm{tr}\left(\sum_t{\frac{\partial L}{\partial \mathbf{h}^{(t)}}}^T\mathrm{d}\mathbf{h}^{(t)}\right)\\    &=\mathrm{tr}\left(\sum_t{\frac{\partial L}{\partial \mathbf{h}^{(t)}}}^T\left(1-(\mathbf{h}^{(t)})^2\right)\odot\mathrm{d}\mathbf{a}^{(t)}\right)\\    &=\mathrm{tr}\left(\sum_t{ {\frac{\partial L}{\partial \mathbf{h}^{(t)}}}\odot\left(1-(\mathbf{h}^{(t)})^2\right)}^T\mathrm{d}\mathbf{a}^{(t)}\right)\end{aligned}</script><p>因此可以得到</p><script type="math/tex; mode=display">\frac{\partial L}{\partial W}=\sum_t{ {\frac{\partial L}{\partial \mathbf{h}^{(t)}}}\odot\left(1-(\mathbf{h}^{(t)})^2\right)}{\mathbf{h}^{(t-1)}}^T</script><p>其他的求导结果与多层感知机类似，从略。</p><h2 id="3-长短时记忆网络模型"><a href="#3-长短时记忆网络模型" class="headerlink" title="3. 长短时记忆网络模型"></a>3. 长短时记忆网络模型</h2><p>循环神经网络的一大问题在于梯度消失或梯度爆炸，很难建立长时间间隔的状态依赖关系。长短时记忆网络通过引入门控机制，从而有效解决循环神经网络存在问题。</p><p>LSTM 网络引入一个新的内部状态 $\mathrm{c}_t$，专门进行线性的循环信息传递，同时非线性的输出信息给隐藏层的外部状态 $\mathrm{h}_t$，它们具有如下关系</p><script type="math/tex; mode=display">\mathbf{c}_t=\boldsymbol{f}_t\odot\mathbf{c}_{t-1}+\boldsymbol{i}_t\odot \tilde{\mathbf{c}}_t</script><script type="math/tex; mode=display">\mathbf{h}_t=\boldsymbol{o}_t\odot \tanh(\mathbf{c}_t)</script><p>其中 $\boldsymbol{f}_t,\boldsymbol{i}_t,\boldsymbol{o}_t\in[0,1]$ 是三个门来控制信息传递的路径。$\tilde{\mathbf{c}}_t$ 是通过非线性函数得到的候选状态</p><script type="math/tex; mode=display">\tilde{\mathbf{c}}_t=\tanh(W_c\mathbf{x}_t+U_c\mathbf{h}_{t-1}+\mathbf{b}_c)</script><p>在每个时刻，LSTM 网络内部状态 $\mathbf{c}_t$ 记录了到当前时刻为止的历史信息。</p><ul><li>遗忘门 $\boldsymbol{f}_t$ 控制上一时刻的内部状态 $\mathbf{c}_{t-1}$ 需要遗忘多少信息。</li><li>输入门 $\boldsymbol{i}_t$ 控制当前时刻的候选状态 $\tilde{\mathbf{c}}_t$ 有多少信息需要保存。</li><li>输出门 $\boldsymbol{o}_t$ 控制当前时刻的内部状态 $\mathbf{c}_{t}$ 有多少信息需要输出给外部状态 $\mathbf{h}_t$。</li></ul><p>三个门的计算方式为</p><script type="math/tex; mode=display">\boldsymbol{f}_t=\sigma (W_f\mathbf{x}_t+U_f\mathbf{h}_{t-1}+\mathbf{b}_f)</script><script type="math/tex; mode=display">\boldsymbol{i}_t=\sigma (W_i\mathbf{x}_t+U_i\mathbf{h}_{t-1}+\mathbf{b}_i)</script><script type="math/tex; mode=display">\boldsymbol{o}_t=\sigma (W_o\mathbf{x}_t+U_o\mathbf{h}_{t-1}+\mathbf{b}_o)</script><p>给出了 LSTM 网络的循环单元结构，其计算过程为：</p><ol><li>首先利用上一时刻的外部状态 $\mathbf{h}_{t-1}$ 和当前时刻的输入 $\mathbf{x}_t$，计算出三个门，以及候选状态 $\tilde{\mathbf{c}}_t$；</li><li>结合遗忘门 $\boldsymbol{f}_t$ 和输入门 $\boldsymbol{i}_t$ 来更新记忆单元 $\mathbf{c}_t$；</li><li>结合输出门 $\boldsymbol{o}_t$，将内部状态的信息传递给外部状态 $\mathbf{h}_{t}$</li></ol><p>循环神经网络中的隐状态 𝒉 存储了历史信息，可以看作是一种记忆（Memory）. 在简单循环网络中，隐状态每个时刻都会被重写，因此可以看作是一种短期记忆（Short-Term Memory）. 在神经网络中，长期记忆（Long-Term Memory）可以看作是网络参数，隐含了从训练数据中学到的经验，其更新周期要远远慢于短期记忆. 而在 LSTM 网络中，记忆单元 𝒄 可以在某个时刻捕捉到某个关键信息，并有能力将此关键信息保存一定的时间间隔. 记忆单元 𝒄 中保存信息的生命周期要长于短期记忆 𝒉，但又远远短于长期记忆，因此称为长短期记忆（Long Short-Term Memory）</p>]]></content>
    
    
      
      
    <summary type="html">&lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;h1 id=&quot;循环神经网络&quot;&gt;&lt;a href=&quot;#循环神经网络&quot; class=&quot;headerlink&quot; title=&quot;循环神经网络&quot;&gt;&lt;/a&gt;循环神经网络&lt;/h1&gt;&lt;h2 id=&quot;1-历史背景&quot;&gt;&lt;a href=&quot;#1-历史背景&quot;</summary>
      
    
    
    
    <category term="Deep learning" scheme="http://example.com/categories/Deep-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>2. Convolutional Neural Network</title>
    <link href="http://example.com/2022/06/20/DeepLearning/2.ConvolutionalNeuralNetwork/"/>
    <id>http://example.com/2022/06/20/DeepLearning/2.ConvolutionalNeuralNetwork/</id>
    <published>2022-06-19T16:00:00.000Z</published>
    <updated>2022-07-11T06:54:03.658Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><h1 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h1><h2 id="1-历史背景"><a href="#1-历史背景" class="headerlink" title="1. 历史背景"></a>1. 历史背景</h2><p>1950 年代和 1960 年代，Hubel 和 Wiesel 在 的工作表明，猫的视觉皮层包含单独对视野的小区域做出反应的神经元。如果眼睛不动，则视觉刺激影响单个神经元放电的视觉空间区域称为其感受野。相邻细胞具有相似和重叠的感受野。感受野大小和位置在整个皮层系统地变化，以形成完整的视觉空间图。每个半球的皮层代表对侧视野。</p><p>1968 年，他们的论文确定了大脑中两种基本的视觉细胞类型：，简单细胞会对<br>感受野中特定朝向的线段做出反应，而复杂细胞对于特定朝向的线段移动也能做出反应。Hubel 和 Wiesel 还提出了这两种类型的细胞的级联模型，用于模式识别任务。</p><p>1980 年，福岛邦彦在此基础上提出了神经认知机模型，引入了卷积层和池化层。卷积层包含的单元的感受野覆盖了前一层的一部分。这种单元的权重向量（一组自适应参数）通常称为滤波器。单元可以共享滤波器。下采样层包含其感受野覆盖先前卷积层块的单元。这样的单元通常计算其补丁中单元激活的平均值。这种下采样有助于正确分类视觉场景中的对象，即使对象发生移动也是如此。</p><p>1989 年，Yann LeCun 等人。使用反向传播直接从手写数字的图像中学习卷积核系数。因此，学习是全自动的，比手动系数设计表现更好，并且适用于更广泛的图像识别问题和图像类型。</p><h2 id="2-基本原理"><a href="#2-基本原理" class="headerlink" title="2. 基本原理"></a>2. 基本原理</h2><h3 id="2-1-卷积运算"><a href="#2-1-卷积运算" class="headerlink" title="2.1 卷积运算"></a>2.1 卷积运算</h3><p>在数字信号中，卷积的计算公式为</p><script type="math/tex; mode=display">W(T)=\int _{0 }^{T }f(\tau )g(T-\tau )\,\mathrm {d} \tau</script><p>$f$ 函数是输入信号，$g$ 函数是系统响应。卷积是建立在<strong>输入信号对系统产生的响应是随时间进行累积的</strong>，并且影响的大小与输入的大小具有线性关系。因此，$t$ 时刻进入系统的信号在系统中存在的时间为 $T-t$，由于线性关系，产生的影响即为 $f(t)g(T-t)$，然后对区间 $[0,T]$ 每一时刻的影响进行累加即可，连续情况下也就是积分。</p><p>在数字信号中， $g$ 函数是一个递减的函数，即距离时刻 $T$ 越近的输入信号造成的影响也就越大。</p><p>在图像处理中，卷积是通过卷积核进行计算的。卷积核矩阵的大小决定了感知野的大小，卷积核中的值决定了图像中相应元素的重要程度，本质上就是加权求和。因此，特定的卷积核可以产生特定的效果，例如相同权重值的卷积核会对输入值进行平均处理，从而对图片进行平滑滤波；而下式中的卷积核则可以对图片进行边缘提取，只有周围像素值差别大的地方例如边缘位置值才不会为 $0$。</p><script type="math/tex; mode=display">\begin{bmatrix}    0 &-1 & 0\\    -1 &-4 & -1\\    0 &-1 & 0\\\end{bmatrix}</script><p>假设把一张二维的图 $I$ 作为输入，同样有一个二维的核 $K$，卷积的结果为</p><script type="math/tex; mode=display">S(i,j)=(I*K)(i,j)=\sum_m\sum_nI(m,n)K(i-m,j-n)</script><p>卷积是可交换的，可以等价的写为</p><script type="math/tex; mode=display">S(i,j)=(I*K)(i,j)=\sum_m\sum_nI(i-m,j-n)K(m,n)</script><p>卷积的可交换性在于将核的相对输入进行了翻转，但在神经网络中卷积核并不是给定的，而是随着迭代改变的，因此翻转与否并不重要。在神经网络中实际使用的是互相关函数</p><script type="math/tex; mode=display">S(i,j)=(I*K)(i,j)=\sum_m\sum_nI(i+m,j+n)K(m,n)</script><p>卷积核的意义在于稀疏交互 （sparse interactions）、 参数共享（parameter sharing）和等变表示（equivariant representations）</p><p>卷积核通过限制输入的作用范围从而达到稀疏连接。如果有 $m$ 个输入和 $n$ 个输出，全连接层的时间复杂度为 $O(m\times n)$，卷积核的大小为 $k$，卷积运算的时间复杂度则为 $O(k\times n)$。尽管同一层输入只对部分输出产生影响，但在深度卷积网络中，深层单元与绝大部分输入具有间接交互。</p><p>在传统的神经网络中，当计算一层的输出时，权重矩阵的每一个元素只使用一次，当<br>它乘以输入的一个元素后就再也不会用到了。而卷积核对于输入都是共享的，因此节省了存储空间。</p><p>卷积运算还具有平移等变的特性。如果我们移动输入中的对象，它的表示也会在输出中移动同样的量。<br><a href="https://cs231n.github.io/assets/conv-demo/index.html">https://cs231n.github.io/assets/conv-demo/index.html</a></p><h3 id="2-2-池化"><a href="#2-2-池化" class="headerlink" title="2.2 池化"></a>2.2 池化</h3><p>在得到卷积特征后，下一步就是用来做分类。理论上，可以用提取到的所有特征训练分类器，但用所有特征的计算量开销会很大，而且也会使分类器倾向于过拟合。</p><p>为了解决这个问题，考虑到要描述一个大图像，一个自然的方法是在不同位置处对特征进行汇总统计。例如，可以计算在图像中某一区域的一个特定特征的平均值 (或最大值)，这样概括统计出来的数据，其规模 (相比使用提取到的所有特征) 就低得多，同时也可以改进分类结果 (使模型不易过拟合)。这样的聚集操作称为 “池化”。池化可以保留显著特征，降低特征规模。</p><ul><li>最大池化函数 (Max Pooling) 给出相邻矩形区域内的最大值</li><li>平均池化 (Average Pooling) 计算相邻矩形区域内的平均值</li><li>其他常用的池化函数包括 L2 范数以及基于距中心像素距离的加权平均函数</li></ul><p>池化函数具有局部平移不变形。平移的不变性是指当我们对输入进行少量平移时，经过<br>池化函数后的大多数输出并不会发生改变。当算法关心某个特征是否出现而不是具体位置时，池化就变得尤为有用。</p><h2 id="3-卷积层与参数"><a href="#3-卷积层与参数" class="headerlink" title="3. 卷积层与参数"></a>3. 卷积层与参数</h2><h3 id="3-1-填充"><a href="#3-1-填充" class="headerlink" title="3.1 填充"></a>3.1 填充</h3><p>假设输入图片大小 $(m,n)$，卷积核大小 $(f,f)$，则卷积后的输出图片大小为 $(m-f+1,m-f+1)$。这样会导致卷积运算后输出图片变小，并且图片的角落与边缘像素只参与一次运算，从而会丢失边缘位置的特征信息。</p><p>因此在卷积操作前，需要对输入图片进行填充，以增加矩阵大小，通常用 $0$ 来作为填充值。</p><p>设每个方向上填充像素点数量为 $p$，填充后的图片大小为 $(m+2p,n+2p)$，卷积核的大小仍为 $(f,f)$，则输出图片大小为 $(m+2p-f+1,n+2p-f+1)$。</p><p>填充方法有</p><ul><li>有效(valid)卷积，不填充，直接卷积，输出大小即为 $(m-f+1,m-f+1)$</li><li>相同(same)卷积，用 $0$ 填充，使卷积后结果大小与输入一致，$p=(f-1)/2$</li><li>全(full)卷积，通过填充，使输出大小为 $(m+f-1,n+f-1)$</li></ul><h3 id="3-2-步幅"><a href="#3-2-步幅" class="headerlink" title="3.2 步幅"></a>3.2 步幅</h3><p>除了需要通过填充来避免信息损失，有时也需要通过设置步幅 (Stride) 来压缩一部分信息。步幅表示核在原始图片的水平方向和垂直方向上每次移动的距离。使用卷积步幅，跳过核中的一些位置 (看作对输出的下采样) 来降低计算的开销。如果水平方向和垂直方向的步幅都设为 $s$，则输出尺寸为</p><script type="math/tex; mode=display">([\frac{m+2p-f}{s}+1,\frac{n+2p-f}{s}+1])</script><h3 id="3-3-多通道与并行"><a href="#3-3-多通道与并行" class="headerlink" title="3.3 多通道与并行"></a>3.3 多通道与并行</h3><p>卷积神经网络中，可以用多组卷积核提取不同的特征，相应的会增加输出的维度，例如输入大小 $(m,n)$，卷积核有两组 $(f,f,2)$，使用 same 卷积，输出则为 $(m,n,2)$。</p><p>输入通常也不仅仅是实值的网格，而是由一系列向量的网格，如一幅彩色图像在每一个像素点都会有红绿蓝三种颜色的亮度。当处理图像时，通常把卷积的输入输出都看作是 3 维的张量，其中一个索引用于标明不同的通道 (例如 RGB)，另外两个索引标明在每个通道上的空间坐标。</p><p>同样上面的例子，假设输入有三通道，即 $(m,n,3)$，卷积核则为 $(f,f,3,2)$，输出即为 $(m,n,3,2)$。</p><p>定义输入通道为 $k$，输出通道为 $l$，则计算公式为</p><script type="math/tex; mode=display">S^l(i,j)=\sum_k(I_k*K^l_k)(i,j)</script><h2 id="4-反向传播"><a href="#4-反向传播" class="headerlink" title="4. 反向传播"></a>4. 反向传播</h2><h3 id="4-1-卷积层反向传播"><a href="#4-1-卷积层反向传播" class="headerlink" title="4.1 卷积层反向传播"></a>4.1 卷积层反向传播</h3><p>先不考虑多通道，假设输入是矩阵的情况下进行推导。</p><p>输入 $\mathbf{x}$，卷积核 $\mathbf{w}$，卷积结果为 $\mathbf{y}$，因此卷积计算为</p><script type="math/tex; mode=display">\mathbf{y}=\mathbf{x}*\mathbf{w}</script><p>每一个元素的计算方法（这里下标 $-1$ 是由于矩阵的角标从 $1$ 开始）</p><script type="math/tex; mode=display">y_{i,j}=(\mathbf{x}*\mathbf{w})(i,j)=\sum_m\sum_nx_{i+m-1,j+n-1}w_{m,n}</script><p>因此偏导数分别为</p><script type="math/tex; mode=display">\frac{\partial y_{i,j}}{\partial w_{m,n}}=x_{i+m-1,j+n-1}</script><script type="math/tex; mode=display">\frac{\partial y_{i-m+1,j-n+1}}{\partial x_{i,j}}=w_{m,n}</script><p>应用链式法则，得到 $L$ 关于 $\mathbf{x}$ 和 $\mathbf{w}$ 的导数</p><script type="math/tex; mode=display">\begin{aligned}    \frac{\partial L}{\partial x_{i,j}}&=\sum_m\sum_n\frac{\partial L}{\partial y_{i-m+1,j-n+1}}\frac{\partial y_{i-m+1,j-n+1}}{\partial x_{i,j}}\\    &=\sum_m\sum_n\delta^{(y)}_{i-m+1,j-n+1}w_{m,n}\\    &=\delta^{(\mathbf{y})}*\mathrm{flip}(\mathbf{w})(i,j)\end{aligned}</script><p>其中，$\delta^{(\mathbf{y})}$ 为 $\mathbf{y}$ 的误差矩阵，注意这里为了保证导数矩阵的维度和 $\mathbf{x}$ 一致，需要对 $\delta^{(\mathbf{y})}$ 进行填充，填充后和 $\mathbf{x}$ 一致。</p><script type="math/tex; mode=display">\begin{aligned}    \frac{\partial L}{\partial w_{m,n}}&=\sum_m\sum_n\frac{\partial L}{\partial y_{i,j}}\frac{\partial y_{i,j}}{\partial w_{m,n}}\\    &=\sum_m\sum_n\delta^{(y)}_{i,j}x_{i+m-1,j+n-1}\\    &=\delta^{(\mathbf{y})}*\mathbf{x}(m,n)\end{aligned}</script><p>经过激活函数，卷积层的输出为</p><script type="math/tex; mode=display">\mathbf{a}=g(\mathbf{y})=g(\mathbf{x}*\mathbf{w}+\mathbf{b})</script><p>因此反向传播为</p><script type="math/tex; mode=display">\frac{\partial L}{\partial x_{i,j}}=\delta^{(\mathbf{y})}*\mathrm{flip}(\mathbf{w})\odot g'(\mathbf{y})</script><h3 id="4-2-池化层反向传播"><a href="#4-2-池化层反向传播" class="headerlink" title="4.2 池化层反向传播"></a>4.2 池化层反向传播</h3><p>池化函数是一个下采样函数，对于大小为 $m$ 的池化区域，池化函数及导数定义为</p><ul><li>最大池化：$g(x)=max(x)$，导数为 $\displaystyle\frac{\partial g}{\partial x_i}={\begin{cases}1&amp;x_i=max(x)\\0&amp;\mathrm{otherwise}\end{cases}}$</li><li>均值池化：$\displaystyle g(x)=\frac{\sum_k x_k}{m}$，导数为 $\displaystyle\frac{\partial g}{\partial x_i}=\frac{1}{m}$</li><li>p 范数池化：$g(x)=|x|_p=(\sum_k |x_k|^p)^{1/p}$，导数为$\displaystyle \frac{\partial g}{\partial x_i}=(\sum_k |x_k|^p)^{1/p -1}|x_i|^{p-1}$</li></ul><p>定义池化的反向传播为</p><script type="math/tex; mode=display">\begin{aligned}    \frac{\partial L}{\partial x_{(n-1)m-1:nm}} &=\frac{\partial L}{\partial y_n}\frac{\partial y_n}{\partial x_{(n-1)m-1:nm}}\\    &=\delta_n^{(y)}g_n'\\    &=upsample(\delta_n^{(y)},g_n')\end{aligned}</script><p>上式是一维的上采样（upsample）方式，对于二维大小为 $m*m$ 的池化方式相同。</p><p>假设池化大小 $2\times 2$，池化层输出反向传播回来的梯度为</p><script type="math/tex; mode=display">\delta_k^{(y)}=\begin{pmatrix}    2 & 4 \\    6 & 8\end{pmatrix}</script><p>根据输入矩阵的大小，将梯度进行填充</p><script type="math/tex; mode=display">\begin{pmatrix}    0 &0 & 0 &0 \\    0 &2 & 4 &0 \\    0 &6 & 8 &0 \\    0 &0 & 0 &0 \\\end{pmatrix}</script><p>如果是最大池化，假设之前在前向传播时记录的最大值位置分别是左上，右上，左下，右下，则转换后的矩阵为</p><script type="math/tex; mode=display">\begin{pmatrix}    2 &0 & 0 &4 \\    0 &0 & 0 &0 \\    0 &0 & 0 &0 \\    6 &0 & 0 &8 \\\end{pmatrix}</script><p>如果是均值池化，根据公式可以得到：</p><script type="math/tex; mode=display">\begin{pmatrix}    0.5 &0.5 & 1.0 &1.0 \\    0.5 &0.5 & 1.0 &1.0 \\    1.5 &1.5 & 2.0 &2.0 \\    1.5 &1.5 & 2.0 &2.0 \\\end{pmatrix}</script><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><blockquote><p><a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">1. Convolutional neural network - Wikipedia</a><br><a href="https://www.zhihu.com/question/22298352/answer/228543288">2. 如何通俗易懂地解释卷积？ - zhihu</a><br><a href="https://www.zhihu.com/question/52237725">3. 卷积神经网络的卷积核 - zhihu</a><br><a href="https://github.com/MingchaoZhu/DeepLearning/releases/download/v0.0.1/DL_cn.pdf">4. 《深度学习》——IanGoodfellow</a><br><a href="https://github.com/MingchaoZhu/DeepLearning">5. MingchaoZhu  DeepLearning</a><br><a href="https://cs231n.github.io/convolutional-networks/">6. CS231n: Convolutional Neural Networks for Visual Recognition.</a><br><a href="https://zhuanlan.zhihu.com/p/49205794">7. 从0到1：实现卷积神经网络(实现篇) - zhihu</a><br><a href="https://web-archive.southampton.ac.uk/cogprints.org/5869/1/cnn_tutorial.pdf">8. Notes on Convolutional Neural Networks</a><br><a href="https://www.cs.toronto.edu/~urtasun/courses/CSC411_Fall16/10_nn1.pdf">9. CSC 411: Lecture 10: Neural Networks</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;h1 id=&quot;卷积神经网络&quot;&gt;&lt;a href=&quot;#卷积神经网络&quot; class=&quot;headerlink&quot; title=&quot;卷积神经网络&quot;&gt;&lt;/a&gt;卷积神经网络&lt;/h1&gt;&lt;h2 id=&quot;1-历史背景&quot;&gt;&lt;a href=&quot;#1-历史背景&quot;</summary>
      
    
    
    
    <category term="Deep learning" scheme="http://example.com/categories/Deep-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>1. Artificial Neural Network</title>
    <link href="http://example.com/2022/06/16/DeepLearning/1.ArtificialNeuralNetwork/"/>
    <id>http://example.com/2022/06/16/DeepLearning/1.ArtificialNeuralNetwork/</id>
    <published>2022-06-15T16:00:00.000Z</published>
    <updated>2022-07-13T00:50:30.495Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><h1 id="人工神经网络"><a href="#人工神经网络" class="headerlink" title="人工神经网络"></a>人工神经网络</h1><h2 id="1-历史背景"><a href="#1-历史背景" class="headerlink" title="1. 历史背景"></a>1. 历史背景</h2><p>1943 年，Warren McCulloch 和 Walter Pitts 提出形式神经元模型。 </p><p>在 1940 年代后期，D. O. Hebb[4] 基于神经可塑性机制创建了一个学习假设，即赫布学习。 Farley 和 Wesley A. Clark[5] \left(1954\right) 首先使用计算机器，然后称为“计算器”来模拟 Hebbian 网络。 </p><p>1958 年，心理学家 Frank Rosenblatt 发明了感知器，这是第一个人工神经网络，由美国海军研究办公室资助。</p><p>1969 年，Minsky 和 ​​Papert 提出感知机无法处理线性不可分问题，他们发现基本感知器无法处理异或电路，并且计算机缺乏足够的能力来处理有用的神经网络。</p><p>1965 年，Ivakhnenko 和 Lapa 提出第一个具有多层的神经网络。</p><p>1960 年，Henry J. Kelley 和 Arthur L. Bryson 使用动态规划原理在控制理论的背景下得出连续反向传播的基础。</p><p>1986 年，Rumelhart, Hinton &amp; Williams 再次提出反向传播一词，并阐述和推广使其在神经网络中的普遍使用，但该技术被独立地重新发现了很多次。</p><h2 id="2-基础预备"><a href="#2-基础预备" class="headerlink" title="2 基础预备"></a>2 基础预备</h2><h3 id="2-1-激活函数"><a href="#2-1-激活函数" class="headerlink" title="2.1 激活函数"></a>2.1 激活函数</h3><p><strong>sigmoid 函数</strong></p><p>该函数将取值为 $\left(-\infty,+\infty\right)$ 的数映射到 $\left(0,1\right)$ 之间。sigmoid 的公式为 </p><script type="math/tex; mode=display">g\left(z\right)=\frac{1}{1+e^{-z}}</script><p>导函数为</p><script type="math/tex; mode=display">g'\left(z\right)=g\left(z\right)\left(1-g\left(z\right)\right)</script><p>sigmoid函数存在的问题在于</p><ol><li>需要计算指数，计算时间花费多。</li><li>当取值非常大或非常小时，sigmoid 的导数接近于 0，有可能会产生梯度消失。</li><li>函数的输出值不是以 0 为均值，不利于下层的计算，因此最好不用于隐藏层，可以作为输出层使用。</li></ol><p><strong>tanh 函数</strong></p><p>将取值为 $\left(-\infty,+\infty\right)$ 的数映射到 $\left(-1,1\right)$ 之间。tanh 的公式为</p><script type="math/tex; mode=display">g\left(z\right)=\frac{e^z-e^{-z}}{e^z+e^{-z}}</script><p>tanh 函数的导函数为</p><script type="math/tex; mode=display">g'\left(z\right)=1-g\left(z\right)^2</script><p>tanh导数具有较大的值域，可以缓解梯度消失的情况</p><p>tanh 函数均值为 0，弥补了 sigmoid 函数均值为 $0.5$ 的缺点。但由于 $g’\left(z\right)$ 在两端取值接近于 0，因此也会有梯度消失的情况发生。</p><p><strong>ReLU 函数</strong></p><p>ReLU 函数又称为修正线性单元（Rectified Linear Unit），是一种分段线性函数，其弥补了 sigmoid 函数以及 tanh 函数的梯度消失问题。</p><p>ReLU 函数的公式为：</p><script type="math/tex; mode=display">{\displaystyle g\left(z\right)={    \begin{cases}        z&z\geq 0\\        0&z<0    \end{cases}    }}</script><p>ReLU 函数的导函数为</p><script type="math/tex; mode=display">{\displaystyle g‘\left(z\right)={    \begin{cases}        1&z\geq 0\\        0&z<0    \end{cases}    }}</script><p>ReLU 函数的优点在于当输入为正数的时候，不存在梯度消失的问题。同时，由于其线性关系，计算速度会快许多。ReLU 函数的缺点是当输入为负时，仍然会有梯度消失的情况发生。</p><p><strong>Leaky ReLU 函数</strong></p><p>公式为</p><script type="math/tex; mode=display">{\displaystyle g\left(z\right)={    \begin{cases}        z&z\geq 0\\        az&z<0    \end{cases}    }}</script><p>其中，$a$ 的取值在 $\left(0,1\right)$ 之间。</p><p>导函数为</p><script type="math/tex; mode=display">{\displaystyle g\left(z\right)={    \begin{cases}        1&z\geq 0\\        a&z<0    \end{cases}    }}</script><p>Leaky ReLU 函数解决了ReLU函数在输入为负的情况下产生的梯度消失问题。</p><p><strong>Sfotmax 函数</strong></p><p>softmax 函数通常被认为是多个 sigmoid 的组合。当神经网络用于二分类问题时，只需要 sigmoid 输出一个区间在 $[0,1]$ 的值即可。当用于多分类问题时，输出层的神经元数量和类别总数量是一样的，通过 softmax 函数输出每一个类别的概率。</p><script type="math/tex; mode=display">g\left(\mathbf{z}\right)_j=\frac{e^{z_j}}{\displaystyle \sum^K_{k=1}e^{z_k}} \qquad j=1,2,\dots,K</script><p>求导函数需要分情况讨论，当 $z_i=z_j$ 时</p><script type="math/tex; mode=display">\begin{aligned}    g'\left(z_i=z_j\right)&=\frac{e^{z_j}\sum^K_{k=1}e^{z_k}-\left(e^{z_j}\right)^2}{\left(\sum^K_{k=1}e^{z_k}\right)^2} \\    &= g\left(\mathbf{z}\right)_j-g\left(\mathbf{z}\right)_j^2 \\    &=g\left(\mathbf{z}\right)_j\left(1-g\left(\mathbf{z}\right)_j\right)\end{aligned}</script><p>当 $z_i\ne z_j$ 时</p><script type="math/tex; mode=display">\begin{aligned}    g'\left(z_i\ne z_j\right)&=\frac{0-e^{z_j}e^{z_i}}{\left(\sum^K_{k=1}e^{z_k}\right)^2} \\    &= -g\left(\mathbf{z}\right)_j\cdot g\left(\mathbf{z}\right)_i \\\end{aligned}</script><p>因此偏导数的最终表达式为</p><script type="math/tex; mode=display">{\displaystyle \frac{\partial g\left(\mathbf{z}\right)_j}{\partial z_i}={    \begin{cases}        g\left(\mathbf{z}\right)_j\left(1-g\left(\mathbf{z}\right)_j\right)&z_i=z_j\\        -g\left(\mathbf{z}\right)_j\cdot g\left(\mathbf{z}\right)_i&z_i\ne z_j    \end{cases}    }}</script><h3 id="2-2-损失函数"><a href="#2-2-损失函数" class="headerlink" title="2.2 损失函数"></a>2.2 损失函数</h3><p>损失函数用来评价模型的预测值和真实值不一样的程度，损失函数越好，通常模型的性能越好。不同的模型用的损失函数一般也不一样。</p><p>损失函数分为经验风险损失函数和结构风险损失函数。经验风险损失函数指预测结果和实际结果的差别，结构风险损失函数是指经验风险损失函数加上正则项。</p><p>平方损失函数</p><script type="math/tex; mode=display">L = \sum_k\frac{1}{2}\left(r_k-y_k\right)^2</script><p>均方误差是与单位高斯分布的输出相关联的交叉熵损失，也就是高斯分布最大似然函数的相反数。</p><p>交叉熵损失函数</p><script type="math/tex; mode=display">L = -\sum_kr_k\ln y_k</script><p>交叉熵函数实际上是多项式分布的最大似然函数加上一个负号，将最大值问题转换为损失值最小的问题，本质是一样的。在多分类问题中，输出是 softmax 函数，如同逻辑回归一样。</p><p>假设 softmax 函数的输入是 $z_i$，推导一下交叉熵损失函数的偏导数</p><script type="math/tex; mode=display">\frac{\partial L}{\partial z_i}=-\sum_k\frac{r_k}{g\left(\mathbf{z}\right)_k}\frac{\partial g\left(\mathbf{z}\right)_k}{\partial z_i}</script><p>分为 $k=i$ 与 $k\ne i$ 进行求和</p><script type="math/tex; mode=display">\begin{aligned}    \frac{\partial L}{\partial z_i}&=\sum_{k\ne i}\frac{r_k}{g\left(\mathbf{z}\right)_k}g\left(\mathbf{z}\right)_k\cdot g\left(\mathbf{z}\right)_i - \frac{r_i}{g\left(\mathbf{z}\right)_i}g\left(\mathbf{z}\right)_i\left(1-g\left(\mathbf{z}\right)_i\right)\\    &=\sum_{k\ne i}r_kg\left(\mathbf{z}\right)_i+r_ig\left(\mathbf{z}\right)_i-r_i\\    &=g\left(\mathbf{z}\right)_i\sum_k r_k- r_i\end{aligned}</script><p>多分类问题都采用 one-hot 编码，只有一个类别的标签值为 $1$，其余为 $0$，因此</p><script type="math/tex; mode=display">\sum_k r_k=1</script><p>最终得到</p><script type="math/tex; mode=display">\frac{\partial L}{\partial z_i}=g\left(\mathbf{z}\right)_i-r_i</script><h2 id="2-多层感知机模型"><a href="#2-多层感知机模型" class="headerlink" title="2. 多层感知机模型"></a>2. 多层感知机模型</h2><p>人工神经网络实际上就是多层感知机模型。感知机最大局限性在于它是一个线性分类器，无法处理非线性分类的问题，而多层感知机就可以解决这样的问题。多层感知器指的是由多层结构的感知器递阶组成的输入值向前传播的网络，也被称为前馈网络或正向传播网络。</p><p>多层感知机的思想就是一个函数不行，就使用多个简单函数共同作用。例如三层的感知机模型，由输入层、中间层和输出层组成。中间层的感知器通过权重与输入层的各单元（unit）相连接，通过阈值函数计算中间层各单元的输出值。中间层与输出层之间同样是通过权重相连接。</p><p>那么，如何确定各层之间的连接权重呢？单层感知器是通过误差修正学习确定输入层与输出层之间的连接权重的。初期的多层感知器使用随机数确定输入层与中间层之间的连接权重，只对中间层与输出层之间的连接权重进行误差修正学习。所以，就会出现输入数据虽然不同，但是中间层的输出值却相同，以至于无法准确分类的情况。直到误差反向传播算法的提出，多层感知机才被广泛应用。</p><h3 id="2-1-前向传播"><a href="#2-1-前向传播" class="headerlink" title="2.1 前向传播"></a>2.1 前向传播</h3><p>多层感知机每一层都有多个神经元，也称为单元。每个单元接受 $n$ 个输入并产生一个输出，并且不同的单元具有各自的权重和偏置。假设输入为 $\mathbf{x}=[x_1,x_2,\cdots,x_n]$，单元 $j$ 的权重为 $\mathbf{w}_j = [w_{j1},w_{j2},\cdots,w_{jn}]$，偏置为 $b_j$，则输出为</p><script type="math/tex; mode=display">z_j=\sum_i w_{ji}x_i+b_j</script><p>为了保证输出的值在区间 $[0,1]$ 之中，并且引入非线性变换，通常再将线性变换的输出值 $z_j$ 放入到激活函数当中。同时，这一层的输出可以作为下一层的输入，因此</p><script type="math/tex; mode=display">x_j=g\left(z_j\right)</script><p>我们再定义一层输出层</p><script type="math/tex; mode=display">z_k=\sum_j w_{kj}x_j+b_k</script><p>最终输出结果为</p><script type="math/tex; mode=display">y_k=g\left(z_k\right)</script><p>输出结果可以与标注结果进行比对，通过损失函数可以衡量结果的准确性。在这里使用平方误差作为损失函数。</p><script type="math/tex; mode=display">L=\sum_k\frac{1}{2}\left(r_k-y_k\right)^2</script><h3 id="2-2-反向传播"><a href="#2-2-反向传播" class="headerlink" title="2.2 反向传播"></a>2.2 反向传播</h3><p>一步一步求偏导数即可，首先是损失函数关于输出 $y_k$ 的导数</p><script type="math/tex; mode=display">\frac{\partial L}{\partial y_k}=-\left(r_k-y_k\right)</script><p>激活函数都使用 sigmoid 函数，因此</p><script type="math/tex; mode=display">\frac{\partial y_k}{\partial z_k}=g'\left(z\right)=g\left(z\right)\left(1-g\left(z\right)\right)=y_k\left(1-y_k\right)</script><p>同时</p><script type="math/tex; mode=display">\frac{\partial z_k}{\partial w_{kj}}=x_j</script><p>所以输出层权重的偏导数为</p><script type="math/tex; mode=display">\frac{\partial L}{\partial w_{kj}}=\frac{\partial L}{\partial y_k}\frac{\partial y_k}{\partial z_k}\frac{\partial z_k}{\partial w_{kj}}=-\left(r_k-y_k\right)y_k\left(1-y_k\right)x_j</script><p>类似的可以得到偏置</p><script type="math/tex; mode=display">\frac{\partial L}{\partial b_k}=\frac{\partial L}{\partial y_k}\frac{\partial y_k}{\partial z_k}\frac{\partial z_k}{\partial b_k}=-\left(r_k-y_k\right)y_k\left(1-y_k\right)</script><p>将偏导数再次向前转播</p><script type="math/tex; mode=display">\frac{\partial z_k}{\partial w_{ji}}=\frac{\partial z_k}{\partial x_j}\frac{\partial x_j}{\partial z_j}\frac{\partial z_j}{\partial w_{ji}}=w_{kj}x_j\left(1-x_j\right)x_i</script><p>同时，对于输入层权重的偏导数是所有输出单元的导数的加权求和</p><script type="math/tex; mode=display">\frac{\partial L}{\partial w_{ji}}=\sum_k\frac{\partial L}{\partial y_k}\frac{\partial y_k}{\partial z_k}\frac{\partial z_k}{\partial w_{ji}}</script><p>因此</p><script type="math/tex; mode=display">\frac{\partial L}{\partial w_{ji}}=\sum_k-\left(r_k-y_k\right)y_k\left(1-y_k\right)w_{kj}x_j\left(1-x_j\right)x_i</script><p>最终不同层权重的调节值为</p><script type="math/tex; mode=display">\triangle w_{kj}=\eta\left(r_k-y_k\right)y_k\left(1-y_k\right)x_j</script><script type="math/tex; mode=display">\triangle w_{ji}=\eta\sum_k\left[\left(r_k-y_k\right)y_k\left(1-y_k\right)w_{kj}\right]x_j\left(1-x_j\right)x_i</script><p>$\eta$ 为取值 $\left(0,1\right)$ 之间的学习率。</p><h3 id="2-3-矩阵求解"><a href="#2-3-矩阵求解" class="headerlink" title="2.3 矩阵求解"></a>2.3 矩阵求解</h3><p>用矩阵法表示两层神经网络并进行求解。最后一层的激活函数为 softmax，损失函数为交叉熵函数，可以用矩阵表示为</p><script type="math/tex; mode=display">L=-\mathbf{y}^T\log\mathrm{softmax}\left(W_2\sigma\left(W_1\mathbf{x}\right)\right)</script><p>其中 $\mathbf{y}$ 是除一个元素为 $1$ 外其元素为 $0$ 的 $m\times1$ 列向量，$W_2$ 为 $m\times p$ 矩阵，$W_1$ 为 $p\times n$ 矩阵，$\mathbf{x}$ 为 $n\times1$ 列向量，$\displaystyle\mathrm{softmax}\left(\mathbf{z}\right)=\frac{\exp\left(\mathbf{z}\right)}{\mathbf{1}^T\exp\left(\mathbf{z}\right)}$，其中 $\exp$ 表示逐元素求指数，$\mathbf{1}$ 表示值均为 $1$ 的列向量；$\ell$ 为标量；sigmoid 是逐元素函数 $\displaystyle \sigma\left(\mathbf{z}\right)=\frac{1}{1+\exp\left(-\mathbf{z}\right)}$。</p><p>定义 $\mathbf{z}_1=W_1\mathbf{x}$，$\mathbf{h}_1=\sigma\left(\mathbf{z}_1\right)$，$\mathbf{z}_2=W_2\mathbf{h}_1$，因此 $L=-\mathbf{y}^T\log\mathrm{softmax}\left(\mathbf{z}_2\right)$</p><p>在逻辑回归中已经求得 </p><script type="math/tex; mode=display">\frac {\partial L }{\partial \mathbf{z}_2}=\mathrm{softmax}\left(\mathbf{z}_2\right)-\mathbf y</script><p>使用复合法则</p><script type="math/tex; mode=display">\begin{aligned}    \mathrm{d}L&=\mathrm{tr}\left(\frac {\partial L }{\partial \mathbf{z}_2}^T \mathrm{d}\mathbf{z}_2\right)\\    &=\mathrm{tr}\left(\frac {\partial L }{\partial \mathbf{z}_2}^T \mathrm{d}\left(W_2\mathbf{h}_1\right)\right)\\    &=\mathrm{tr}\left(\frac {\partial L }{\partial \mathbf{z}_2}^T \mathrm{d}W_2\mathbf{h}_1\right)+\underbrace{\mathrm{tr}\left(\frac {\partial L }{\partial \mathbf{z}_2}^T W_2\mathrm{d}\mathbf{h}_1\right)}_{\mathrm{d}L_2}\\\end{aligned}</script><p>从第一项可以得到</p><script type="math/tex; mode=display">\frac {\partial L }{\partial W_2}=\frac {\partial L }{\partial \mathbf{z}_2}\mathbf{h}_1^T</script><p>从第二项可以得到</p><script type="math/tex; mode=display">\frac {\partial L }{\partial \mathbf{h}_1}=W_2^T\frac {\partial L }{\partial \mathbf{z}_2}</script><p>继续对后进行复合法则</p><script type="math/tex; mode=display">\begin{aligned}    \mathrm{d}L_2&=\mathrm{tr}\left(\frac {\partial L }{\partial \mathbf{h}_1}^T \mathrm{d}\mathbf{h}_1\right)\\    &=\mathrm{tr}\left(\frac {\partial L }{\partial \mathbf{h}_1}^T \mathrm{d}\sigma\left(\mathbf{z}_1\right)\right)\\    &=\mathrm{tr}\left(\frac {\partial L }{\partial \mathbf{h}_1}^T \sigma'\left(\mathbf{z}_1\right)\odot\mathrm{d}\mathbf{z}_1\right)\\    &=\mathrm{tr}\left(\left(\frac {\partial L }{\partial \mathbf{h}_1}\odot\sigma'\left(\mathbf{z}_1\right)\right)^T\mathrm{d}\mathbf{z}_1\right)\\\end{aligned}</script><p>可以得到</p><script type="math/tex; mode=display">\frac {\partial L }{\partial \mathbf{z}_1}=\frac {\partial L }{\partial \mathbf{h}_1}\odot\sigma'\left(\mathbf{z}_1\right)</script><p>最后再进行一个复合法则</p><script type="math/tex; mode=display">\begin{aligned}    \mathrm{d}L_2&=\mathrm{tr}\left(\frac {\partial L }{\partial \mathbf{z}_1}^T \mathrm{d}\mathbf{z}_1\right)\\    &=\mathrm{tr}\left(\frac {\partial L }{\partial \mathbf{z}_1}^T \mathrm{d}\left(W_1\mathbf{x}\right)\right)\\    &=\mathrm{tr}\left(\frac {\partial L }{\partial \mathbf{z}_1}^T \mathrm{d}W_1\mathbf{x}\right)\\\end{aligned}</script><p>可以得到</p><script type="math/tex; mode=display">\frac {\partial L }{\partial W_1}=\frac {\partial L }{\partial \mathbf{z}_1}\mathbf{x}^T</script><p>将以上式子联立即可得到</p><script type="math/tex; mode=display">\frac {\partial L }{\partial W_2}=\left(\mathrm{softmax}\left(\mathbf{z}_2\right)-\mathbf y\right)\mathbf{h}_1^T</script><script type="math/tex; mode=display">\frac {\partial L }{\partial W_1}=W_2^T\left(\mathrm{softmax}\left(\mathbf{z}_2\right)-\mathbf y\right)\odot\sigma'\left(\mathbf{z}_1\right)\mathbf{x}^T</script><h3 id="2-4-矩阵形式推广"><a href="#2-4-矩阵形式推广" class="headerlink" title="2.4 矩阵形式推广"></a>2.4 矩阵形式推广</h3><p>具有多个样本 $\{\left(\mathbf{x}_1,\mathbf{y}_1\right),\left(\mathbf{x}_2,\mathbf{y}_2\right),\dots,\left(\mathbf{x}_N,\mathbf{y}_N\right)\}$ 时，损失函数为</p><script type="math/tex; mode=display">L=-\sum_{i=1}^{N}\mathbf{y}_i^T\log\mathrm{softmax}\left(W_2\sigma\left(W_1\mathbf{x}_i+\mathbf{b}_1\right)+\mathbf{b}_2\right)</script><p>其中 $\mathbf{b}_1$ 为 $p\times 1$ 列向量，$\mathbf{b}_1$ 为 $m\times 1$ 列向量，其余定义同上</p><p>定义 $\mathbf{z}_{1,i}=W_1\mathbf{x}_i+\mathbf{b}_1$，$\mathbf{h}_{1,i}=\sigma\left(\mathbf{z}_{1,i}\right)$，$\mathbf{z}_{2,i}=W_2\mathbf{h}_{1,i}+\mathbf{b}_2$</p><p>如同上可以求出</p><script type="math/tex; mode=display">\frac {\partial L }{\partial \mathbf{z}_{2,i}}=\mathrm{softmax}\left(\mathbf{z}_{2,i}\right)-\mathbf y_i</script><p>使用复合法则</p><script type="math/tex; mode=display">\begin{aligned}    \mathrm{d}L&=\mathrm{tr}\left(\sum_{i=1}^{N}\frac {\partial L }{\partial \mathbf{z}_{2,i}}^T \mathrm{d}\mathbf{z}_{2,i}\right)\\    &=\mathrm{tr}\left(\sum_{i=1}^{N}\frac {\partial L }{\partial \mathbf{z}_{2,i}}^T \mathrm{d}\left(W_2\mathbf{h}_{1,i}+\mathbf{b}_2\right)\right)\\    &=\mathrm{tr}\left(\sum_{i=1}^{N}\frac {\partial L }{\partial \mathbf{z}_{2,i}}^T \mathrm{d}W_2\mathbf{h}_{1,i}\right)+\underbrace{\mathrm{tr}\left(\sum_{i=1}^{N}\frac {\partial L }{\partial \mathbf{z}_{2,i}}^T W_2\mathrm{d}\mathbf{h}_{1,i}\right)}_{\mathrm{d}L_2}+\mathrm{tr}\left(\sum_{i=1}^{N}\frac {\partial L }{\partial \mathbf{z}_{2,i}}^T \mathrm{d}\mathbf{b}_2\right)\\\end{aligned}</script><p>从第一项可以得到 $\displaystyle\frac {\partial L }{\partial W_{2}}=\sum_{i=1}^{N}\frac {\partial L }{\partial \mathbf{z}_{2,i}}\mathbf{h}_{1,i}^T$，从第二项可以得到 $\displaystyle\frac {\partial L }{\partial \mathbf{h}_{1,i}}=W_2^T\frac {\partial L }{\partial \mathbf{z}_{2,i}}$，从第三项可以得到 $\displaystyle\frac {\partial L }{\partial \mathbf{b}_{2}}=\sum_{i=1}^{N}\frac {\partial L }{\partial \mathbf{z}_{2,i}}$</p><p>对第二项继续使用复合法则</p><script type="math/tex; mode=display">\begin{aligned}    \mathrm{d}L_2&=\mathrm{tr}\left(\sum_{i=1}^{N}\frac {\partial L }{\partial \mathbf{h}_{1,i}}^T \mathrm{d}\mathbf{h}_{1,i}\right)\\    &=\mathrm{tr}\left(\sum_{i=1}^{N}\frac {\partial L }{\partial \mathbf{h}_1}^T \mathrm{d}\sigma\left(\mathbf{z}_{1,i}\right)\right)\\    &=\mathrm{tr}\left(\sum_{i=1}^{N}\frac {\partial L }{\partial \mathbf{h}_{1,i}}^T \sigma'\left(\mathbf{z}_{1,i}\right)\odot\mathrm{d}\mathbf{z}_{1,i}\right)\\    &=\mathrm{tr}\left(\sum_{i=1}^{N}\left(\frac {\partial L }{\partial \mathbf{h}_{1,i}}\odot\sigma'\left(\mathbf{z}_{1,i}\right)\right)^T\mathrm{d}\mathbf{z}_{1,i}\right)\\\end{aligned}</script><p>可以得到</p><script type="math/tex; mode=display">\frac {\partial L }{\partial \mathbf{z}_{1,i}}=\frac {\partial L }{\partial \mathbf{h}_{1,i}}\odot\sigma'\left(\mathbf{z}_{1,i}\right)</script><p>最后再进行一个复合法则</p><script type="math/tex; mode=display">\begin{aligned}    \mathrm{d}L_2&=\mathrm{tr}\left(\sum_{i=1}^{N}\frac {\partial L }{\partial \mathbf{z}_{1,i}}^T \mathrm{d}\mathbf{z}_{1,i}\right)\\    &=\mathrm{tr}\left(\sum_{i=1}^{N}\frac {\partial L }{\partial \mathbf{z}_{1,i}}^T \mathrm{d}\left(W_1\mathbf{x}_i+\mathbf{b}_1\right)\right)\\    &=\mathrm{tr}\left(\sum_{i=1}^{N}\frac {\partial L }{\partial \mathbf{z}_{1,i}}^T \mathrm{d}W_1\mathbf{x}_i\right)+\mathrm{tr}\left(\sum_{i=1}^{N}\frac {\partial L }{\partial \mathbf{z}_{1,i}}^T \mathrm{d}\mathbf{b}_1\right)\\\end{aligned}</script><p>可以得到</p><script type="math/tex; mode=display">\frac {\partial L }{\partial W_1}=\sum_{i=1}^{N}\frac {\partial L }{\partial \mathbf{z}_{1,i}}\mathbf{x}_i^T</script><script type="math/tex; mode=display">\frac {\partial L }{\partial \mathbf{b}_1}=\sum_{i=1}^{N}\frac {\partial L }{\partial \mathbf{z}_{1,i}}</script><p>将以上式子联立即可得到</p><script type="math/tex; mode=display">\frac {\partial L }{\partial W_2}=\sum_{i=1}^{N}\left(\mathrm{softmax}\left(\mathbf{z}_{2,i}\right)-\mathbf y_i\right)\mathbf{h}_{1,i}^T</script><script type="math/tex; mode=display">\displaystyle\frac {\partial L }{\partial \mathbf{b}_{2}}=\sum_{i=1}^{N}\left(\mathrm{softmax}\left(\mathbf{z}_{2,i}\right)-\mathbf y_i\right)</script><script type="math/tex; mode=display">\frac {\partial L }{\partial W_1}=\sum_{i=1}^{N}W_2^T\left(\mathrm{softmax}\left(\mathbf{z}_{2,i}\right)-\mathbf y_i\right)\odot\sigma(\mathbf{z}_{1,i})\odot(1-\sigma(\mathbf{z}_{1,i}))\mathbf{x}_i^T</script><script type="math/tex; mode=display">\frac {\partial L }{\partial \mathbf{b}_1}=\sum_{i=1}^{N}W_2^T\left(\mathrm{softmax}\left(\mathbf{z}_{2,i}\right)-\mathbf y_i\right)\odot\sigma(\mathbf{z}_{1,i})\odot(1-\sigma\left(\mathbf{z}_{1,i})\right)</script><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><blockquote><p><a href="https://en.wikipedia.org/wiki/Artificial_neural_network">1. Artificial neural network - Wikipedia</a><br><a href="https://en.wikipedia.org/wiki/Backpropagation">2. Backpropagation - Wikipedia</a><br><a href="https://zhuanlan.zhihu.com/p/80730031">3. 深度学习中【激活函数】存在的意义是什么？</a><br><a href="https://www.datalearner.com/blog/1051508750742453">4. 深度学习基础——激活函数以及什么时候该使用激活函数</a><br><a href="https://www.analyticsvidhya.com/blog/2020/01/fundamentals-deep-learning-activation-functions-when-to-use-them/">5. Fundamentals of Deep Learning – Activation Functions and When to Use Them?</a><br><a href="https://zhuanlan.zhihu.com/p/105722023">6. 一文详解Softmax函数 - zhihu</a><br><a href="https://zhuanlan.zhihu.com/p/58883095">7. 常见的损失函数(loss function)总结 - zhihu</a><br><a href="https://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes03-neuralnets.pdf\right">8. CS224n: Natural Language Processing with Deep Learning</a><br><a href="https://www.cs.toronto.edu/~urtasun/courses/CSC411_Fall16/10_nn1.pdf">9. CSC 411: Lecture 10: Neural Networks</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;h1 id=&quot;人工神经网络&quot;&gt;&lt;a href=&quot;#人工神经网络&quot; class=&quot;headerlink&quot; title=&quot;人工神经网络&quot;&gt;&lt;/a&gt;人工神经网络&lt;/h1&gt;&lt;h2 id=&quot;1-历史背景&quot;&gt;&lt;a href=&quot;#1-历史背景&quot;</summary>
      
    
    
    
    <category term="Deep learning" scheme="http://example.com/categories/Deep-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>11. Conditional Random Field</title>
    <link href="http://example.com/2022/06/06/MachineLearning/11.ConditionalRandomField/"/>
    <id>http://example.com/2022/06/06/MachineLearning/11.ConditionalRandomField/</id>
    <published>2022-06-05T16:00:00.000Z</published>
    <updated>2022-06-20T09:59:58.391Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><h1 id="条件随机场"><a href="#条件随机场" class="headerlink" title="条件随机场"></a>条件随机场</h1><h2 id="1-历史背景"><a href="#1-历史背景" class="headerlink" title="1. 历史背景"></a>1. 历史背景</h2><h3 id="1-1-分类模型"><a href="#1-1-分类模型" class="headerlink" title="1.1 分类模型"></a>1.1 分类模型</h3><p>我们对前面的知识进行总体的回顾。</p><p>首先，我们再次定义分类问题，在给定特定的特征向量 $\mathbf{x}=(x_1,x_2,\dots,x_K)$ 的情况下，预测单个类变量 $y$，从概率的角度来说，就是确定 $p(y|\mathbf{x})$ 的值。</p><p>最简单的方法，就是假设当类标签确定后，所有的特征都是相互独立的，也就是<strong>条件独立性假设</strong>，基于这种假设的分类器就是朴素贝叶斯分类器。虽然朴素贝叶斯最终计算的是 $p(y|\mathbf{x})$，但实际上是通过公式 $\displaystyle p(y|\mathbf{x})=\frac{p(y,\mathbf{x})}{p(\mathbf{x})}$ 得到的，由于分母的值都是一样的，最终 $\argmax$ 得到的结果实际上是基于以下形式的联合概率模型</p><script type="math/tex; mode=display">p(y,\mathbf{x})=p(y)\prod_{k=1}^Kp(x_k|y)</script><p>逻辑回归则是直接拟合条件概率的函数，它的假设依据是每个类别的对数概率 $\log p(y|\mathbf{x})$ 是 $\mathbf{x}$ 的线性函数，如果再加上一个归一化常数 $Z$，就得到条件概率分布</p><script type="math/tex; mode=display">p(y|\mathbf{x})=\frac{1}{Z(\mathbf{x})}\exp\left\{ {\lambda_y+\sum_{j=1}^K\lambda_{y,j}x_j}\right\}</script><p>其中，$Z(\mathbf{x})=\sum_y\exp\left\{ {\lambda_y+\sum_{j=1}^K\lambda_{y,j}x_j}\right\}$。从形式上来说很像是分母除以了一个 $p(\mathbf{x})$，但实际上 $Z(\mathbf{x})$ 并不是真正的 $p(\mathbf{x})$，逻辑回归并没有对 $\mathbf{x}$ 的分布构建模型。上面的公式中对每一个类别都需要一组向量进行权重表示，可以使用不同的表示法，只使用一个函数表示</p><script type="math/tex; mode=display">p(y|\mathbf{x})=\frac{1}{Z(\mathbf{x})}\exp\left\{\sum_{k=1}^K\lambda_kf_k(y,\mathbf{x})\right\}</script><h3 id="1-2-序列模型"><a href="#1-2-序列模型" class="headerlink" title="1.2 序列模型"></a>1.2 序列模型</h3><h2 id="2-问题引入"><a href="#2-问题引入" class="headerlink" title="2. 问题引入"></a>2. 问题引入</h2><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><blockquote><p><a href="https://www.zhihu.com/question/20446337/answer/2223156872">1. 机器学习“判定模型”和“生成模型”有什么区别？ - zhihu</a><br><a href="https://people.cs.umass.edu/~mccallum/papers/crf-tutorial.pdf">2. An Introduction to Conditional Random Fields for Relational Learning</a></p><p><a href="https://www.stats.ox.ac.uk/~caron/teaching/sb1b/lecturehmm.pdf">3. Lecture notes: Hidden Markov Models</a><br><a href="http://faculty.washington.edu/yenchic/18A_stat516/Lec9_HMM.pdf">4. Lecture 9: Hidden Markov Model</a><br><a href="https://www.intechopen.com/chapters/15369">5. History and Theoretical Basicsof Hidden Markov Models</a><br><a href="https://web.stanford.edu/~jurafsky/slp3/A.pdf">6. Hidden Markov Models</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;h1 id=&quot;条件随机场&quot;&gt;&lt;a href=&quot;#条件随机场&quot; class=&quot;headerlink&quot; title=&quot;条件随机场&quot;&gt;&lt;/a&gt;条件随机场&lt;/h1&gt;&lt;h2 id=&quot;1-历史背景&quot;&gt;&lt;a href=&quot;#1-历史背景&quot; cla</summary>
      
    
    
    
    <category term="Machine learning" scheme="http://example.com/categories/Machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>10. Hidden Markov Models</title>
    <link href="http://example.com/2022/04/22/MachineLearning/10.HiddenMarkovModels/"/>
    <id>http://example.com/2022/04/22/MachineLearning/10.HiddenMarkovModels/</id>
    <published>2022-04-21T16:00:00.000Z</published>
    <updated>2022-06-17T06:36:01.638Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><h1 id="隐马尔科夫模型"><a href="#隐马尔科夫模型" class="headerlink" title="隐马尔科夫模型"></a>隐马尔科夫模型</h1><h2 id="1-历史背景"><a href="#1-历史背景" class="headerlink" title="1. 历史背景"></a>1. 历史背景</h2><h2 id="2-问题引入"><a href="#2-问题引入" class="headerlink" title="2. 问题引入"></a>2. 问题引入</h2><p>假设有一个由多个可观测的样本组合的序列 $\mathbf{x}=(x_1,x_2,\dots,x_T)$，我们称之为观测序列。观测序列中的 $t$ 可以指时间、染色体或 DNA 上位点的索引或单词在句子中的位置，对于每个 $t\in1,2,\dots,T$，我们希望得到一个对应的感兴趣的隐藏状态变量 $z_t\in \mathcal{Z}$，其中 $\mathcal{Z}$ 是有限的集合，由 $z_t$ 组成的序列称为状态序列 $\mathbf{z}$。例如在词性标注中，观测序列就是文档中的 $t$ 个单词，状态序列就是每个单词对应的词性标签。</p><p>试想一下，如果用之前的机器学习方法可以怎么做？</p><p>可以用贝叶斯估计，最大似然条件概率 $\displaystyle\argmax \frac{p(X=\mathbf{x}|Z=\mathbf{z})p(Z=\mathbf{z})}{p(X=\mathbf{x})}$，显然单词间的组合太多了，需要的样本量之多几乎不可能做到，只能利用朴素贝叶斯的思想，假定 $(x_i,z_i)$ 与 $(x_j,z_j)$ 相互独立，这样我们就可以对每一个单词给出一个最大后验概率 $\displaystyle\hat{z}_t=\argmax p(X_t={x_t}|Z_t={z_t})p(Z_t={z_t})$。但这显然是不合理的，最终只能给出每个单词的所属词性最大概率的一个，但实际上每个单词与前后文相关，而在朴素贝叶斯中却无法体现出来。</p><p>为了考虑时序的概率情况，隐马尔科夫模型被提了出来。隐马尔科夫是在马尔科夫链的基础上提出来的，它们之间的不同之处就在于，马尔科夫链中的状态都是可观测的，而隐马尔科夫模型中存在不可观测的状态，但它们之间的根本原理都是无后效性，即未来状态只与当前的状态有关，即</p><script type="math/tex; mode=display">P(Z_{t+1}=z_{t+1}|Z_t=z_t,\cdots,Z_0=z_0)=P(Z_{t+1}=z_{t+1}|Z_t=z_{t})</script><p>隐马尔科夫模型中存在一个隐藏的马尔科夫链，也就是状态序列 $Z=(Z_0,Z_1,\dots,Z_T)$，状态集合为 $\mathcal{Z}$，对于任意两个状态 $i,j\in\mathcal{Z}$ 都可以给出一个转移概率 </p><script type="math/tex; mode=display">a_{ij}=P(Z_{t+1}=j|Z_{t}=i)\qquad i,j=1,2,\dots,N</script><p>因此最终可以得到一个状态转移概率矩阵</p><script type="math/tex; mode=display">A=\begin{bmatrix}    a_{11}&a_{12}&\cdots&a_{1N}\\    a_{21}&a_{22}&\cdots&a_{2N}\\    \vdots  \\    a_{N1}&a_{N2}&\cdots&a_{NN}\\\end{bmatrix}</script><p>同时存在另一个随机变量序列 $X=(X_0,X_2,\dots,X_T)$ 称为观测序列，它的取值来自于观测空间 $\mathcal{X}$，我们假设观测具有独立性，即任意时刻的观测只依赖于该时刻的马尔科夫链的状态，而与其他时刻观测及状态无关。因此，在给定时刻 $t$ 状态 $b_j$ 的情况下，都可以得到对应观测值 $k$ 的概率</p><script type="math/tex; mode=display">b_{j}(k)=P(X_t=k|Z_t=j)\qquad k=1,2,\dots,M;j=1,2,\dots,N</script><p>进一步地可以得到一个观测概率矩阵</p><script type="math/tex; mode=display">B=\begin{bmatrix}    b_{11}&b_{12}&\cdots&b_{1M}\\    b_{21}&b_{22}&\cdots&b_{2M}\\    \vdots  \\    b_{N1}&b_{N2}&\cdots&b_{NM}\\\end{bmatrix}</script><p>最后还需要确定初始状态概率 $\pi=(\pi_1,\pi_2,\dots,\pi_N)$，其中</p><script type="math/tex; mode=display">\pi_i=P(Z_1=i)\qquad i=1,2,\dots,N</script><p>通过初始状态概率向量 $\pi$、状态转移概率矩阵 $A$，观测概率矩阵 $B$ 就可以确定隐马尔科夫模型，它们也称为隐马尔科夫模型的三要素</p><script type="math/tex; mode=display">\lambda=(A,B,\pi)</script><p>可以发现，隐马尔科夫是基于无后效性和观测独立性假设提出来的。观测独立性假设，即任意时刻的观测结果只与该时刻的马尔科夫链的状态有关，与其他状态及观测无关</p><script type="math/tex; mode=display">P(X_t|X_T,Z_{T},\dots,X_1,Z_{1})=P(X_t|Z_t)</script><p>有了三要素，给定序列长度 $T$ 就可以生成一个对应的观测序列，而概率矩阵的拟合根据数据是否标记可采用不同的学习算法。最终想要隐马尔科夫模型进行预测需要解决一下三个问题</p><ol><li>学习问题。已知观测序列 $\mathbf{x}=(x_1,x_2,\dots,x_T)$，估计模型 $\lambda=(A,B,\pi)$ 参数，使得在该模型下的观测序列概率 $P(\mathbf{x}|\lambda)$ 最大，也就是用最大似然估计的方法来估计模型参数。</li><li>先验概率问题。给定模型 $\lambda=(A,B,\pi)$ 和观测序列 $\mathbf{x}=(x_1,x_2,\dots,x_T)$，计算在模型 $\lambda$ 下观测序列 $\mathbf{x}$ 出现的概率 $P(\mathbf{x}|\lambda)$，也就是先验概率。</li><li>预测问题。已知模型 $\lambda=(A,B,\pi)$ 和观测序列 $\mathbf{x}=(x_1,x_2,\dots,x_T)$，求在给定观测序列下条件概率 $P(\mathbf{z}|\mathbf{x})$ 最大的状态序列 $\mathbf{z}=(z_1,z_2,\dots,z_T)$。</li></ol><h2 id="3-先验概率计算算法"><a href="#3-先验概率计算算法" class="headerlink" title="3. 先验概率计算算法"></a>3. 先验概率计算算法</h2><p>给定模型 $\lambda=(A,B,\pi)$ 和观测序列 $\mathbf{x}=(x_1,x_2,\dots,x_T)$，计算观测序列 $\mathbf{x}$ 出现的概率 $P(\mathbf{x}|\lambda)$，也就是先验概率。</p><p>通过概率公式可以直接计算，通过列举所有长度为 $T$ 可能的状态序列 $\mathbf{z}=(z_1,z_2,\dots,z_T)$，求每个状态序列 $\mathbf{z}$ 与观测序列 $\mathbf{x}$ 的联合概率 $P(\mathbf{x}, \mathbf{z}|\lambda)$，然后对所有可能的状态序列求和，就可以得到先验概率 $P(\mathbf{x}|\lambda)$。</p><p>状态序列 $\mathbf{z}=(z_1,z_2,\dots,z_T)$ 的概率</p><script type="math/tex; mode=display">P(\mathbf{z}|\lambda)=\pi(z_1)\prod_{t=2}^T A(z_t|z_{t-1})</script><p>给定状态序列，观测序列的条件概率为</p><script type="math/tex; mode=display">p(\mathbf{x}|\mathbf{z},\lambda)=\prod_{t=1}^T B(x_t|z_{t})</script><p>因此状态序列 $\mathbf{z}$ 和观测序列 $\mathbf{x}$ 联合概率为</p><script type="math/tex; mode=display">P(\mathbf{x},\mathbf{z}|\lambda)=P(\mathbf{x}|\mathbf{z},\lambda)P(\mathbf{z}|\lambda)</script><p>然后对所有可能的状态序列 $\mathbf{z}$ 求和，得到观测序列 $\mathbf{x}$ 的概率为 </p><script type="math/tex; mode=display">\begin{aligned}    P(\mathbf{x}|\lambda)&=\sum_{\mathbf{z}}P(\mathbf{x}|\mathbf{z},\lambda)P(\mathbf{z}|\lambda)\\    &=\sum_{\mathbf{z}}\pi(z_1)\prod_{t=2}^TA(z_{t}|z_{t-1})\prod_{t=1}^TB(x_t|z_t)\end{aligned}</script><p>状态序列 $\mathbf{z}$ 的可能情况有 $N^T$ 种，因此时间复杂度为 $O(TN^T)$，通过动态规划的思想可以将算法进行优化。</p><h3 id="3-1-前向算法"><a href="#3-1-前向算法" class="headerlink" title="3.1 前向算法"></a>3.1 前向算法</h3><p>从上可以知道观测序列的概率</p><script type="math/tex; mode=display">P(\mathbf{x}|\lambda)=\sum_{\mathbf{z}}\pi(z_1)\prod_{t=2}^TA(z_{t}|z_{t-1})\prod_{t=1}^TB(x_t|z_t)</script><p>对于不同的状态序列都需要重新计算一遍该公式，但依照动态规划的思想，中间计算结果可以保存下来从而减少计算量，假设 $T=3$ 的情况下</p><script type="math/tex; mode=display">\begin{aligned}    P(\mathbf{x}|\lambda)&=\sum_{z_1,z_2,z_3}\pi(z_1)\prod_{t=2}^3A(z_{t}|z_{t-1})\prod_{t=1}^3B(x_t|z_t)\\    &=\sum_{z_3}\underbrace{B(x_3|z_3)\sum_{z_2}A(z_{3}|z_{2})\underbrace{B(x_2|z_2)\sum_{z_1}A(z_{2}|z_{1})\underbrace{\pi(z_1)B(x_1|z_1)}_{\alpha_1(z_1)}}_{\alpha_2(z_2)}}_{\alpha_3(z _3)}\end{aligned}</script><p>我们可以发现</p><script type="math/tex; mode=display">\alpha_2(z_2)=B(x_2|z_2)\sum_{z_1}A(z_{2}|z_{1})\alpha_1(z_1)</script><script type="math/tex; mode=display">\alpha_3(z_3)=B(x_3|z_3)\sum_{z_2}A(z_{3}|z_{2})\alpha_2(z_2)</script><p>以上 $\alpha_t(z_t)$ 就是每次重复计算的过程结果，如果保存下来的话就可以减少计算量，通过推导可以得到递推公式</p><script type="math/tex; mode=display">\alpha_{t+1}(i)=b_i(x_{t+1})\sum_{j=1}^Na_{ij}\alpha_t(i)\qquad i=1,2,\dots,N</script><p>$\alpha$ 实际上就是时刻 $t$ 给定部分观测序列 $x_1,x_2,\dots,x_t$ 且状态为 $i$ 的概率，称为前向概率</p><script type="math/tex; mode=display">\alpha_t(z_t=i)=P(x_1,x_2,\dots,x_t,z_t=i|\lambda)</script><p>如果状态空间的数量为 $4$，那么原本需要计算 $4<em>4</em>4$ 次，而上述算法只需要 $4<em>4+4</em>4$ 次，时间复杂度由 $O(TN^T)$ 降到了 $O(TN^2)$</p><p>有了递推公式之后，动态规划算法还需要初始化状态和终止条件，前向算法如下</p><ol><li>初始化状态 $\alpha_1(i)=\pi(i)b_i(x_1)$。</li><li>对于每一时刻 $t=1,2,\dots,T-1$ 计算<script type="math/tex; mode=display">\alpha_{t+1}(i)=b_i(x_{t+1})\sum_{j=1}^Na_{ij}\alpha_t(i)\qquad i=1,2,\dots,N</script></li><li>最终计算结束状态<script type="math/tex; mode=display">P(\mathbf{x}|\lambda)=\sum_{i=1}^N\alpha_{T}(i)</script></li></ol><h3 id="3-2-后向算法"><a href="#3-2-后向算法" class="headerlink" title="3.2 后向算法"></a>3.2 后向算法</h3><p>前向算法是从初始状态向结束状态进行计算，后向算法则是从结束状态向前得到递推公式，同样在假设 $T=3$ 的情况下</p><script type="math/tex; mode=display">\begin{aligned}    P(\mathbf{x}|\lambda)&=\sum_{z_1,z_2,z_3}\pi(z_1)\prod_{t=2}^3A(z_{t}|z_{t-1})\prod_{t=1}^3B(x_t|z_t)\\    &=\underbrace{\sum_{z_1}\pi(z_1)B(x_1|z_1)\underbrace{\sum_{z_2}A(z_{2}|z_{1})B(x_2|z_2)\underbrace{\sum_{z_3}A(z_{3}|z_{2})B(x_3|z_3)}_{\beta_2(z_2)}}_{\beta_1(z_1)}}_{\beta_0}\end{aligned}</script><p>对于 $t=2$ 时，根据观测独立性假设有 $P(x_3|z_3) = P(x_3|z_3,z_2)$，因此</p><script type="math/tex; mode=display">\begin{aligned}    \beta_2(z_2)&=\sum_{z_3}A(z_{3}|z_{2})B(x_3|z_3) \\    &=\sum_{z_3}P(z_{3}|z_{2})P(x_3|z_3)\\    &=\sum_{z_3}P(z_{3}|z_{2})P(x_3|z_3,z_2) \\    &=P(x_3|z_2)\end{aligned}</script><p>并且</p><script type="math/tex; mode=display">\begin{aligned}    \beta_1(z_1)&=\sum_{z_2}A(z_{2}|z_{1})B(x_2|z_2)\beta_2(z_2) \\    &=\sum_{z_2}P(z_{2}|z_{1})P(x_2|z_2)P(x_3|z_2)\\    &=P(x_2,x_3|z_1)\end{aligned}</script><p>通过归纳可以推导出递推公式</p><script type="math/tex; mode=display">\beta_{t}(i)=\sum_{j=1}^Na_{ij}b_j(x_{t+1})\beta_{t+1}(j)\qquad i=1,2,\dots,N</script><p>$\beta_t$ 即为在时刻 $t$ 状态为 $i$ 的条件下，从 $t+1$ 到 $T$ 的部分观测序列的概率，称为后向概率</p><script type="math/tex; mode=display">\beta_{t}(i)=P(x_{t+1},x_{t+2},\dots,x_{T}|z_t=i,\lambda)</script><p>后向算法同样需要确定初始化状态和终止条件</p><ol><li>初始化状态 $\beta_T(i)=1$。</li><li>对于每一时刻 $t=1,2,\dots,T-1$ 计算<script type="math/tex; mode=display">\beta_{t}(i)=\sum_{j=1}^Na_{ij}b_j(x_{t+1})\beta_{t+1}(j)\qquad i=1,2,\dots,N</script></li><li>最终计算结束状态<script type="math/tex; mode=display">P(\mathbf{x}|\lambda)=\sum_{i=1}^N\pi(i)b_i(x_{1})\beta_{1}(i)</script></li></ol><h3 id="3-3-概率计算"><a href="#3-3-概率计算" class="headerlink" title="3.3 概率计算"></a>3.3 概率计算</h3><p>有了前向概率和后向概率，可以直接计算一些概率值。</p><p>由前向概率和后向概率的定义可以知道</p><script type="math/tex; mode=display">\alpha_{t}(i)\beta_{t}(i) = P(z_t=i,\mathbf{x}|\lambda)</script><p>因此，在某一时刻 $t$，观测序列的概率 $P(\mathbf{x}|\lambda)$ 可以由该时刻的前向和后向概率计算</p><script type="math/tex; mode=display">P(\mathbf{x}|\lambda) = \sum_{i=1}^N\alpha_{t}(i)\beta_{t}(i)=\sum_{i=1}^N\sum_{j=1}^N\alpha_{t}(i)a_{ij}b_j(x_{t+1})\beta_{t+1}(j)</script><p>给定观测序列 $\mathbf{x}$ 和模型参数 $\lambda$，在时刻 $t$ 状态为 $i$ 的条件概率为</p><script type="math/tex; mode=display">\gamma_t(i)=P(z_t=i|\mathbf{x},\lambda)=\frac{P(z_t=i,\mathbf{x}|\lambda)}{P(\mathbf{x}|\lambda)}</script><p>因此，由前向和后向概率可得</p><script type="math/tex; mode=display">\gamma_t(i)=\frac{P(z_t=i,\mathbf{x}|\lambda)}{P(\mathbf{x}|\lambda)}=\frac{\alpha_{t}(i)\beta_{t}(i)}{\displaystyle \sum_{i=1}^N\alpha_{t}(i)\beta_{t}(i)}</script><p>给定观测序列 $\mathbf{x}$ 和模型参数 $\lambda$，在时刻 $t$ 状态为 $i$ 且时刻 $t+1$ 的状态为 $j$ 的条件概率为</p><script type="math/tex; mode=display">\xi_t(i,j)=P(z_t=i,z_{t+1}=j|\mathbf{x},\lambda)</script><p>通过前向后向概率计算</p><script type="math/tex; mode=display">\begin{aligned}    \xi_t(i,j)&=\frac{P(z_t=i,z_{t+1}=j,\mathbf{x}|\lambda)}{P(\mathbf{x}|\lambda)}\\    &= \frac{\alpha_{t}(i)a_{ij}b_j(x_{t+1})\beta_{t+1}(j)}{\displaystyle\sum_{i=1}^N\sum_{j=1}^N\alpha_{t}(i)a_{ij}b_j(x_{t+1})\beta_{t+1}(j)}\end{aligned}</script><p>给定观测序列 $\mathbf{x}$ ，状态 $i$ 出现的期望值</p><script type="math/tex; mode=display">\sum_{t=1}^T\gamma_t(i)</script><p>给定观测序列 $\mathbf{x}$ ，由状态 $i$ 转移的期望值</p><script type="math/tex; mode=display">\sum_{t=1}^{T-1}\gamma_t(i)</script><p>给定观测序列 $\mathbf{x}$ ，由状态 $i$ 转移的期望值</p><script type="math/tex; mode=display">\sum_{t=1}^{T-1}\xi_t(i,j)</script><h2 id="4-学习算法"><a href="#4-学习算法" class="headerlink" title="4. 学习算法"></a>4. 学习算法</h2><p>隐马尔科夫模型参数的学习可分为监督学习与无监督学习。</p><h3 id="4-1-监督学习"><a href="#4-1-监督学习" class="headerlink" title="4.1 监督学习"></a>4.1 监督学习</h3><p>在监督学习中，观测序列相当于特征值，状态序列相当于标注结果，假设给出数据集</p><script type="math/tex; mode=display">D=\{(\mathbf x_1,\mathbf z_1),(\mathbf x_2,\mathbf z_2),...,(\mathbf x_S,\mathbf z_S)\}</script><p>其中，观测序列 $\mathbf x_i$ 与状态序列 $\mathbf z_i$ 长度均为 $T$，因此可以通过最大似然估计来确定隐马尔科夫模型的参数。</p><p>假设样本中时刻 $t$ 处于状态 $i$ 时刻 $t+1$ 转移到状态 $j$ 的频数为 $c_{ij}$，状态空间的总数为 $N$，那么状态转移概率 $a_{ij}$ 的估计为 </p><script type="math/tex; mode=display">\hat a_{ij}=\frac{c_{ij}}{\displaystyle \sum_{j=1}^{N}c_{ij}}\qquad i,j=1,2,\dots,N</script><p>设样本状态 $j$ 并观测为 $k$ 的频数是 $d_{ij}$，观测空间的总数为 $M$，那么状态为 $j$ 时观测为 $k$ 的概率估计为</p><script type="math/tex; mode=display">\hat{b}_{j}(k)=\frac{d_{ij}}{\displaystyle \sum_{j=1}^{N}d_{ij}}\qquad k=1,2,\dots,M;j=1,2,\dots,N</script><p>初始状态概率 $\pi_i$ 的估计 $\hat{\pi}_i$ 为 $S$ 个样本中初始状态为 $i$ 的频率。</p><h3 id="4-2-无监督学习"><a href="#4-2-无监督学习" class="headerlink" title="4.2 无监督学习"></a>4.2 无监督学习</h3><p>如果给定训练数据只包含 $S$ 个长度为 $T$ 的观测序列，而缺少状态序列，那么状态序列可以视为不可观测的隐藏变量，隐马尔科夫模型实际上就是一个存在隐藏变量的概率模型</p><script type="math/tex; mode=display">P(\mathbf{x}|\lambda)=\sum_{\mathbf{z}}P(\mathbf{x}|\mathbf{z},\lambda)P(\mathbf{z}|\lambda)</script><p>我们可以使用 EM 算法求解上述概率模型，同时应用在 HMM 中的 EM 算法也称为 Baum-Welch 算法。由之前已经推导出，第 $k+1$ 次迭代只需要最大化下式即可。</p><script type="math/tex; mode=display">\argmax_{\lambda} \sum_{\mathbf{z}}{P}(\mathbf{z}|\mathbf{X}, \lambda_k)\ln{P}(\mathbf{X}, \mathbf{z}|\lambda)</script><p>由隐马尔科夫三要素可以得到完全数据的似然函数为</p><script type="math/tex; mode=display">P(\mathbf{x},\mathbf{z}|\lambda)=\pi(z_1)\prod_{t=2}^TA(z_{t}|z_{t-1})\prod_{t=1}^TB(x_t|z_t)</script><p>相应的对数似然函数为</p><script type="math/tex; mode=display">\ln P(\mathbf{x},\mathbf{z}|\lambda)=\ln{\pi(z_1)}+\sum_{t=2}^T\ln A(z_{t}|z_{t-1})+\sum_{t=1}^T\ln B(x_t|z_t)</script><p>E 步，得到在 $\lambda_k$ 下的上述对数似然函数的期望</p><script type="math/tex; mode=display">\begin{aligned}    E_{\mathbf{z|\mathbf{X},\lambda}}\{\ln\mathcal{P}(\mathbf{X}, \mathbf{z}|\theta)\} &= \sum_{\mathbf{z}}{P}(\mathbf{z}|\mathbf{X}, \lambda_k)\ln{P}(\mathbf{X}, \mathbf{z}|\lambda) \\    &= \sum_{\mathbf{z}}{P}(\mathbf{z}|\mathbf{X}, \lambda_k)\ln{\pi(z_1)}+\sum_{\mathbf{z}}\sum_{t=2}^T{P}(\mathbf{z}|\mathbf{X}, \lambda_k)\ln A(z_{t}|z_{t-1})\\    &+\sum_{\mathbf{z}}\sum_{t=1}^T{P}(\mathbf{z}|\mathbf{X}, \lambda_k)\ln B(x_t|z_t)\end{aligned}</script><p>M 步，最大化上述期望，可以分别最大化等式中的每一项。</p><p><strong>a. 更新初始状态概率 $\pi$</strong></p><script type="math/tex; mode=display">\begin{aligned}    F_1(\pi;\lambda_k) &= \sum_{\mathbf{z}}{P}(\mathbf{z}|\mathbf{X}, \lambda_k)\ln{\pi(z_1)} \\    &= \sum_{z_1}{P}(z_1|\mathbf{X}, \lambda_k)\ln{\pi(z_1)}\end{aligned}</script><p>对上式进行优化，$\pi$ 是唯一变量，同时满足约束条件 $\displaystyle\sum_{z_1=i}^N\pi(z_1)=1$，利用拉格朗日乘子法，得到拉格朗日函数</p><script type="math/tex; mode=display">\sum_{z_1}{P}(z_1|\mathbf{X}, \lambda_k)\ln{\pi(z_1)}+\theta\left(\displaystyle\sum_{z_1=i}^N\pi(z_1)-1\right)</script><p>对其求偏导数并令结果为 0</p><script type="math/tex; mode=display">\frac{\partial}{\partial\pi(z_1)}\left[\sum_{z_1}{P}(z_1|\mathbf{X}, \lambda_k)\ln{\pi(z_1)}+\theta\left(\displaystyle\sum_{z_1}\pi(z_1)-1\right)\right]</script><p>可得</p><script type="math/tex; mode=display">{P}(z_1|\mathbf{X}, \lambda_k)+\theta\pi(z_1)=0\qquad z_1=i=1,2,\dots,N</script><p>对上式进行合并</p><script type="math/tex; mode=display">\sum_{z_1}{P}(z_1|\mathbf{X}, \lambda_k)+\theta\sum_{z_1}\pi(z_1)=0</script><p>条件概率之和为 1，最终可得</p><script type="math/tex; mode=display">\theta=-1</script><p>因此求得</p><script type="math/tex; mode=display">\pi(z_1)={P}(z_1|\mathbf{X}, \lambda_k)</script><p>由前面已经得到</p><script type="math/tex; mode=display">{P}(z_t=i|\mathbf{X}, \lambda_k)=\gamma_t(i)=\frac{\alpha_{t}(i)\beta_{t}(i)}{\displaystyle \sum_{i=1}^N\alpha_{t}(i)\beta_{t}(i)}</script><p>因此解的</p><script type="math/tex; mode=display">\pi(z_1=i)=\gamma_1(i)</script><p><strong>b. 更新状态转移概率 $A$</strong></p><script type="math/tex; mode=display">\begin{aligned}    F_2(A;\lambda_k) &= \sum_{\mathbf{z}}\sum_{t=2}^T{P}(\mathbf{z}|\mathbf{X}, \lambda_k)\ln A(z_{t}|z_{t-1}) \\    &= \sum_{t=2}^T\sum_{i,j}{P}(z_{t-1}=i,z_t=j|\mathbf{X}, \lambda_k)\ln{A(z_{t}=j|z_{t-1}=i)}\end{aligned}</script><p>前面已经求得</p><script type="math/tex; mode=display">\xi_t(i,j)=P(z_t=i,z_{t+1}=j|\mathbf{x},\lambda)</script><p>因此</p><script type="math/tex; mode=display">F_2(A;\lambda_k)=\sum_{i,j}\sum_{t=2}^{T}\xi_{t-1}(i,j)\ln{a_{ij}}</script><p>如同计算初始状态概率，需要满足约束条件 $\displaystyle \sum_j a_{ij}=1$，通过拉格朗日乘子法得到拉格朗日函数</p><script type="math/tex; mode=display">\sum_{i,j}\sum_{t=2}^{T}\xi_{t-1}(i,j)\ln{a_{ij}}+\theta\left(\displaystyle\sum_{j=1}^Na_{ij}-1\right)</script><p>偏导数</p><script type="math/tex; mode=display">\sum_{t=2}^{T}\xi_{t-1}(i,j)+\theta a_{ij}=0 \qquad i,j=1,2,\dots,N</script><p>根据 $j$ 的所有取值合并上述公式</p><script type="math/tex; mode=display">\sum_j\sum_{t=2}^{T}\xi_{t-1}(i,j)+\theta=0 \qquad i=1,2,\dots,N</script><p>根据条件概率</p><script type="math/tex; mode=display">\begin{aligned}    \sum_j\sum_{t=2}^{T}\xi_{t-1}(i,j)&=\sum_j\sum_{t=2}^{T}P(z_{t-1}=i,z_{t}=j|\mathbf{x},\lambda)\\    &=\sum_{t=2}^{T}\sum_jP(z_{t-1}=i,z_{t}=j|\mathbf{x},\lambda)\\    &=\sum_{t=2}^{T}P(z_{t-1}=i|\mathbf{x},\lambda)\\    &=\sum_{t=2}^{T}\gamma_{t-1}(i)\\\end{aligned}</script><p>因此</p><script type="math/tex; mode=display">\theta=-\sum_{t=2}^{T}\gamma_{t-1}(i)</script><p>最终解得</p><script type="math/tex; mode=display">a_{ij}=\frac{\displaystyle\sum_{t=2}^{T}\xi_{t-1}(i,j)}{\displaystyle\sum_{t=2}^{T}\gamma_{t-1}(i)}</script><p><strong>c. 更新观测概率 $B$</strong></p><script type="math/tex; mode=display">\begin{aligned}    F_3(B;\lambda_k) &= \sum_{\mathbf{z}}\sum_{t=1}^T{P}(\mathbf{z}|\mathbf{X}, \lambda_k)\ln B(x_t|z_t) \\    &= \sum_{t=1}^T\sum_{z_t}{P}(z_t|\mathbf{X}, \lambda_k)\ln{B(x_t|z_t)}\\    &= \sum_{t=1}^T\sum_{j}\gamma_{t}(j)\ln{b_j(x_t))}\\\end{aligned}</script><p>同样具有约束条件 $\displaystyle \sum_{k=1}^Mb_j(k)=1$，因此拉格朗日函数</p><script type="math/tex; mode=display">\sum_{t=1}^T\sum_{j}\gamma_{t}(j)\ln{b_j(x_t)}+\theta\left(\sum_{k=1}^Mb_j(k)-1\right)</script><p>偏导数</p><script type="math/tex; mode=display">\sum_{t=1}^{T}\gamma_{t}(j)I(x_t=k)+\theta b_j(k)=0 \qquad k=1,2,\dots,M;j=1,2,\dots,N</script><p>合并 $k$ 个方程，解得 $\displaystyle\theta=-\sum_{t=1}^{T}\gamma_{t}(j)$，因此</p><script type="math/tex; mode=display">b_j(k)=\frac{\displaystyle \sum_{t=1}^{T}\gamma_{t}(j)I(x_t=k)}{\displaystyle \sum_{t=1}^{T}\gamma_{t}(j)}</script><blockquote><p>注意这里是对 $k$ 求和的结果为 $1$，同时 $b_j(k)$ 相当于固定变量，而 $b_j(x_t)$ 只有在 $x_t=k$ 的情况下才是同一个值，才具有偏导数。</p></blockquote><p><strong>总结</strong></p><h2 id="5-预测算法"><a href="#5-预测算法" class="headerlink" title="5. 预测算法"></a>5. 预测算法</h2><p>已知 $\mathbf{x},\lambda$，求得状态概率 $P(\mathbf{z}|\mathbf{x},\lambda)$ 即为预测问题。</p><p>隐马尔科夫模型预测分为近似算法和维特比算法，近似算法相当于路径规划中每走一步只选最短的路线，也就是贪婪算法，而维特比算法则相当于动态规划算法。</p><h3 id="5-1-近似算法"><a href="#5-1-近似算法" class="headerlink" title="5.1 近似算法"></a>5.1 近似算法</h3><p>由前已知</p><script type="math/tex; mode=display">\gamma_t(i)=P(z_t=i|\mathbf{x},\lambda)=\frac{\alpha_{t}(i)\beta_{t}(i)}{\displaystyle \sum_{i=1}^N\alpha_{t}(i)\beta_{t}(i)}</script><p>因此，在给定 $\mathbf{x},\lambda$ 的情况下，想要得到隐藏的状态序列，可以在每一时刻 $t$ 选择最大的条件概率 $P(z_t=i|\mathbf{x},\lambda)$ 对应的隐藏状态 $\hat{z}_t$，由于分母都一样，因此只需要考虑分子即可，即</p><script type="math/tex; mode=display">\hat{z}_t=\argmax_{i}(\alpha_{t}(i)\beta_{t}(i))</script><p>由此得到状态序列</p><script type="math/tex; mode=display">{\mathbf{\hat z}}=(\hat{z}_1,\hat{z}_2,\cdots,\hat{z}_t)</script><h3 id="5-2-维特比算法"><a href="#5-2-维特比算法" class="headerlink" title="5.2 维特比算法"></a>5.2 维特比算法</h3><p>近似算法相当于单步最优，要想得到全局最优的结果，则需要根据联合分布函数得到联合概率最大对应的状态，即</p><script type="math/tex; mode=display">{\mathbf{\hat z}}=\argmax_{\mathbf{z}} P(\mathbf{z},\mathbf{x}|\lambda)</script><p>我们分步求取当前的联合概率，假设</p><script type="math/tex; mode=display">\mathbf{z}_t = (z_1,z_2,\dots,z_t)</script><p>在最终预测的时候模型参数 $\lambda$ 确定，因此可以省略。联合概率为</p><script type="math/tex; mode=display">\begin{aligned}    P(\mathbf{z}_t,\mathbf{x}_t)&=P(\mathbf{z}_t,\mathbf{x}_t|\mathbf{z}_{t-1},\mathbf{x}_{t-1})P(\mathbf{z}_{t-1},\mathbf{x}_{t-1})\\    &=P(z_t,x_t|\mathbf{z}_{t-1},\mathbf{x}_{t-1})P(\mathbf{z}_{t-1},\mathbf{x}_{t-1})\\    &=P(x_t|z_t,\mathbf{z}_{t-1},\mathbf{x}_{t-1})P(z_t|\mathbf{z}_{t-1},\mathbf{x}_{t-1})P(\mathbf{z}_{t-1},\mathbf{x}_{t-1})\\    &=P(x_t|z_t)P(z_t|z_{t-1})P(\mathbf{z}_{t-1},\mathbf{x}_{t-1})\\    &=B(x_t|z_t)A(z_t|z_{t-1})P(\mathbf{z}_{t-1},\mathbf{x}_{t-1})\\\end{aligned}</script><p>定义</p><script type="math/tex; mode=display">d_t(i)=\max_{\mathbf{z}_{t-1}}P(\mathbf{z}_{t-1},z_t=i,\mathbf{x}_{t})</script><p>对于 $t=2,\dots,T$ 且 $i=1,\dots,N$，$d_t(i)$ 存在以下递归关系</p><script type="math/tex; mode=display">\begin{aligned}    d_t(i)&=\max_{\mathbf{z}_{t-1}}P(\mathbf{z}_{t-1},z_t=i,\mathbf{x}_{t})\\    &=\max_{\mathbf{z}_{t-1}}B(x_t|z_t=i)A(z_t=i|z_{t-1})P(\mathbf{z}_{t-1},\mathbf{x}_{t-1})\\    &=B(x_t|z_t=i)\max_{z_{t-1}}A(z_t=i|z_{t-1})\max_{\mathbf{z}_{t-2}}P(\mathbf{z}_{t-2},z_{t-1}=j,\mathbf{x}_{t-1})\\    &=B(x_t|z_t=i)\max_{z_{t-1}}A(z_t=i|z_{t-1})d_{t-1}(z_{t-1}=j)\\\end{aligned}</script><p>再确定初始化和结束条件，最后完善维特比算法</p><p><strong>维特比算法</strong></p><ol><li>初始化，对于 $i=1,2,\dots,N$，计算 $d_1(i)=\pi(i)b_i(x_1)$</li><li>对于 $t=2,3,\dots,T$，计算<script type="math/tex; mode=display">d_t(i)=b_i(x_t)\max_{j}d_{t-1}(j)a_{ji}\qquad i=1,2,\dots,N</script><script type="math/tex; mode=display">f_t(i)=\argmax_jd_{t-1}(j)a_{ji}\qquad i=1,2,\dots,N</script></li><li>最终得到 $\displaystyle z_T^*=\argmax_jd_T(j)$</li><li>回溯，对于 $t=T-1,\dots,1$<script type="math/tex; mode=display">z_{t}^*=f_{t+1}(z_{t+1}^*)</script></li><li>返回 $\mathbf z^<em>=(z^</em>_1, z^<em>_2, \dots, z^</em>_T)$</li></ol><p>当 $T$ 很大时，计算概率时的舍入误差可能会成为问题，为避免问题，可以使用对数计算</p><script type="math/tex; mode=display">d_t(i)=\max_{\mathbf{z}_{t-1}}\log P(\mathbf{z}_{t-1},z_t=i,\mathbf{x}_{t})</script><p>递推公式则为</p><script type="math/tex; mode=display">d_t(i)=\log b_i(x_t)+ \max_{j}\left\{d_{t-1}(j)+\log a_{ji}\right\}\qquad i=1,2,\dots,N</script><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><blockquote><p><a href="https://en.wikipedia.org/wiki/Hidden_Markov_model">1. Hidden Markov model - Wikipedia</a><br><a href="https://zhuanlan.zhihu.com/p/26811689">2. 隐马尔科夫模型（HMM）一基本模型与三个基本问题 - zhihu</a><br><a href="https://www.stats.ox.ac.uk/~caron/teaching/sb1b/lecturehmm.pdf">3. Lecture notes: Hidden Markov Models</a><br><a href="http://faculty.washington.edu/yenchic/18A_stat516/Lec9_HMM.pdf">4. Lecture 9: Hidden Markov Model</a><br><a href="https://www.intechopen.com/chapters/15369">5. History and Theoretical Basicsof Hidden Markov Models</a><br><a href="https://web.stanford.edu/~jurafsky/slp3/A.pdf">6. Hidden Markov Models</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;h1 id=&quot;隐马尔科夫模型&quot;&gt;&lt;a href=&quot;#隐马尔科夫模型&quot; class=&quot;headerlink&quot; title=&quot;隐马尔科夫模型&quot;&gt;&lt;/a&gt;隐马尔科夫模型&lt;/h1&gt;&lt;h2 id=&quot;1-历史背景&quot;&gt;&lt;a href=&quot;#1-历</summary>
      
    
    
    
    <category term="Machine learning" scheme="http://example.com/categories/Machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>8. Expectation Maximization</title>
    <link href="http://example.com/2022/04/08/MachineLearning/9.ExpectationMaximization/"/>
    <id>http://example.com/2022/04/08/MachineLearning/9.ExpectationMaximization/</id>
    <published>2022-04-07T16:00:00.000Z</published>
    <updated>2022-04-22T05:48:47.853Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><h1 id="期望最大化算法"><a href="#期望最大化算法" class="headerlink" title="期望最大化算法"></a>期望最大化算法</h1><h2 id="1-历史背景"><a href="#1-历史背景" class="headerlink" title="1. 历史背景"></a>1. 历史背景</h2><p>1955 年，Cedric Smith 提出一种用于估计等位基因频率的基因计数方法。H.O. Hartley 于 1958 年、Hartley and Hocking 于 1977 年分别提出类似的方法，都是解决不完整数据中的最大似然求解问题，它们均为 EM 算法的起源。</p><p>1971 年，Rolf Sundberg 在他的几篇论文中探讨了指数族变量不完整数据的最大似然理论，并给出了非常详细的处理。Sundberg 将后来称为 Sundberg 公式的公式归功于其老师 Per Martin-Löf 和 Anders Martin-Löf 以前的手稿。</p><p>1977 年，Arthur Dempster、Nan Laird 和 Donald Rubin Dempster-Laird-Rubin 论文概括了 EM 方法，并对更广泛的问题进行了收敛性分析。 Dempster-Laird-Rubin 的论文将 EM 方法确立为统计分析的重要工具。</p><p>1983 年，由于 Dempster-Laird-Rubin 算法的收敛性分析存在缺陷，C. F. Jeff Wu 发表了正确的收敛性分析。Wu 的证明确立了 EM 方法在指数族之外的收敛性，正如 Dempster-Laird-Rubin 所声称的那样。</p><h2 id="2-基础预备"><a href="#2-基础预备" class="headerlink" title="2. 基础预备"></a>2. 基础预备</h2><p>推导一些有关的不等式，部分是高中知识。</p><p><strong>定义1</strong>　如果 $f$ 是定义在区间 $I=[a,b]$ 上的实值函数，且 $\forall x_1,x_2\in I,\lambda\in I$，满足</p><script type="math/tex; mode=display">f(\lambda x_1+(1-\lambda)x_2)\le \lambda f(x_1)+(1-\lambda)f(x_2)</script><p>则称 $f$ 为凸函数，如果不等式是严格的，则 $f$ 是严格凸的。</p><blockquote><p>实际上 $\lambda x_1+(1-\lambda)x_2=\lambda(x_1-x_2)+x_2$，表示的是区间 $[x_1,x_2]$ 中的一个点。不等式的含义就是区间 $[x_1,x_2]$ 的函数值永远不会高于点 $(x_1,f(x_1))$ 到 $(x_2,f(x_2))$ 的直线。$x^2$ 是凸函数，与高数中定义相反。</p></blockquote><p><strong>定义2</strong>　如果 $f$ 是凹（严格凹）函数，则 $-f$ 是凸（严格凸）函数。</p><p><strong>定理1</strong>　如果 $f(x)$ 在 $[a,b]$ 上是两次可微的，并且 $f’’(x)\ge 0$，则 $f(x)$ 在 $[a,b]$ 是凸的。 </p><p>证明：假设 $x\le y\in[a,b]$，并且 $\lambda\in[0,1]$，让 $z=\lambda y+(1-\lambda)x$，根据定义 1 ，如果满足</p><script type="math/tex; mode=display">f(z)\le \lambda f(y)+(1-\lambda)f(x)</script><p>则可证明 $f$ 是凸函数，$f(z)$ 可以表示为</p><script type="math/tex; mode=display">f(z)=\lambda f(z)+(1-\lambda)f(z)</script><p>联立两个式子可以得到</p><script type="math/tex; mode=display">\lambda(f(y)-f(z))\ge(1-\lambda)(f(z)-f(x))</script><p>根据中值定理，存在 $z\le t\le y$</p><script type="math/tex; mode=display">f(y)-f(z)=f'(t)(y-z)</script><p>同理，存在 $x\le s\le z$</p><script type="math/tex; mode=display">f(z)-f(x)=f'(s)(z-x)</script><p>由于 $f’’(x)\ge 0$，并且 $t\le s$，可知 $f’(t)\le f’(s)$</p><p>根据 $z=\lambda y+(1-\lambda)x$，可以得到</p><script type="math/tex; mode=display">(1-\lambda)(z-x)=\lambda(y-z)</script><p>最终，联立以上各式</p><script type="math/tex; mode=display">\begin{aligned}    \lambda(f(y)-f(z))&=\lambda f'(t)(y-z) \\    &\ge f'(s)\lambda(y-z)\\    &=f'(s)(1-\lambda)(z-x)\\    &=(1-\lambda)(f(z)-f(x))\end{aligned}</script><p><strong>推论1</strong>　$-\ln(x)$ 是在区间 $(0,\infty)$ 是严格凸函数。</p><p>证明：$f(x)=-\ln(x)$，由于 $\displaystyle f’’(x)=\frac{1}{x^2}&gt;0$，因此 $-\ln(x)$ 是在区间 $(0,\infty)$ 是严格凸函数。</p><blockquote><p>将上述凸性的概念扩展到 $n$ 个点，得到的就是 Jensen 不等式。</p></blockquote><p><strong>定理2（Jensen 不等式）</strong>　如果 $f$ 是区间 $I$ 上的凸函数，如果 $x_1,x_2,\dots,x_n\in I$ ， $\lambda_1,\lambda_2,\dots,\lambda_n \ge 0$ 且 $\displaystyle\sum_{i=1}^n \lambda_i = 1$，则有</p><script type="math/tex; mode=display">f\left(\sum_{i=1}^n \lambda_ix_i\right)\le \sum_{i=1}^n \lambda_if(x_i)</script><p>证明：$n=2$ 对应于凸性的定义，为了证明这对所有自然数都是正确的，我们通归纳来证明，假设定理对某些 $n$ 成立，则</p><script type="math/tex; mode=display">\begin{aligned}    f\left(\sum_{i=1}^{n+1} \lambda_ix_i\right) &=f\left(\lambda_{n+1}x_{n+1}+\sum_{i=1}^n \lambda_ix_i\right)\\    &=f\left(\lambda_{n+1}x_{n+1}+(1-\lambda_{n+1})\frac{1}{1-\lambda_{n+1}}\sum_{i=1}^n \lambda_ix_i\right)\\    &\le \lambda_{n+1}f(x_{n+1})+(1-\lambda_{n+1})f\left(\frac{1}{1-\lambda_{n+1}}\sum_{i=1}^n \lambda_ix_i\right) \\    &= \lambda_{n+1}f(x_{n+1})+(1-\lambda_{n+1})f\left(\sum_{i=1}^n \frac{\lambda_i}{1-\lambda_{n+1}}x_i\right) \\    &\le \lambda_{n+1}f(x_{n+1})+(1-\lambda_{n+1})\sum_{i=1}^n \frac{\lambda_i}{1-\lambda_{n+1}}f(x_i) \\    &= \lambda_{n+1}f(x_{n+1})+\sum_{i=1}^n \lambda_if(x_i)\\    &=\sum_{i=1}^{n+1} \lambda_if(x_i)\end{aligned}</script><blockquote><p>由于 $\ln$ 是凹函数，因此通过 Jensen 不等式可以推导出</p><script type="math/tex; mode=display">\ln\sum_{i=1}^n \lambda_ix_i \ge \sum_{i=1}^n \lambda_i\ln(x_i)</script><p>这个公式可以得到一个和的对数的下限，可用于推导 EM 算法。</p><p>Jensen不等式可以证明算术平均值大于等于几何平均值，即</p></blockquote><p><strong>推论2</strong>　</p><script type="math/tex; mode=display">\frac{1}{n}\sum_{i=1}^n x_i\ge \sqrt[n]{x_1x_2\dots x_n}</script><p>证明： 如果 $x_1,x_2,\dots,x_n\ge0$，由于 $\ln$ 是凹函数，可以得到</p><script type="math/tex; mode=display">\begin{aligned}    \ln\left(\frac{1}{n}\sum_{i=1}^{n}x_i\right) &\ge \sum_{i=1}^{n}\frac{1}{n} \ln(x_i) \\    &= \frac{1}{n}\ln(x_1x_2\dots x_n) \\    &=\ln(x_1x_2\dots x_n)^{\frac{1}{n}}\end{aligned}</script><p>因此，有</p><script type="math/tex; mode=display">\frac{1}{n}\sum_{i=1}^n x_i\ge \sqrt[n]{x_1x_2\dots x_n}</script><h2 id="3-算法推导"><a href="#3-算法推导" class="headerlink" title="3. 算法推导"></a>3. 算法推导</h2><p>在概率模型当中，已知样本观察数据，想要得到模型参数，一般使用极大似然估计。</p><p>极大似然估计需要对似然函数的所有未知值、参数求导，并同时求解得到的的方程。而在某些统计模型当中，除了已知的观察数据之外，还有未知的潜在变量。话句话说，也就是模型中缺失了部分的观察变量，而缺失的观察变量和已知的之间存在某种概率关系。如果用极大似然算法，它们之间的导数是一组互锁的方程，其中参数的解需要潜在变量的值，反之亦然，但是将一组方程带入另一组方程会产生一个不可解的方程组。</p><p>EM 算法就是求解上述问题的一种迭代方法，主要思想是简单地为两组未知数中的一组选择任意值，使用它们来估计第二组，然后使用这些新值来找到对第一组的更好估计，然后在两者之间保持交替，直到结果值都收敛到固定点。</p><p>EM 算法是一种通用的算法，无论是离散还是连续，二项式分布或高斯分布，都可以用来求解。</p><p>假设 $\mathbf{X}$ 表示观测随机变量的一组结果，在概率模型参数 $\theta$ 下的条件概率为 $\mathcal{P}(\mathbf{X}|\theta)$，找到最大 $\theta$ 使其概率最大的过程就称为最大似然估计。为了估计 $\theta$，通常引入对数似然函数</p><script type="math/tex; mode=display">L(\theta)=\ln \mathcal{P}(\mathbf{X}|\theta)</script><p>如果概率模型中存在一组隐藏变量 $\mathbf{Z}$，它的结果无法通过观测得到，但其结果会对观测变量 $\mathbf{X}$ 产生影响。$\mathbf{X}$ 和 $\mathbf{Z}$ 一起称为完全数据，观测变量 $\mathbf{X}$ 则又称为不完全数据。假定隐藏变量 $\mathbf{Z}$ 的一组取值为 $\mathbf{z}$，则观测结果 $\mathbf{X}$ 是基于 $\mathbf{z}$ 和参数 $\theta$ 的条件之下产生的，</p><script type="math/tex; mode=display">\mathcal{P}(\mathbf{X}|\mathbf{z}, \theta)=\frac{\mathcal{P}(\mathbf{X}, \mathbf{z}, \theta)}{\mathcal{P}(\mathbf{z}, \theta)}</script><p>而隐藏变量同样是基于 $\theta$ 产生的，</p><script type="math/tex; mode=display">\mathcal{P}(\mathbf{z}|\theta)=\frac{\mathcal{P}(\mathbf{z}, \theta)}{\mathcal{P}(\theta)}</script><p>将两个条件概率相乘，并将隐藏变量所有可能的取值进行累加（隐藏变量的取值似乎都是可数的），就可以得到 $\mathbf{X}$ 在 $\theta$ 下的条件概率，</p><script type="math/tex; mode=display">\sum_{\mathbf{z}}\mathcal{P}(\mathbf{X}|\mathbf{z}, \theta)\mathcal{P}(\mathbf{z}|\theta)=\sum_{\mathbf{z}}\frac{\mathcal{P}(\mathbf{X}, \mathbf{z}, \theta)}{\mathcal{P}(\theta)}=\mathcal{P}(\mathbf{X}|\theta)</script><p>因此将对数似然函数改写为</p><script type="math/tex; mode=display">L(\theta) = \ln\mathcal{P}(\mathbf{X}|\theta)=\ln\sum_{\mathbf{z}}\mathcal{P}(\mathbf{X}|\mathbf{z}, \theta)\mathcal{P}(\mathbf{z}|\theta)</script><p>最终是求 $\theta$ 使上式结果最大化，该问题没有解析解，只能通过迭代的方法求解。假设第 $t$ 次迭代后 $\theta$ 的估计值为 $\theta_t$，我们希望新估计值 $\theta$ 能使 $L(\theta)$ 增加，考虑两者差值</p><script type="math/tex; mode=display">L(\theta)-L(\theta_t)=\ln\sum_{\mathbf{z}}\mathcal{P}(\mathbf{X}|\mathbf{z}, \theta)\mathcal{P}(\mathbf{z}|\theta) - \ln\mathcal{P}(\mathbf{X}|\theta_t)</script><p>这是一个变量为 $\theta$ 的函数，$\theta_t$ 相当于常数，$\sum$ 在 $\ln$ 里面是无法对求解函数极值的，因此利用上述 Jensen 不等式</p><script type="math/tex; mode=display">\ln\sum_{i=1}^n \lambda_ix_i \ge \sum_{i=1}^n \lambda_i\ln(x_i)</script><p>为了提出 $\lambda_i$，需要凑出 $\displaystyle\sum_{i=1}^n \lambda_i = 1$，可以利用条件概率 $\mathcal{P}(\mathbf{z}|\mathbf{X}, \theta_t)$，我们有 $\mathcal{P}(\mathbf{z}|\mathbf{X}, \theta_t)\ge 0$ 且 $\displaystyle\sum_\mathbf{z}\mathcal{P}(\mathbf{z}|\mathbf{X}, \theta_t)= 1$，因此</p><script type="math/tex; mode=display">\begin{aligned}    L(\theta)-L(\theta_t)&=\ln\sum_{\mathbf{z}}\mathcal{P}(\mathbf{X}|\mathbf{z}, \theta)\mathcal{P}(\mathbf{z}|\theta) - \ln\mathcal{P}(\mathbf{X}|\theta_t)\\    &=\ln\sum_{\mathbf{z}}\mathcal{P}(\mathbf{X}|\mathbf{z}, \theta)\mathcal{P}(\mathbf{z}|\theta)\frac{\mathcal{P}(\mathbf{z}|\mathbf{X}, \theta_t)}{\mathcal{P}(\mathbf{z}|\mathbf{X}, \theta_t)} - \ln\mathcal{P}(\mathbf{X}|\theta_t)\\    &\ge\sum_{\mathbf{z}}\mathcal{P}(\mathbf{z}|\mathbf{X}, \theta_t)\ln\frac{\mathcal{P}(\mathbf{X}|\mathbf{z}, \theta)\mathcal{P}(\mathbf{z}|\theta)}{\mathcal{P}(\mathbf{z}|\mathbf{X}, \theta_t)\mathcal{P}(\mathbf{X}|\theta_t)}\end{aligned}</script><p>令</p><script type="math/tex; mode=display">l(\theta|\theta_t)=L(\theta_t)+\sum_{\mathbf{z}}\mathcal{P}(\mathbf{z}|\mathbf{X}, \theta_t)\ln\frac{\mathcal{P}(\mathbf{X}|\mathbf{z}, \theta)\mathcal{P}(\mathbf{z}|\theta)}{\mathcal{P}(\mathbf{z}|\mathbf{X}, \theta_t)\mathcal{P}(\mathbf{X}|\theta_t)}</script><p>则有</p><script type="math/tex; mode=display">L(\theta)\ge l(\theta|\theta_t)</script><p>因此我们有一个函数 $l(\theta|\theta_t)$ 来作为对数似然函数 $L(\theta)$ 的下界，并且当 $\theta=\theta_t$ 时，可以推导出</p><script type="math/tex; mode=display">l(\theta_t|\theta_t)=L(\theta_t)</script><p>因此，任何可以使 $l(\theta|\theta_t)$ 增大的 $\theta$，也可以使 $L(\theta)$ 增大，为了使 $L(\theta)$ 尽可能大的增长，选择 $\theta_{t+1}$ 使 $l(\theta|\theta_t)$ 达到极大值，只与 $\theta_t$ 有关的项为常数项，即</p><script type="math/tex; mode=display">\begin{aligned}    \theta_{t+1}&=\argmax_{\theta} l(\theta|\theta_t)\\    &=\argmax_{\theta} \sum_{\mathbf{z}}\mathcal{P}(\mathbf{z}|\mathbf{X}, \theta_t)\ln\mathcal{P}(\mathbf{X}|\mathbf{z}, \theta)\mathcal{P}(\mathbf{z}|\theta)\\    &=\argmax_{\theta} \sum_{\mathbf{z}}\mathcal{P}(\mathbf{z}|\mathbf{X}, \theta_t)\ln\frac{\mathcal{P}(\mathbf{X}, \mathbf{z}, \theta)}{\mathcal{P}(\mathbf{z}, \theta)}\frac{\mathcal{P}(\mathbf{z}, \theta)}{\mathcal{P}(\theta)}\\    &=\argmax_{\theta} \sum_{\mathbf{z}}\mathcal{P}(\mathbf{z}|\mathbf{X}, \theta_t)\ln\mathcal{P}(\mathbf{X}, \mathbf{z}|\theta)\\    &=\argmax_{\theta} E_{\mathbf{z|\mathbf{X},\theta_t}}\{\ln\mathcal{P}(\mathbf{X}, \mathbf{z}|\theta)\}\\\end{aligned}</script><blockquote><p>最后的一项是完全数据的对数似然函数 $\ln\mathcal{P}(\mathbf{X}, \mathbf{z}|\theta)$ 关于给定观测数据 $\mathbf{X}$ 和当前参数 $\theta_t$ 下对未观测数据 $\mathbf{z}$ 的条件概率分布 $\mathcal{P}(\mathbf{z}|\mathbf{X}, \theta_t)$ 的期望。</p></blockquote><p>总结如下</p><p><strong>EM 算法</strong></p><ul><li><strong>输入</strong>：观测变量 $\mathbf{X}$</li><li><strong>输出</strong>：模型参数 $\theta$</li><li><strong>步骤</strong>：<ol><li>初始化模型参数为 $\theta_0$</li><li>（E 步）假设第 $t$ 次迭代参数 $\theta$ 的估计值为 $\theta_t$，在给定观测数据 $\mathbf{X}$ 和当前参数 $\theta_t$，求得完全数据的对数似然函数关于未观测数据 $\mathbf{z}$ 的概率分布的期望 $\displaystyle \sum_{\mathbf{z}}\mathcal{P}(\mathbf{z}|\mathbf{X}, \theta_t)\ln\mathcal{P}(\mathbf{X}, \mathbf{z}|\theta)$，记为 $Q(\theta,\theta_t)$。</li><li>（M 步）求使 $l(\theta|\theta_t)$ 最大化的 $\theta$，使 $\theta_{t+1}=\argmax_{\theta} Q(\theta,\theta_t)$。</li><li>重复 E 步与 M 步。</li><li>如果满足 $|\theta_{t+1}-\theta_t|&lt;\varepsilon_1$ 或 $|Q(\theta_{t+1},\theta_t)-Q(\theta_t,\theta_t)|&lt;\varepsilon_1$，则停止迭代。</li></ol></li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><blockquote><p><a href="https://www.lri.fr/~sebag/COURS/EM_algorithm.pdf">1. The Expectation Maximization Algorithm: A short tutorial</a><br><a href="https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm">2. Expectation–maximization algorithm - Wikipedia</a><br><a href="https://engineering.purdue.edu/ChanGroup/ECE645Notes/StudentLecture10.pdf">3. Lecture 10: Expectation-Maximization Algorithm</a><br><a href="https://www.cnblogs.com/pinard/p/6912636.html">4. EM算法原理总结 - 刘建平</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;h1 id=&quot;期望最大化算法&quot;&gt;&lt;a href=&quot;#期望最大化算法&quot; class=&quot;headerlink&quot; title=&quot;期望最大化算法&quot;&gt;&lt;/a&gt;期望最大化算法&lt;/h1&gt;&lt;h2 id=&quot;1-历史背景&quot;&gt;&lt;a href=&quot;#1-历</summary>
      
    
    
    
    <category term="Machine learning" scheme="http://example.com/categories/Machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>1. Linear Equation</title>
    <link href="http://example.com/2022/04/02/LinearAlgebra/1.Linear%20Equation/"/>
    <id>http://example.com/2022/04/02/LinearAlgebra/1.Linear%20Equation/</id>
    <published>2022-04-01T16:00:00.000Z</published>
    <updated>2022-04-08T02:40:12.329Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><h1 id="线性方程组"><a href="#线性方程组" class="headerlink" title="线性方程组"></a>线性方程组</h1><h2 id="1-线性方程组"><a href="#1-线性方程组" class="headerlink" title="1. 线性方程组"></a>1. 线性方程组</h2><p><strong>线性方程</strong>形如</p><script type="math/tex; mode=display">a_1x_1+a_2x_2+\dots+a_nx_n=b</script><p>$x_1,x_2,\dots,x_n$ 为变量，$a_1,a_2,\dots,a_n$ 为系数，系数与 $b$ 为实数或复数，通常为已知数，下标 $n$ 可以是任意正整数。</p><p><strong>线性方程组</strong>是由一个或多个有相同变量的线性方程组成的。</p><p>方程组所有可能的解的集合称为线性方程组的<strong>解集</strong>。若两个线性方程组有相同的解集 ，则这两个线性方程组称为<strong>等价</strong>的。</p><p>方程组解的情况可以概括为有唯一解、有无穷多解、无解。</p><p>当方程组有解时称该方程组为 <strong>相容的</strong>，如果无解则称为 <strong>不相容的</strong>。</p><blockquote><p>当方程组有两个变量时，在平面空间一个线性方程就代表一条直线，当两条直线相交时有解，平行时则表示无解，重合时则有无穷多解。三个变量时则是三维空间中的一个平面，当三个平面没有共同交点时无解。</p></blockquote><p>方程组的系数可以由一个<strong>矩阵</strong>表示，称为<strong>系数矩阵</strong>。如果将常数列添加到系数矩阵中则称其为<strong>增广矩阵</strong>。矩阵的维数表示其行数与列数，例如 $m\times n$ 矩阵有 $m$ 行 $n$ 列。</p><p>求解线性方程组的一般思路是将方程组用一个更容易解的等价方程组代替，变化的过程使用行消去法，可以保证变换后的方程组与之前的方程组解一致。这种操作矩阵的方法不仅仅适用于求解方程组，更适用于任意矩阵。</p><p><strong>定义1</strong>　一个矩阵称为阶梯形矩阵，若它有以下三个性质：</p><ol><li>每一非零行都在每一零行之上.</li><li>某一行的先导元素所在的列位于前一行先导元素的右边.</li><li>某一先导元素所在列下方元素都是零.</li></ol><p>如有以下性质，则称为简化阶梯形矩阵</p><ol><li>每一非零行先导元素是 1.</li><li>每一先导元素 1 是该元素所在列唯一的非零元素.</li></ol><p><strong>定理1</strong>　(简化阶梯形矩阵的唯一性〉 每个矩阵行等价于唯一的简化阶梯形矩阵。</p><p>因简化阶梯形矩阵是唯一的，故当给定矩阵化为任何一个阶梯形时，先导元素总是在相同的位置上。这些先导元素对应于简化阶梯形中的先导元素1。</p><p>行化简算法，也就是矩阵形式的消元法，分为向前步骤和向后步骤。向前步骤将增广矩阵化为阶梯形矩阵，向后步骤将阶梯形矩阵化为简化阶梯形矩阵。</p><p><strong>定义2</strong>　矩阵中的主元位置是 A 中对应于它的阶梯形中先导元素 1 的位置。主元列是 A 中含有主元位置的列。</p><p>在方程组的增广矩阵中，主元列对应的变量为基本变量，其他变量称为自由变量。</p><h2 id="2-向量方程"><a href="#2-向量方程" class="headerlink" title="2. 向量方程"></a>2. 向量方程</h2><p>仅含一列的矩阵称为<strong>列向量</strong>，或简称向量</p><script type="math/tex; mode=display">\mathbf{w}=\begin{bmatrix}   w_1 \\   \vdots  \\   w_n \\\end{bmatrix}</script><p>其中 $w_i$ 为任意实数， 所有 $n$ 个元素的向量集记为 $\mathbb{R}^n$，$\mathbb{R}$ 表示向量中的元素是实数，指数 $n$ 表示每个向量中包含 $n$ 个元素。</p><p>所有元素都是零的向量称为<strong>零向量</strong>，用 $\mathbf{0}$ 表示（$\mathbf{0}$ 中元素的个数可由上下文确定）。</p><p>$\mathbb{R}^n$ 中两个向量相等当且仅当其对应元素相等。向量的基础运算有向量加法与向量乘法（数乘），向量减法可以视作两种运算的结合，例如 $\mathbf{u}-\mathbf{v}=\mathbf{u}+(-1)\mathbf{v}$。</p><p>给定 $\mathbb{R}^n$ 中向量 $\mathbf{v}_1,\mathbf{v}_2,\dots,\mathbf{v}_p$ 和标量 $c_1,c_2,\dots,c_p$，向量</p><script type="math/tex; mode=display">\mathbf{y}=c_1\mathbf{v}_1+\cdots+c_p\mathbf{v}_p</script><p>称为向量 $\mathbf{v}_1,\mathbf{v}_2,\dots,\mathbf{v}_p$ 以 $c_1,c_2,\dots,c_p$ 为权的<strong>线性组合</strong>，线性组合中的权可以为任意实数。 </p><blockquote><p>向量 $\mathbf{u}=3\mathbf{v}_1-2\mathbf{v}_2$，可以解释为经过两条直线路径从原点到达 $\mathbf{u}$ 的移动指令。首先在 $\mathbf{v}_1$ 方向移动 3 个单位到达 $3\mathbf{v}_1$，然后在 $\mathbf{v}_2$ 方向移动 -2 个单位</p></blockquote><p>线性代数的一个主要思想是研究可以表示为某一固定向量集合 $\{\mathbf{v}_1,\mathbf{v}_2,\dots,\mathbf{v}_p\}$ 的线性组合的所有向量。</p><p><strong>定义</strong>　若 $\mathbf{v}_1,\mathbf{v}_2,\dots,\mathbf{v}_p$ 是 $\mathbb{R}^n$ 中的向量，则 $\mathbf{v}_1,\mathbf{v}_2,\dots,\mathbf{v}_p$ 的所有线性组合的集合用记号 $\mathrm{Span}\{\mathbf{v}_1,\mathbf{v}_2,\dots,\mathbf{v}_p\}$ 表示，称为由 $\mathbf{v}_1,\mathbf{v}_2,\dots,\mathbf{v}_p$ 所生成的 $\mathbb{R}^n$ 的子集。也就是说 $\mathrm{Span}\{\mathbf{v}_1,\mathbf{v}_2,\dots,\mathbf{v}_p\}$ 是所有形如</p><script type="math/tex; mode=display">c_1\mathbf{v}_1+\cdots+c_p\mathbf{v}_p</script><p>的向量的集合，其中 $c_1,c_2,\dots,c_p$ 为标量。</p><p>要判断向量 $\mathbf{b}$ 是否属于 $\mathrm{Span}\{\mathbf{v}_1,\mathbf{v}_2,\dots,\mathbf{v}_p\}$，就是判断<strong>向量方程</strong></p><script type="math/tex; mode=display">x_1\mathbf{v}_1+x_2\mathbf{v}_2+\cdots+x_n\mathbf{v}_n=\mathbf{b}</script><p>是否有解，它与增广矩阵为</p><script type="math/tex; mode=display">\begin{bmatrix}   \mathbf{v}_1 &\mathbf{v}_2 &\cdots &\mathbf{v}_n & \mathbf{b}\end{bmatrix}</script><p>的线性方程组有相同的解集，即等价。</p><h2 id="3-矩阵方程"><a href="#3-矩阵方程" class="headerlink" title="3. 矩阵方程"></a>3. 矩阵方程</h2><p>向量的线性组合可以看作矩阵与向量的积。</p><p><strong>定义</strong>　若 $A$ 是 $m\times n$ 矩阵，它的各列为 $\mathbf{a}_1,\mathbf{a}_2,\dots,\mathbf{a}_n$，若 $\mathbf{x}$ 是 $\mathbb{R}^n$ 中的向量，则 $A$ 与 $\mathbf{x}$ 的积（记为 $A\mathbf{x}$ ） 就是 $A$ 的各列以 $\mathbf{x}$ 中对应元素为权的线性组合，即</p><script type="math/tex; mode=display">A\mathbf{x}=\begin{bmatrix} \mathbf{a}_1& \mathbf{a}_2 &\cdots  &\mathbf{a}_n \end{bmatrix}\begin{bmatrix}   x_1 \\   x_2 \\   \vdots  \\   x_n \\\end{bmatrix}= x_1\mathbf{a}_1+x_2\mathbf{a}_2+\cdots+x_n\mathbf{a}_n</script><p>当且仅当 $A$ 中的列数等于 $\mathbf{x}$ 中元素个数时 $A\mathbf{x}$ 才有定义。</p><p>线性方程组可以用矩阵方程表示</p><p><strong>定理1</strong>　若 $A$ 是 $m\times n$ 矩阵，它的各列为 $\mathbf{a}_1,\mathbf{a}_2,\dots,\mathbf{a}_n$，同时 $\mathbf{b}$ 属于 $\mathbb{R}^n$，则矩阵方程</p><script type="math/tex; mode=display">A\mathbf{x}=\mathbf{b}</script><p>与向量方程</p><script type="math/tex; mode=display">x_1\mathbf{a}_1+x_2\mathbf{a}_2+\cdots+x_n\mathbf{a}_n=\mathbf{b}</script><p>以及与增广矩阵为</p><script type="math/tex; mode=display">\begin{bmatrix}   \mathbf{a}_1 &\mathbf{a}_2 &\cdots &\mathbf{a}_n & \mathbf{b}\end{bmatrix}</script><p>的线性方程组都有相同的解集。</p><p>上述定理是研究线性代数问题的有力工具，使我们现在可将线性方程组用三种不同但彼此等价的观点来研究：作为矩阵方程、作为向量方程或作为线性方程组。当构造实际生活中某个问题的数学模型时，我们可自由地选择任何一种最自然的观点。于是我们可在方便的时候由一种观点转向另一种观点。任何情况下，矩阵方程、向量方程以及线性方程组都用相同方法来解——用行化简算法来化简增广矩阵。</p><p>下面讨论线性方程组解的情况。</p><p><strong>定理2</strong>　若 $A$ 是 $m\times n$ 矩阵，则下列命题逻辑上是等价的。即同时成立或同时不成立。</p><ol><li>对 $\mathbb{R}^n$ 中每个 $\mathbf{b}$，方程 $A\mathbf{x}=\mathbf{b}$ 有解。</li><li></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;h1 id=&quot;线性方程组&quot;&gt;&lt;a href=&quot;#线性方程组&quot; class=&quot;headerlink&quot; title=&quot;线性方程组&quot;&gt;&lt;/a&gt;线性方程组&lt;/h1&gt;&lt;h2 id=&quot;1-线性方程组&quot;&gt;&lt;a href=&quot;#1-线性方程组&quot; c</summary>
      
    
    
    
    <category term="Linear Algebra" scheme="http://example.com/categories/Linear-Algebra/"/>
    
    
  </entry>
  
  <entry>
    <title>8. Adaptive Boost</title>
    <link href="http://example.com/2022/03/19/MachineLearning/8.AdaptiveBoost/"/>
    <id>http://example.com/2022/03/19/MachineLearning/8.AdaptiveBoost/</id>
    <published>2022-03-18T16:00:00.000Z</published>
    <updated>2022-06-22T08:17:34.049Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><h2 id="1-历史背景"><a href="#1-历史背景" class="headerlink" title="1. 历史背景"></a>1. 历史背景</h2><p>1984 年，Leslie Valiant 提出概率近似正确（probably approximately correct，PAC）学习框架。当存在算法满足 $P[R(h_S)\le\epsilon]\ge 1-\delta$，$R(h_S)$ 是算法 $h$ 数据集 $S$ 上的经验误差，同时样本量 $m\ge poly(1/\epsilon,1/\delta,n,size(c))$，则称该算法为 PAC可学习的（learnable）。当 $\epsilon \in (0, 0.5)$ 且 $\delta \in (0, 0.5)$ 时，即算法学习成功的概率大于 $0.5$，且误分类率 $err(h)&lt;\epsilon$，则称算法拟合的那个概念是强可学习的；如果满足 $\delta \in [0, 0.5]$ 的基础上，算法的误差率 $err(h)&lt;1/2-\gamma$，则称为弱可学习。</p><p>1988 年，Michael Kearns 提出问题 “is weakly learnability equivalent to strong learnability?” 是提升机器学习算法（boosting）的起源。</p><p>1990 年，Yoav Freund 提出 Boost-by-majority 算法，并给予证明，即 PAC 学习架构下强可学习和弱可学习是充分必要条件，但该算法并不实用。</p><p>1995 年，Yoav Freund 和 Robert Schapire 提出 AdaBoost 算法，他们的工作获得了 2003 年哥德尔奖。</p><p>2000 年，Friedman 等人提出 Boosting Tree 算法。</p><h2 id="2-Adaboost-算法"><a href="#2-Adaboost-算法" class="headerlink" title="2. Adaboost 算法"></a>2. Adaboost 算法</h2><p>boosting 算法是一种集成算法，主要作用就是将弱可学习分类器转化为强可学习分类器，因为在分类问题中，给定一个训练样本集，弱分类器是比较容易得到的。Adaboost 是自适应算法，通过调整训练数据的概率分布，使随后的弱学习器更关注那些被先前分类器错误分类的实例，这样就保证在不同的弱分类器中，使得所有训练数据都能被有效的分类，最后通过多个弱学习器加权多数表决的方法，得到最终分类结果。        </p><p>给定二元分类训练数据集：</p><script type="math/tex; mode=display">T=\{(\mathbf x_1,y_1),(\mathbf x_2,y_2),...,(\mathbf x_N,y_N)\}</script><p>其中，${\displaystyle \mathbf x_i\in \mathcal{X}\subseteq R^n}$ 表示实例的特征向量，$y\in \mathcal{Y}=\{-1,+1\}$ 表示实例的类别，也就是标记（label）。给定实例特征向量$\mathbf x$，输出所属的类 $y$ 。</p><p>首先初始化训练数据集的权重</p><script type="math/tex; mode=display">D_1=(1/N,1/N,\dots,1/N)</script><p>假设第 $t$ 轮的权重为 $D_t$，通过弱分类算法 $A$ 产生一个弱分类器 $h_t\in \mathcal{H},h_t:\mathcal{X}\rightarrow \mathcal{Y}$，</p><p>弱分类器的误分类率为</p><script type="math/tex; mode=display">\begin{aligned}    \epsilon_t &= error_{D_t}(h_t)\\    &=P(h_t(\mathbf x_i)\ne y_i) \\    &=\sum_{i=t}^N D_t(i)\cdot I (h_t(\mathbf x_i)\ne y_i)\\    &=\sum_{h_t(\mathbf x_i)\ne y_i} D_t(i)\end{aligned}</script><p>弱分类算法 $A$ 的损失函数就是最小化误分类率 $\epsilon_t$，在这里需要保证 $\epsilon_t&lt;1/2$，否则就不是弱分类器，算法停止。</p><p>计算弱分类器 $h_t$ 的系数 </p><script type="math/tex; mode=display">\alpha_t=\frac{1}{2}\ln \frac{1-\epsilon_t}{\epsilon_t}</script><p>从公式中可以看出，当 $\epsilon_t<1/2$ 时，$\alpha_t>0$，且 $\alpha_t$ 随着 $\epsilon_t$ 的减小而增加，因此分类误差率越小的弱分类器在最后多数表决时起的作用越大。</p><p>更新训练数据集的权重</p><script type="math/tex; mode=display">D_{t+1}(i)=\frac{D_t(i)}{Z_t}e^{-\alpha_ty_ih_t(\mathbf x_i)}</script><p>$Z_t$ 是规范化因子，它保证了更新后的权重也是一个概率分布</p><script type="math/tex; mode=display">Z_t=\sum_{i=1}^N D_t(i)e^{-\alpha_ty_ih_t(\mathbf x_i)}</script><p>从更新公式中可以看出，当分类正确时，权重乘以 $e^{-\alpha}$ 会降低 ，当分类错误时，权重乘以 $e^{\alpha}$ 会增加。相较于正确分类样本，误分类样本的权值被放大 $\displaystyle e^{2\alpha}=\frac{1-\epsilon}{\epsilon}$倍。</p><p>将以上步骤重复 $T$ 次，就得到了 $T$ 个弱分类器，最终 Adaboost 的输出结果为</p><script type="math/tex; mode=display">H(\mathbf x)=\mathrm{sign}\left(\sum_{t=1}^T \alpha_t h_t(\mathbf x)\right)</script><p>在式中，$\displaystyle \sum_{t=1}^T \alpha_t h_t(\mathbf x)$ 的正负号决定了实例 $\mathbf{x}$ 的分类结果，绝对值表示分类的确信度。</p><h2 id="2-Adaboost-算法分析与证明"><a href="#2-Adaboost-算法分析与证明" class="headerlink" title="2. Adaboost 算法分析与证明"></a>2. Adaboost 算法分析与证明</h2><p>Adaboost 算法对于给定的训练数据集，对于足够多的轮次 $T$ 之后，可以证明出最后的分类器 $H$ 的训练误差很小。定义 $H$ 在训练数据集 $S$ 上的训练误差为</p><script type="math/tex; mode=display">err_S(H)=\frac{1}{N}\sum_{i=1}^N \mathbf I (H(\mathbf x_i)\ne y_i)</script><p>对于每一轮 $t$，目前为止构建的弱分类器的线性组合为</p><script type="math/tex; mode=display">F_t(\mathbf x)=\sum_{j=1}^t\alpha_j h_j(\mathbf{x})</script><p><strong>引理 1.</strong> 对于每一轮 $t$，$D_{t+1}(i)\propto e^{-y_iF_t(\mathbf x_i)}$，即分布 $D_{t+1}(i)$ 根据历史弱分类器 $F_t$ 的值对结果进行加权。</p><p>证明：</p><script type="math/tex; mode=display">\begin{aligned}    D_{t+1}(i) &= \frac{D_t(i)}{Z_t}e^{-\alpha_ty_ih_t(\mathbf x_i)}\\    &=\frac{D_{t-1}(i)}{Z_tZ_{t-1}}e^{-\alpha_ty_ih_t(\mathbf x_i)}e^{-\alpha_{t-1}y_ih_{t-1}(\mathbf x_i)} \\    &\dots \\    &= \frac{D_1(i)}{ \prod_{j=1}^t Z_j}e^{ -y_i  \sum_{j=1}^t\alpha_jh_j(\mathbf x_i)} \\    &= \frac{1}{ N\prod_{j=1}^t Z_j}e^{-y_iF_t(\mathbf x_i)}\end{aligned}</script><p>因此，分布 $D_{t+1}$ 根据目前得到的函数 $F_t$ 的间隔（margin） $y_iF_t(\mathbf x_i)$ 为 $S$ 中的样本 $(\mathbf x_i, y_i)$ 分配权重。间隔越小表示分类效果越差，因此权重越大，这迫使第 $t+1$ 轮的弱学习器专注于 $F_t$ 未准确分类的实例。</p><p><strong>引理 2.</strong> $\displaystyle err_S(H)\le \frac{1}{N}\sum_{i=1}^N e^{-y_iF_T(\mathbf x_i)}=\prod_{j=1}^T Z_j$</p><p>证明：当 $H(\mathbf x_i)\ne y_i$ 时，$y_iF_T(\mathbf x_i)\le0$，因此 $e^{-y_iF_T(\mathbf x_i)}\ge1$，从而得到</p><script type="math/tex; mode=display">err_S(H)\le 1 \le \frac{1}{N}\sum_{i=1}^N e^{-y_iF_T(\mathbf x_i)}</script><p>进一步地，由引理 1 得到</p><script type="math/tex; mode=display">\begin{aligned}    \frac{1}{N}&\sum_{i=1}^N e^{-y_iF_T(\mathbf x_i)} \\     &= \prod_{j=1}^t Z_j \sum_{i=1}^ND_{t+1}(i) \end{aligned}</script><p>由于 </p><script type="math/tex; mode=display">\displaystyle \sum_{i=1}^ND_{t+1}(i) =1</script><p>因此 </p><script type="math/tex; mode=display">\displaystyle \frac{1}{N}\sum_{i=1}^N e^{-y_iF_T(\mathbf x_i)}=\prod_{j=1}^T Z_j</script><p><strong>引理 3.</strong> 对于给定的 $\alpha_t$，每一轮归一化常数具有简单形式 $Z_t=2\sqrt{\epsilon_t(1-\epsilon_t)}$</p><p>证明：根据前面可知</p><script type="math/tex; mode=display">\displaystyle e^{2\alpha_t}=\frac{1-\epsilon_t}{\epsilon_t}</script><p>推出</p><script type="math/tex; mode=display">\displaystyle e^{-\alpha_t}=\sqrt{\frac{\epsilon_t}{1-\epsilon_t}}</script><p>并且</p><script type="math/tex; mode=display">{\displaystyle y_ih_t(\mathbf x_i)={    \begin{cases}        +1&\mathrm{if}\quad h_t(\mathbf x_i)=y_i\\        -1&\mathrm{otherwise}    \end{cases}    }}</script><p>因此</p><script type="math/tex; mode=display">\begin{aligned}     Z_t&=\sum_{i=1}^N D_t(i)e^{-\alpha_ty_ih_t(\mathbf x_i)}\\     &= \sum_{i=1}^N D_t(i)\left(e^{-\alpha_t}I( h_t(\mathbf x_i)=y_i)+e^{\alpha_t}I( h_t(\mathbf x_i)\ne y_i)\right)\\     &=e^{-\alpha_t}\sum_{i=1}^N D_t(i)\cdot I( h_t(\mathbf x_i)=y_i) + e^{\alpha_t}\sum_{i=1}^N D_t(i)\cdot I( h_t(\mathbf x_i)\ne y_i)\\     &= \sqrt{\frac{\epsilon_t}{1-\epsilon_t}} (1-\epsilon_t)+\sqrt{\frac{1-\epsilon_t}{\epsilon_t}}\epsilon_t \\     &=2\sqrt{\epsilon_t(1-\epsilon_t)}\end{aligned}</script><p><strong>引理 4.</strong> $\displaystyle\gamma \in (0,\frac{1}{2}]$时，如果 $\displaystyle\epsilon_t\le \frac{1}{2}-\gamma$，存在 $err_S(H)\le e^{-2T\gamma^2}$</p><p>证明：由引理 2 和引理 3 可得</p><script type="math/tex; mode=display">\begin{aligned}     err_S(H)&\le \prod_{t=1}^T Z_j\\      &= \prod_{t=1}^T 2\sqrt{\epsilon_t(1-\epsilon_t)}\\     &\le2^T\prod_{t=1}^T \sqrt{(\frac{1}{2}-\gamma)(\frac{1}{2}+\gamma)},\\     &\qquad \text{ since } \epsilon_t\le \frac{1}{2}-\gamma，\mathrm{and} \sqrt{x(1-x)} \text{ is an increasing function of } x \text{ on }  (0,\frac{1}{2}]\\     &= 2^T\prod_{t=1}^T \sqrt{\frac{1}{4}-\gamma^2} \\     &= (1-4\gamma^2)^{T/2}\\     &\le e^{-2T\gamma^2},\text{ since } 1-x\le e^{-x}\end{aligned}</script><p>从引理中可以看出，如果弱学习器的分类结果比随机预测 $(0.5)$ 的结果要好，那么最终分类器 $H$ 的误差将随着 $T$ 的增加呈指数下降，且对于足够大的 $T$，误差会变得足够小。</p><h2 id="3-Adaboost-损失函数"><a href="#3-Adaboost-损失函数" class="headerlink" title="3. Adaboost 损失函数"></a>3. Adaboost 损失函数</h2><p>前面的算法过程是直接给出了 $\alpha$ 的取值方式，如果给定 Adaboost 的损失函数，事实上每一步 $\alpha_t$ 的取值都是为了使损失函数最小。</p><p>定义指数损失函数为</p><script type="math/tex; mode=display">L(y,f)=e^{-yf}</script><p>定义 Adaboost 的损失函数为指数损失函数</p><script type="math/tex; mode=display">L(Y,F_T(X))=\sum_{i=1}^N e^{-y_iF_T(\mathbf x_i)}</script><p>其中</p><script type="math/tex; mode=display">F_T(\mathbf x)=\sum_{j=1}^T\alpha_j h_j(\mathbf{x})</script><p>求解该损失函数极小化问题是一个复杂的优化问题，可以使用前向分布算法的思想。前向分步算法类似动态规划中的前向计算，每一步只求取一个的最优分类器 $h_j$ 及其参数 $\alpha_j$，与之前的过程无关，即前 $t-1$ 步求取的分类器及参数都当做定值。</p><p>从上述思想中可以得到第 $t$ 次迭代得到的分类器为</p><script type="math/tex; mode=display">F_t(\mathbf{x}_i)=F_{t-1}(\mathbf{x}_i)+\alpha_th_t(\mathbf{x}_i)</script><p>损失函数为</p><script type="math/tex; mode=display">\begin{aligned}    L(Y,F_t(X))&=\sum_{i=1}^N e^{-y_i(F_{t-1}(\mathbf{x}_i)+\alpha_th_t(\mathbf{x}_i))}\\    &=\sum_{i=1}^Ne^{-y_iF_{t-1}(\mathbf{x}_i)} e^{\alpha_t y_ih_t(\mathbf{x}_i)}\\    &=\sum_{i=1}^N (N\prod_{j=1}^{t-1} Z_j) D_{t}(i) e^{\alpha_t y_ih_t(\mathbf{x}_i)}\end{aligned}</script><p>最小化上述损失函数，对于任意的 $\alpha_t&gt;0$，使损失函数最小可以得到</p><script type="math/tex; mode=display">h_t(\mathbf{x})=\argmin_h \sum_{i=1}^N D_{t}(i)I( h_t(\mathbf x_i)\ne y_i)</script><p>其实就是弱分类器的误分类率</p><p>由之间的定理 3 将损失函数进一步拆分</p><script type="math/tex; mode=display">\begin{aligned}     L(Y,F_t(X))&=(N\prod_{j=1}^{t-1} Z_j)\sum_{i=1}^N D_t(i)e^{-\alpha_ty_ih_t(\mathbf x_i)}\\     &= (N\prod_{j=1}^{t-1} Z_j)\sum_{i=1}^N D_t(i)\left(e^{-\alpha_t}I( h_t(\mathbf x_i)=y_i)+e^{\alpha_t}I( h_t(\mathbf x_i)\ne y_i)\right)\\     &= (N\prod_{j=1}^{t-1} Z_j)(e^{-\alpha_t} (1-\epsilon_t)+e^{\alpha_t}\epsilon_t) \\\end{aligned}</script><p>对 $\alpha_t$ 求导，并令导数为 0，可以得到</p><script type="math/tex; mode=display">-e^{-\alpha_t} (1-\epsilon_t)+e^{\alpha_t}\epsilon_t=0</script><p>解得</p><script type="math/tex; mode=display">\alpha_t=\frac{1}{2}\ln{\frac{1-\epsilon_t}{\epsilon_t}}</script><p>结果与前面给出的一致。</p><p>实际上每一步 $t$ 的弱分类器是加权后的误分类率 $\epsilon_t$ 最小，然后确定最小的误分类率之后，$\alpha_t$ 的取值使最终分类器的损失函数最小。</p><h2 id="3-Adaboost-回归"><a href="#3-Adaboost-回归" class="headerlink" title="3. Adaboost 回归"></a>3. Adaboost 回归</h2><p>相对应于分类问题的误分类率，在回归问题中则是误差率，需要归一化处理并最后取平均值得到平均误差率，保证其值在 $[0,1]$ 之间即可。</p><p>首先初始化训练数据集的权重</p><script type="math/tex; mode=display">D_1=(1/N,1/N,\dots,1/N)</script><p>假设第 $t$ 轮的权重为 $D_t$，通过弱分类算法 $A$ 产生一个弱学习器 $h_t\in \mathcal{H},h_t:\mathcal{X}\rightarrow \mathcal{Y}$</p><p>每个样本的相对误差</p><script type="math/tex; mode=display">e_i = \frac{|y_i-h(\mathbf x_i)|}{\displaystyle \max_j |y_j-h(\mathbf x_j)|}</script><p>这里是曼哈顿距离，如果是平方误差则为</p><script type="math/tex; mode=display">e_i = \frac{(y_i-h(\mathbf x_i))^2}{\displaystyle \max_j (y_j-h(\mathbf x_j))^2}</script><p>指数误差则为（存疑）</p><script type="math/tex; mode=display">e_i = 1-\exp({\frac{|y_i-h(\mathbf x_i)|}{\displaystyle\max_j |y_j-h(\mathbf x_j)|}})</script><p>第 $t$ 轮弱学习器的误差率为</p><script type="math/tex; mode=display">\epsilon_t = \sum_i^N D_t(i)e_i</script><p>计算弱学习器 $h_t$ 的系数 </p><script type="math/tex; mode=display">\alpha_t=\frac{1}{1-\epsilon_t}-1=\frac{\epsilon_t}{1-\epsilon_t}</script><p>更新训练数据集的权重</p><script type="math/tex; mode=display">D_{t+1}(i)=\frac{D_t(i)}{Z_t}\alpha_t^{1-e_i}</script><p>$Z_t$ 是规范化因子</p><script type="math/tex; mode=display">Z_t=\sum_{i=1}^N D_t(i)\alpha_t^{1-e_i}</script><p>最后是结合策略，采用的是对加权的弱学习器取权重中位数对应的弱学习器作为强学习器的方法，最终的强回归器为</p><script type="math/tex; mode=display">\ln \frac{1}{\alpha_t},t=1,2,3,\dots,T</script><p>的中位数值序号 $t^<em>$ 对应的学习器 $h_{t^</em>}$</p><blockquote><p><a href="https://zhuanlan.zhihu.com/p/66799567">1. 【Mohri-机器学习基础】第2章: PAC学习框架-zhihu</a><br><a href="https://blog.csdn.net/rongxiang20054209/article/details/77601091?utm_medium=distribute.pc_aggpage_search_result.none-task-blog-2~aggregatepage~first_rank_ecpm_v1~rank_v31_ecpm-1-77601091.pc_agg_new_rank&amp;utm_term=pac%E5%BC%B1%E5%8F%AF%E5%AD%A6%E4%B9%A0&amp;spm=1000.2123.3001.4430">2. PAC（probably approximately correct） 学习架构介绍-csdn</a><br><a href="https://en.wikipedia.org/wiki/Boosting_(machine_learning">3. Boosting (machine learning)-wiki</a>)<br><a href="https://www.shivani-agarwal.net/Teaching/CIS-520/Spring-2018/Lectures/Reading/boosting.pdf">4. CIS 520: Machine Learning Spring 2018: Lecture 9 Boosting</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;h1 id=&quot;决策树&quot;&gt;&lt;a href=&quot;#决策树&quot; class=&quot;headerlink&quot; title=&quot;决策树&quot;&gt;&lt;/a&gt;决策树&lt;/h1&gt;&lt;h2 id=&quot;1-历史背景&quot;&gt;&lt;a href=&quot;#1-历史背景&quot; class=&quot;head</summary>
      
    
    
    
    <category term="Machine learning" scheme="http://example.com/categories/Machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>7. Support Vecor Machine</title>
    <link href="http://example.com/2022/03/17/MachineLearning/7.SupportVecorMachine/"/>
    <id>http://example.com/2022/03/17/MachineLearning/7.SupportVecorMachine/</id>
    <published>2022-03-16T16:00:00.000Z</published>
    <updated>2022-06-06T03:00:43.698Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><h1 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h1><h2 id="1-历史背景"><a href="#1-历史背景" class="headerlink" title="1. 历史背景"></a>1. 历史背景</h2><p>支持向量机的发明可以追溯到 20 世纪中叶一系列事件。</p><p>1950 年，Aronszajn 发表了 “Theory of Reproducing Kernels”。</p><p>1957 年，Frank Rosenblatt 采用上述思想，发明了感知机，一种简单的线性分类器。</p><p>1963 年，Vapnik 和 Lerner 发表了 “Generalized Portrait Algorithm”，这是支持向量机的灵感来源。</p><p>1992 年，Vladimir Vapnik 和同事 Bernhard Boser、Isabelle Guyon 在 AT&amp;T 贝尔实验室开发出支持向量机算法。</p><p>1995 年，Vladimir Vapnik 和 Cortes 开发出软边距（soft margin）分类器。</p><p>1998 年，Shawe、Taylor 等人，对硬间隔（hard margin）支持向量机的泛化做出了重大贡献。</p><p>2001 年，Vladimir Vapnik 和 Hava Siegelmann 开发出支持向量聚类（Support Vector Clustering，SVC），可以用于未标记的数据。</p><h2 id="2-基础预备"><a href="#2-基础预备" class="headerlink" title="2. 基础预备"></a>2. 基础预备</h2><h3 id="2-1-拉格朗日乘数法-3"><a href="#2-1-拉格朗日乘数法-3" class="headerlink" title="2.1 拉格朗日乘数法[3]"></a>2.1 拉格朗日乘数法<a href="#refer-anchor-1"><sup>[3]</sup></a></h3><p>假设 $f(x,y)$ 与 $g(x,y)$ 都具有连续的一阶导数，即在 $\R^n$ 上是连续可微函数，考虑最优化问题</p><script type="math/tex; mode=display">{\min f(x,y)} \\{\displaystyle s.t \quad  g(x,y)=0}</script><p>如果 $f(x,y)$ 与 $g(x,y)$ 在 $(x_0,y_0)$ 处取极值，它们必定相切，因此梯度平行</p><script type="math/tex; mode=display">\triangledown f(x,y)=\lambda\triangledown g(x,y)</script><p>同时必定满足</p><script type="math/tex; mode=display">g(x,y)=0</script><p>将它们联立起来即可求解出 $(x_0,y_0)$ 的取值。</p><p>拉格朗日乘数法将上述优化问题构造为一个新的函数称作拉格朗日函数</p><script type="math/tex; mode=display">{\displaystyle {\mathcal {L}}(x,y,\lambda )=f(x,y)-\lambda g(x,y)}</script><p>然后直接求解拉格朗日函数的极值点，即</p><script type="math/tex; mode=display">{\displaystyle {    \begin{cases}        \triangledown_x{\mathcal {L}}(x,y,\lambda )=0\\        \triangledown_y{\mathcal {L}}(x,y,\lambda )=0\\        \triangledown_\lambda{\mathcal {L}}(x,y,\lambda )=0    \end{cases}    }}</script><p>事实上，这与下式是完全一样的。</p><script type="math/tex; mode=display">{\displaystyle {    \begin{cases}        \triangledown f(x,y)=\lambda\triangledown g(x,y)\\        \;\\        g(x,y)=0\\    \end{cases}    }}</script><p>因此拉格朗日乘数法只是一种构造方法，本质是极值点处的两个曲线相切。</p><h3 id="2-2-广义拉格朗日乘数法"><a href="#2-2-广义拉格朗日乘数法" class="headerlink" title="2.2 广义拉格朗日乘数法"></a>2.2 广义拉格朗日乘数法</h3><p>Harold W. Kuhn 和 Albert W. Tucker 将拉格朗日乘数法进行了推广，在满足 Karush-Kuhn-Tucker (KKT) 条件的情况下，允许不等式约束。</p><h4 id="2-2-1-原始问题"><a href="#2-2-1-原始问题" class="headerlink" title="2.2.1 原始问题"></a>2.2.1 原始问题</h4><p>考虑如下最优化问题，$f,g,h$ 都具有连续的一阶导数，即在 $\R^n$ 上是连续可微函数</p><script type="math/tex; mode=display">\begin{aligned}    &\min_{\mathbf x} f(\mathbf x) \\    \displaystyle s.t \quad  &g_i(\mathbf x)\le 0 & i=1,2,\dots,k\\    &h_j(\mathbf x) =0 & j=1,2,\dots,l\\\end{aligned}</script><p>构造如下拉格朗日函数</p><script type="math/tex; mode=display">{\displaystyle L(\mathbf x,\mu ,\lambda )=f(\mathbf x)+\sum _{i=1}^{k}\mu _{i}g_{i}(\mathbf x)+\sum _{j=1}^{l }\lambda _{j}h_{j}(\mathbf x)}</script><p>其中，$\mu_i,\lambda_j$ 是拉格朗日乘子。考虑如下目标函数</p><script type="math/tex; mode=display">\theta_{\mathcal P}(\mathbf x)=\max_{\mu,\lambda:\mu_i\ge 0}L(\mathbf x,\mu ,\lambda )</script><p>这里，$\mathcal P$ 代表原始（primal）问题，相对的是对偶（dual）问题 $\mathcal  D$。</p><p>假设给定 $\mathbf x$，如果 $\mathbf x$ 不满足任一约束条件，即存在 $g_i(\mathbf x)&gt; 0$ 或者 $h_j(\mathbf x)\ne0$，会导致</p><script type="math/tex; mode=display">\theta_{\mathcal P}(\mathbf x)=\max_{\mu,\lambda:\mu_i\ge 0}L(\mathbf x,\mu ,\lambda )=+\infty</script><p>因为，当 $g_i(\mathbf x)&gt; 0$ 时，$\theta_{\mathcal P}(\mathbf x)$ 随 $\mu_i$ 的增大而增大，最终趋于正无穷；当 $h_j(\mathbf x)\ne0$ 时，如果 $h_j(\mathbf x)&gt;0$，$\theta_{\mathcal P}(\mathbf x)$ 随 $\lambda_j$ 的增大而增大，反之随 $\lambda_j$ 的减小而增大，最终都趋于正无穷。</p><p>如果 $\mathbf x$ 满足约束条件，可以得到 $\theta_{\mathcal P}(\mathbf x)=f(\mathbf x)$。因此</p><script type="math/tex; mode=display">{\displaystyle \theta_{\mathcal P}(\mathbf x)={    \begin{cases}        f(\mathbf x)&\text{if }\mathbf x \text{ satisfies primal constraints}\\        +\infty&\text{otherwise}    \end{cases}    }}</script><p>所以，对于满足原始约束的 $\mathbf{x}$ 的所有值，$\theta_{\mathcal P}(\mathbf x)$ 与最优化问题中的目标值相同，如果不满足原始约束，则值为正无穷大。因此，如果考虑最小化问题</p><script type="math/tex; mode=display">\min_{\mathbf x}\theta_{\mathcal P}(\mathbf x)=\min_{\mathbf x}\max_{\mu,\lambda:\mu_i\ge 0}L(\mathbf x,\mu ,\lambda )</script><p>它与原始最优化问题是等价的，即具有相同的解。定义原始最优问题的最优解为</p><script type="math/tex; mode=display">p^*=\min_{\mathbf{x}}\theta_{\mathcal P}(\mathbf x)</script><h4 id="2-2-2-对偶问题"><a href="#2-2-2-对偶问题" class="headerlink" title="2.2.2 对偶问题"></a>2.2.2 对偶问题</h4><p>定义对偶问题</p><script type="math/tex; mode=display">\theta_{\mathcal D}(\mu,\lambda)=\min_{\mathbf{x}}L(\mathbf x,\mu ,\lambda )</script><p>再将上式极大化</p><script type="math/tex; mode=display">\max_{\mu,\lambda:\mu_i\ge 0}\theta_{\mathcal D}(\mu,\lambda)=\max_{\mu,\lambda:\mu_i\ge 0}\min_{\mathbf x}L(\mathbf x,\mu ,\lambda )</script><p>定义对偶问题的最优值</p><script type="math/tex; mode=display">d^*=\max_{\mu,\lambda:\mu_i\ge 0}\theta_{\mathcal D}(\mu,\lambda)</script><blockquote><p>用函数值集合理解对偶问题<a href="#refer-anchor-1"><sup>[7]</sup></a>。</p><p>将问题简单化，只考虑一个不等式约束，假设 $f,g$ 映射后的值为 $a,b$，那拉格朗日函数即为 $a+\lambda b$，其中 $b\le 0$。原始问题中是先对于不同的 $\mathbf{x}$，即每一组 $a,b$ 都求最大化的 $a+\lambda b$，由于 $b\le 0$，因此 $\lambda=0$ 时，$a+\lambda b$ 值最大，因此然后只需要再最小化 $a$ 即 $f(\mathbf{x})$ 即可。</p><p>反之，在对偶问题中，则是对于每一个斜率 $\lambda$，都求得一个最小化的 $a+\lambda b$，最后再在所有 $\lambda$ 中选一个能使 $a+\lambda b$ 最大化的即可，而 $a+\lambda b$ 实际上是该直线的截距。</p></blockquote><h4 id="2-2-3-原始问题与对偶问题关系"><a href="#2-2-3-原始问题与对偶问题关系" class="headerlink" title="2.2.3 原始问题与对偶问题关系"></a>2.2.3 原始问题与对偶问题关系</h4><p><strong>定理1. （弱对偶性）</strong> 若原始问题和对偶问题都有最优值，则</p><script type="math/tex; mode=display">d^*=\max_{\mu,\lambda:\mu_i\ge 0}\min_{\mathbf x}L(\mathbf x,\mu ,\lambda )\le \min_{\mathbf x}\max_{\mu,\lambda:\mu_i\ge 0}L(\mathbf x,\mu ,\lambda )=p^*</script><p>证明：对于任意的 $\mu ,\lambda$</p><script type="math/tex; mode=display">\theta_{\mathcal D}(\mu,\lambda)=\min_{\mathbf{x}}L(\mathbf x,\mu ,\lambda )\le L(\mathbf x,\mu ,\lambda )</script><p>对于任意的 $\mathbf x$，有</p><script type="math/tex; mode=display">\theta_{\mathcal P}(\mathbf x)=\max_{\mu,\lambda:\mu_i\ge 0}L(\mathbf x,\mu ,\lambda )\ge L(\mathbf x,\mu ,\lambda )</script><p>因此</p><script type="math/tex; mode=display">\theta_{\mathcal D}(\mu,\lambda)\le \theta_{\mathcal P}(\mathbf x)</script><p>已知原始问题和对偶问题均有最优值，因此</p><script type="math/tex; mode=display">\max_{\mu,\lambda:\mu_i\ge 0}\theta_{\mathcal D}(\mu,\lambda)\le \min_{\mathbf x}\theta_{\mathcal P}(\mathbf x)</script><p>即</p><script type="math/tex; mode=display">d^*=\max_{\mu,\lambda:\mu_i\ge 0}\min_{\mathbf x}L(\mathbf x,\mu ,\lambda )\le \min_{\mathbf x}\max_{\mu,\lambda:\mu_i\ge 0}L(\mathbf x,\mu ,\lambda )=p^*</script><p><strong>定理2. （强对偶性的充分条件）</strong> 如果函数 $f,g_i$ 是凸函数，$h_j$ 是仿射函数，并且不等式约束 $g$ 是严格执行的，即存在 $\mathbf{x}$ 对所有 $i$ 有 $g_i(\mathbf{x})&lt;0$，则存在 $\mathbf{x}^<em>,\mu^</em>,\lambda^<em>$，使 $\mathbf{x}^</em>$ 是原始问题的解，$\mu^<em>,\lambda^</em>$ 是对偶问题的解，并且</p><script type="math/tex; mode=display">p^*=d^*=L(\mathbf{x}^*,\mu^*,\lambda^*)</script><p><strong>定理3. （强对偶性的充要条件）</strong> 如果函数 $f,g_i$ 是凸函数，$h_j$ 是仿射函数，并且不等式约束 $g$ 是严格执行的，则存 $\mathbf{x}^<em>$ 和 $\mu^</em>,\lambda^<em>$ 分别是原始问题和对偶问题的解的充要条件是 $\mathbf{x}^</em>,\mu^<em>,\lambda^</em>$ 满足如下 Karush-Kuhn-Tucker (KKT) 条件</p><script type="math/tex; mode=display">\triangledown_{\mathbf{x}}L(\mathbf{x}^*,\mu^*,\lambda^*)=0</script><script type="math/tex; mode=display">\mu_ig_i(\mathbf{x}^*)=0,\quad i=1,2,\cdots,k</script><script type="math/tex; mode=display">g_i(\mathbf{x}^*)\le0,\quad i=1,2,\cdots,k</script><script type="math/tex; mode=display">\mu_i^*\ge0,\quad i=1,2,\cdots,k</script><script type="math/tex; mode=display">h_j(\mathbf{x}^*)=0,\quad j=1,2,\cdots,l</script><p>后面三个关系式其实就是约束条件。第二个关系式是对偶互补条件，类似于线性规划中互补松弛性，当影子价格 $\mu_i^<em>&gt;0$，则 $g_i(\mathbf{x}^</em>)=0$，如果 $g_i(\mathbf{x}^<em>)&lt;0$，则 $\mu_i^</em>=0$。</p><h2 id="3-基本概念"><a href="#3-基本概念" class="headerlink" title="3. 基本概念"></a>3. 基本概念</h2><p>假设训练数据集：</p><script type="math/tex; mode=display">T=\{(\mathbf x_1,y_1),(\mathbf x_2,y_2),...,(\mathbf x_N,y_N)\}</script><p>其中，${\displaystyle \mathbf x_i\in \mathcal{X}\subseteq R^n}$ 表示实例的特征向量，$y\in \mathcal{Y}=\{+1,-1\}$ 表示实例的类别。</p><p>在感知机中，通过超平面对线性可分的数据进行分类，超平面为</p><script type="math/tex; mode=display">{\displaystyle f(\mathbf x)=\mathbf w\cdot \mathbf x+b}</script><p>超平面将特征空间分为两部分，法向量指向的一侧为正类，另一侧为负类，即 $\mathbf w\cdot \mathbf x+b &gt; 0$ 时为正，反之为负。</p><p>在感知机算法中，满足条件的超平面有多个，而支持向量机就是寻找最优的一个。至于哪一个是最优的，直观的想法就是距离正负实例都尽可能的远，可能最终影响到超平面位置的只有两个实例，距离超平面最近的一正一负两实例。</p><p>实例到超平面的距离还有另一种解释，就是分类的确信程度，距离越远表示分类的确信度越大，距离越近表示确信度越小。为了衡量实例到超平面的距离，引入函数间隔和几何间隔。</p><p>对于分离超平面 $\mathbf w\cdot \mathbf x+b=0$，定义样本点 $(\mathbf x_i,y_i)$ 函数间隔 $\hat{\gamma}_i$ 为</p><script type="math/tex; mode=display">\hat{\gamma}_i = y_i(\mathbf w\cdot \mathbf x_i+b)</script><p>样本集 $T$ 关于超平面的函数间隔则为每个样本点函数间隔的最小值</p><script type="math/tex; mode=display">\hat{\gamma}=\min_i \hat{\gamma}_i</script><p>可以发现，当超平面分类正确时，$w\cdot \mathbf x+b$ 与 $y_i$ 同号，函数间隔为正，当分类错误时，函数间隔为负。</p><p>在感知机中使用的损失函数就是函数间隔，而函数间隔的问题在于并没有正常反映样本点到超平面的距离，例如 $\mathbf w,b$ 同时扩大 $2$ 倍，超平面并没有改变，但同一样本点的函数距离也扩大了 $2$ 倍。因此，在感知机中其实只用到了 $y_i(\mathbf w\cdot \mathbf x_i+b)$ 的符号，当所有样本正确分类则结束算法，在支持向量机中想要考虑距离因素则必须引入几何间隔。</p><p>定义几何间隔</p><script type="math/tex; mode=display">\gamma_i=\frac{y_i(\mathbf w\cdot \mathbf x_i+b)}{\left\|\mathbf w\right\|}</script><p>同理，样本集 $T$ 关于超平面的几何间隔为每个样本点几何间隔的最小值</p><script type="math/tex; mode=display">{\gamma}=\min_i {\gamma}_i</script><p>几何间隔与函数间隔存在如下关系</p><script type="math/tex; mode=display">\gamma=\frac{\hat{\gamma}}{\left\|\mathbf w\right\|}</script><p>如果可以保证 ${\left|\mathbf w\right|}=1$，则几何间隔与函数间隔相等，简化计算。</p><h2 id="4-线性可分：硬间隔支持向量机"><a href="#4-线性可分：硬间隔支持向量机" class="headerlink" title="4. 线性可分：硬间隔支持向量机"></a>4. 线性可分：硬间隔支持向量机</h2><p>支持向量机的核心思想就是在满足正确分类的情况下，同时希望超平面的几何间隔尽可能大，这就是一个条件约束问题。</p><script type="math/tex; mode=display">\begin{aligned}    \max\quad &\gamma \\    \displaystyle s.t \quad  &\frac{y_i(\mathbf w\cdot \mathbf x_i+b)}{\left\|\mathbf w\right\|}\ge \gamma \quad i=1,2,\dots,N\end{aligned}</script><p>根据几何间隔与函数间隔的关系，上式替换为</p><script type="math/tex; mode=display">\begin{aligned}    \max\quad &\frac{\hat{\gamma}}{\left\|\mathbf w\right\|} \\    \displaystyle s.t \quad  &y_i(\mathbf w\cdot \mathbf x_i+b)\ge \hat{\gamma}\quad i=1,2,\dots,N\end{aligned}</script><p>上面的约束问题中，$\hat{\gamma}$ 的取值实际上不影响解的结果，$\mathbf w,b$ 同时扩大 $\lambda$ 倍，$\hat{\gamma}$ 则变为 $\lambda\hat{\gamma}$，对于目标函数来说并没有改变。因此，取 $\hat{\gamma}=1$，同时将最大化 $\displaystyle \frac{1}{\left|\mathbf w\right|}$ 转换为最小化 $\displaystyle\frac{1}{2}\left|\mathbf w\right|^2$，因此最终线性可分支持向量机的最优化问题为</p><script type="math/tex; mode=display">\begin{aligned}    \min\quad &\frac{1}{2}\left\|\mathbf w\right\|^2 \\    \displaystyle s.t \quad  &y_i(\mathbf w\cdot \mathbf x_i+b)-1\ge 0\quad i=1,2,\dots,N\end{aligned}</script><p>该优化问题是具有凸二次目标函数，同时只有线性约束的优化问题。</p><p>求解该凸二次优化问题，需要用到拉格朗日乘子法，并转换为对偶问题求解，优点在于对偶问题更容易求解，且自然引入核函数的概念。</p><p>首先构建拉格朗日函数</p><script type="math/tex; mode=display">L(\mathbf w,b,\alpha)=\frac{1}{2}\left\|\mathbf w\right\|^2-\sum_{i=1}^N\alpha_{i}\left[y_{i}(\mathbf{w}\cdot \mathbf{x}_{i}+b)-1\right]</script><p>原始问题转变为</p><script type="math/tex; mode=display">\min_{\mathbf w,b}\max_{\alpha\ge 0}L(\mathbf w,b,\alpha)</script><p>对偶问题即为</p><script type="math/tex; mode=display">\max_{\alpha\ge 0}\min_{\mathbf w,b}L(\mathbf w,b,\alpha)</script><p>第一步先求 $\displaystyle \min_{\mathbf w,b}L(\mathbf w,b,\alpha)$，分别对 $\mathbf w,b$ 求偏导数并令其等于 $0$。</p><script type="math/tex; mode=display">\triangledown_{\mathbf w}L(\mathbf w,b,\alpha)=\mathbf w-\sum_{i=1}^N \alpha_{i}y_i\mathbf{x}_{i}=0</script><script type="math/tex; mode=display">\triangledown_{b}L(\mathbf w,b,\alpha)=-\sum_{i=1}^N \alpha_{i}y_i=0</script><p>得到</p><script type="math/tex; mode=display">\mathbf w=\sum_{i=1}^N \alpha_{i}y_i\mathbf{x}_{i}</script><script type="math/tex; mode=display">\sum_{i=1}^N \alpha_{i}y_i=0</script><p>将 $\mathbf{w}$ 的表达式带入拉格朗日函数</p><script type="math/tex; mode=display">\begin{aligned}    L(\mathbf w,b,\alpha)&=\frac{1}{2}(\sum_{i=1}^N \alpha_{i}y_i\mathbf{x}_{i})^2-\sum_{i=1}^N\alpha_{i}\left[y_{i}(\sum_{j=1}^N \alpha_{j}y_j\mathbf{x}_{j}\cdot \mathbf{x}_{i}+b)-1\right]\\    &=-\frac{1}{2}(\sum_{i=1}^N \alpha_{i}y_i\mathbf{x}_{i})\cdot(\sum_{j=1}^N \alpha_{j}y_j\mathbf{x}_{j})+\sum_{j=1}^N \alpha_i\end{aligned}</script><p>第二步再求 $\displaystyle\max_{\alpha\ge 0}\min_{\mathbf w,b}L(\mathbf w,b,\alpha)$，优化对偶问题为</p><script type="math/tex; mode=display">\begin{aligned}    \max_{\alpha} &-\frac{1}{2}(\sum_{i=1}^N \alpha_{i}y_i\mathbf{x}_{i})\cdot(\sum_{j=1}^N \alpha_{j}y_j\mathbf{x}_{j})+\sum_{j=1}^N \alpha_i \\    \displaystyle s.t \quad  &\sum_{i=1}^N \alpha_{i}y_i=0 \\    &\alpha_i\ge 0,\qquad i=1,2,\cdots,N \\\end{aligned}</script><p>对目标函数进行变换，改变正负号，由求最大改为最小，得到等价对偶优化问题</p><script type="math/tex; mode=display">\begin{aligned}    \min_{\alpha}\quad &\frac{1}{2}(\sum_{i=1}^N \alpha_{i}y_i\mathbf{x}_{i})\cdot(\sum_{j=1}^N \alpha_{j}y_j\mathbf{x}_{j})-\sum_{j=1}^N \alpha_i \\    \displaystyle s.t \quad  &\sum_{i=1}^N \alpha_{i}y_i=0 \\    &\alpha_i\ge 0,\qquad i=1,2,\cdots,N \\\end{aligned}</script><p>假设求得对偶最优化问题的解为 $\alpha^*$，根据 KKT 条件有</p><script type="math/tex; mode=display">\triangledown_{\mathbf{w}}L(\mathbf w^*,b^*,\alpha^*)=\mathbf w^*-\sum_{i=1}^N \alpha^*_{i}y_i\mathbf{x}_{i}=0</script><script type="math/tex; mode=display">\triangledown_{b}L(\mathbf w^*,b^*,\alpha^*)=-\sum_{i=1}^N \alpha^*_{i}y_i=0</script><script type="math/tex; mode=display">\alpha^*_i[y_i(\mathbf w^*\cdot \mathbf x_i+b^*)-1]=0,\quad i=1,2,\cdots,N</script><script type="math/tex; mode=display">y_i(\mathbf w^*\cdot \mathbf x_i+b^*)-1\ge0,\quad i=1,2,\cdots,N</script><script type="math/tex; mode=display">\alpha_i^*\ge0,\quad i=1,2,\cdots,N</script><p>根据第一个公式可以得到</p><script type="math/tex; mode=display">\mathbf w^*=\sum_{i=1}^N \alpha^*_{i}y_i\mathbf{x}_{i}</script><p>利用反证法可以知道一定存在一个 $\alpha_j^*&gt;0$，因此根据第三个公式也就是互补性可知</p><script type="math/tex; mode=display">y_j(\mathbf w^*\cdot \mathbf x_j+b^*)-1=0</script><p>联立两个式子可以得到</p><script type="math/tex; mode=display">b^*=y_j-\sum_{i=1}^N \alpha^*_{i}y_i\mathbf{x}_{i}\cdot \mathbf x_j</script><p>分离超平面</p><script type="math/tex; mode=display">\begin{aligned}    f(\mathbf x)&=\mathbf w^*\cdot \mathbf x+b^*\\    &=\sum_{i=1}^N \alpha^*_{i}y_i\mathbf{x}_{i}\cdot \mathbf x+y_j-\sum_{i=1}^N \alpha^*_{i}y_i\mathbf{x}_{i}\cdot \mathbf x_j\\    &=\sum_{i=1}^N \alpha^*_{i}y_i\mathbf{x}_{i}\cdot (\mathbf x-\mathbf x_j) + y_i\end{aligned}</script><p>由以上可知，$\mathbf w^<em>$ 和 $b^</em>$ 只依赖于训练数据中对应 $\alpha_j^*&gt;0$ 的样本点 $(\mathbf{x}_i,y_i)$，而其他样本点则没有影响，这个样本点就称为支持向量。</p><blockquote><p>与线性规划相类比，其实这个实例点就是起到桎梏作用的点，如同工厂生产中最紧缺的材料，再增加减少其它材料都不会影响最优解，只有增减该种材料才会影响结果，在支持向量机图中就是移动距离超平面最近的点，自然会影响到超平面的位置。</p></blockquote><h2 id="5-线性近似可分：软间隔支持向量机"><a href="#5-线性近似可分：软间隔支持向量机" class="headerlink" title="5. 线性近似可分：软间隔支持向量机"></a>5. 线性近似可分：软间隔支持向量机</h2><p>在上述硬间隔支持向量机中，所有的约束都是硬约束，如果没有满足所有约束条件的可行解的话就求不出结果。所以，对应于线性近似可分的数据集，如果只有少数异常点无法通过分离超平面区分出来，那么可以给这些不满足的约束条件一个惩罚，最终求出一个近似最优解。其实，这就是线性规划中的目标规划，将原本的硬约束条件改为软约束条件即可。</p><p>根据上述思想，软间隔支持向量机原始问题为</p><script type="math/tex; mode=display">\begin{aligned}    \min\quad &\frac{1}{2}\left\|\mathbf w\right\|^2 + C\sum_{i=1}^N\xi_i \\    \displaystyle s.t \quad  &y_i(\mathbf w\cdot \mathbf x_i+b)\ge 1-\xi_i\quad i=1,2,\dots,N \\    &\xi_i\ge0\quad i=1,2,\dots,N\end{aligned}</script><p>拉格朗日函数为</p><script type="math/tex; mode=display">L(\mathbf w,b,\xi,\alpha,\mu)=\frac{1}{2}\left\|\mathbf w\right\|^2+ C\sum_{i=1}^N\xi_i -\sum_{i=1}^N\alpha_{i}\left[y_{i}(\mathbf{w}\cdot \mathbf{x}_{i}+b)-1+\xi_i\right]-\sum_{i=1}^N \mu_i\xi_i</script><p>原始问题转换为</p><script type="math/tex; mode=display">\min_{\mathbf w,b,\xi}\max_{\alpha\ge 0,\mu\ge 0}L(\mathbf w,b,\xi,\alpha,\mu)</script><p>因此对偶问题为</p><script type="math/tex; mode=display">\max_{\alpha\ge 0,\mu\ge 0}\min_{\mathbf w,b,\xi}L(\mathbf w,b,\xi,\alpha,\mu)</script><p>先求 $\displaystyle\min_{\mathbf w,b,\xi}L(\mathbf w,b,\xi,\alpha,\mu)$，对三个变量 $\mathbf w,b,\xi$ 分别求偏导并令其等于 $0$</p><script type="math/tex; mode=display">\triangledown_{\mathbf w}L(\mathbf w,b,\xi,\alpha,\mu)=\mathbf w-\sum_{i=1}^N \alpha_{i}y_i\mathbf{x}_{i}=0</script><script type="math/tex; mode=display">\triangledown_{b}L(\mathbf w,b,\xi,\alpha,\mu)=-\sum_{i=1}^N \alpha_{i}y_i=0</script><script type="math/tex; mode=display">\triangledown_{\xi_i}L(\mathbf w,b,\xi,\alpha,\mu)=C-\alpha_i-\mu_i=0</script><p>将结果带入 $L$ 得</p><script type="math/tex; mode=display">\begin{aligned}    L(\alpha,\mu)&=\frac{1}{2}(\sum_{i=1}^N \alpha_{i}y_i\mathbf{x}_{i})^2-\sum_{i=1}^N\alpha_{i}\left[y_{i}(\sum_{j=1}^N \alpha_{j}y_j\mathbf{x}_{j}\cdot \mathbf{x}_{i}+b)-1\right]+\sum_{i=1}^N(C-\alpha_i-\mu_i)\xi_i\\    &=-\frac{1}{2}(\sum_{i=1}^N \alpha_{i}y_i\mathbf{x}_{i})\cdot(\sum_{j=1}^N \alpha_{j}y_j\mathbf{x}_{j})+\sum_{j=1}^N \alpha_i\end{aligned}</script><p>再求 $\displaystyle\max_{\alpha\ge 0,\mu\ge 0}L(\alpha,\mu)$，优化对偶问题为</p><script type="math/tex; mode=display">\begin{aligned}    \max_{\alpha,\mu} &-\frac{1}{2}(\sum_{i=1}^N \alpha_{i}y_i\mathbf{x}_{i})\cdot(\sum_{j=1}^N \alpha_{j}y_j\mathbf{x}_{j})+\sum_{j=1}^N \alpha_i \\    \displaystyle s.t \quad  &\sum_{i=1}^N \alpha_{i}y_i=0 \\    &C-\alpha_i-\mu_i=0\\    &\alpha_i\ge 0\\    &\mu_i\ge 0,\qquad i=1,2,\cdots,N \\\end{aligned}</script><p>将目标函数极大转为极小，同时将 $\mu_i$ 的关系式带入消去 $\mu_i$，得到等价优化问题</p><script type="math/tex; mode=display">\begin{aligned}    \min_{\alpha}\quad &\frac{1}{2}(\sum_{i=1}^N \alpha_{i}y_i\mathbf{x}_{i})\cdot(\sum_{j=1}^N \alpha_{j}y_j\mathbf{x}_{j})-\sum_{j=1}^N \alpha_i \\    \displaystyle s.t \quad  &\sum_{i=1}^N \alpha_{i}y_i=0 \\    &0\le\alpha_i\le C,\qquad i=1,2,\cdots,N \\\end{aligned}</script><p>假设求得的最优解为 $\mathbf w^<em>,b^</em>,\xi^<em>,\alpha^</em>,\mu^*$</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><blockquote><p><a href="https://holypython.com/svm/support-vector-machine-history/">1. Support Vector Machine History</a><br><a href="https://www.zhihu.com/question/64044033">2. 构造拉格朗日函数有何意义？-zhihu</a><br><a href="https://www.zhihu.com/question/38586401">3. 如何理解拉格朗日乘子法？-zhihu</a><br><a href="https://en.wikipedia.org/wiki/Lagrange_multiplier">4. Lagrange multiplier - Wikipedia</a><br><a href="https://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions">5. Karush–Kuhn–Tucker conditions - Wikipedia</a><br><a href="https://www.zhihu.com/question/26658861">6. 为什么我们要考虑线性规划的对偶问题？-zhihu</a><br><a href="https://www.zhihu.com/question/58584814">7. 如何通俗地讲解对偶问题，尤其是拉格朗日对偶 lagrangian duality？-zhihu</a></p><p><a href="https://en.wikipedia.org/wiki/Logistic_function">8. Logistic function - Wikipedia</a><br><a href="https://www.cnblogs.com/pinard/p/6029432.html">9. 逻辑回归原理小结 - 刘建平</a></p><div id="refer-anchor-1"></div></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;h1 id=&quot;支持向量机&quot;&gt;&lt;a href=&quot;#支持向量机&quot; class=&quot;headerlink&quot; title=&quot;支持向量机&quot;&gt;&lt;/a&gt;支持向量机&lt;/h1&gt;&lt;h2 id=&quot;1-历史背景&quot;&gt;&lt;a href=&quot;#1-历史背景&quot; cla</summary>
      
    
    
    
    <category term="Machine learning" scheme="http://example.com/categories/Machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>6. Logistic Regression</title>
    <link href="http://example.com/2022/02/20/MachineLearning/6.LogisticRegression/"/>
    <id>http://example.com/2022/02/20/MachineLearning/6.LogisticRegression/</id>
    <published>2022-02-19T16:00:00.000Z</published>
    <updated>2022-06-20T01:07:00.129Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><h1 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h1><h2 id="1-历史背景"><a href="#1-历史背景" class="headerlink" title="1. 历史背景"></a>1. 历史背景</h2><p>1830 年代和 1840 年代，在 Adolphe Quetelet 的指导下，Pierre François Verhulst 将逻辑函数（logistic function）作为人口增长模型并命名为“逻辑函数”。Verhulst 在 1830 年代中期首先设计了这个函数，但没有具体说明他如何将曲线拟合到数据中。随后，在 1838 年发表了一篇简短的笔记。最后在 1844 年进行了扩展分析并命名了这个函数（1845 年出版），Verhulst 通过使曲线通过三个观察点来确定模型的三个参数，这产生了较差的预测。逻辑函数最早应用就是作为人口增长的通用模型，满足微分方程式 $\displaystyle {\frac {dP}{dt}}=rP\left(1-{\frac {P}{K}}\right)$，其中，$P$ 代表种群大小，$t$ 代表时间，常数 $r$ 定义为增长率，$K$ 是承载容量，微分方程结果为 $\displaystyle P(t)={\frac {K}{1+\left({\frac {K-P_{0}}{P_{0}}}\right)e^{-rt}}}$，$\displaystyle \frac {K-P_{0}}{P_{0}}$ 是常数可以移动到指数上，相当于对 $t$ 进行平移，就可以得到逻辑函数标准形式。</p><p>1883 年，逻辑函数在化学领域中独立开发出来作为自催化模型（Wilhelm Ostwald）。自催化反应是指反应中的一种产物本身就是同一反应的催化剂，而其中一种反应物的供应是固定的。出于与人口增长相同的原因，这自然会产生逻辑方程：反应是自我强化的，但受到限制。</p><p>1920 年，逻辑函数被 Raymond Pearl 和 Lowell Reed 再次独立地发现为人口增长的模型，这导致它在现代统计学中的应用。Pearl 和 Reed 将该模型首次应用于美国人口，并通过三个点对曲线进行了初步拟合，与 Verhulst 一样，这再次产生了糟糕的结果。他们最初不知道 Verhulst 的工作，大概是从 L. Gustave du Pasquier 那里了解到的，但他们没有给他多少信任，也没有采用他的术语。 在 1925 年，Verhulst 的优先权得到承认，Udny Yule 重新使用了“logistic”一词，并一直沿用至今。</p><p>1930 年代，概率模型（probit model）由 Chester Ittner Bliss 开发和系统化，并且 John Gaddum 通过 Ronald A. Fisher 的最大似然估计拟合该模型。probit 模型主要用于生物测定，早在 1860 年的工作就已经开始了。probit 模型影响了 logit 模型的后续发展。</p><p>1943 年，逻辑模型（logistic model）可能首先被 Edwin Bidwell Wilson 和他的学生 Jane Worcester 用作生物测定中概率模型的替代方案。然而，logistic 模型作为 probit 模型的一般替代方案的发展主要归功于 Joseph Berkson 数十年来的工作，从 1944年开始，他通过与“probit”类比创造了“logit”。logit 模型最初被认为不如 probit 模型，但“逐渐达到了与 probit 平等的地位”，特别是在 1960 年至 1970 年间。到 1970 年，统计期刊中使用logit 模型与 probit 模型数量相当，然后前者超越了后者。这种相对流行是由于在生物测定之外采用了 logit，而不是在生物测定中取代 probit，以及它在实践中的非正式使用；logit 的受欢迎程度归功于 logit 模型的计算简单性、数学特性和通用性，允许其在各种领域中使用。</p><p>1966年，多项式logit模型由 David Cox 引入，大大增加了logit模型的应用范围和普及度。1973 年，Daniel McFadden 将多项式 logit 与离散选择理论，特别是 Luce 的选择公理联系起来，表明多项式 logit 遵循 independence of irrelevant alternatives (IIA) 假设并将备选方案的几率解释为相对偏好，这给出了一个逻辑回归的理论基础。</p><h2 id="2-算法模型"><a href="#2-算法模型" class="headerlink" title="2. 算法模型"></a>2. 算法模型</h2><p>逻辑回归实际上是分类模型，之所以名字中带有回归，我想是因为它是对概率值进行回归的。逻辑回归是对事件发生的概率进行建模，根据分类事件的数量分为二元逻辑回归和多元逻辑回归，</p><h3 id="2-1-逻辑函数"><a href="#2-1-逻辑函数" class="headerlink" title="2.1 逻辑函数"></a>2.1 逻辑函数</h3><p>阐述逻辑回归模型之前，先介绍一下逻辑函数（logistic function）。</p><p>逻辑函数的公式如下</p><script type="math/tex; mode=display">\displaystyle f(x)={\frac {L}{1+e^{-k(x-x_{0})}}}</script><p>式中，$x_0$ 是曲线的中点坐标，$L$ 是曲线的最大值，$k$ 是逻辑增长率或曲线的陡度。逻辑函数最早用于人口增长预测，$f(x)$ 是人口数量，$x$ 代表时间。</p><p>当 $\displaystyle L=1,k=1,x_{0}=0$ 时就得到了 sigmoid 函数</p><script type="math/tex; mode=display">\displaystyle f(x)={\frac {1}{1+e^{-x}}}</script><p>与正态分布函数进行类比，逻辑函数改为</p><script type="math/tex; mode=display">\displaystyle f(x)={\frac {1}{1+e^{-(x-\mu )/s}}}</script><p>该函数图形如图所示，是一条 S 形曲线（sigmoid curve），可以发现形状与正态分布函数相似。该函数曲线以点 $\displaystyle(\mu,\frac{1}{2})$ 为中心对称，满足 </p><script type="math/tex; mode=display">f(x)=1-f(-x)</script><p>逻辑函数还有一个非常好的性质，就是其导数易求</p><script type="math/tex; mode=display">f'(x)=f(x)(1-f(x))</script><p>逻辑函数的导函数满足概率密度公式的要求，因此逻辑函数就是一种概率分布函数，至于为什么在分类问题中比正态分布好用还需考证。</p><p>logistic model 与 probit model 的区别就是在于使用逻辑函数取代了正态分布函数。</p><h3 id="2-2-二元逻辑回归"><a href="#2-2-二元逻辑回归" class="headerlink" title="2.2 二元逻辑回归"></a>2.2 二元逻辑回归</h3><p>假设有数据集</p><script type="math/tex; mode=display">D=\{(x_1,y_1),(x_2,y_2),\dots,(x_k,y_k),\dots,(x_N,y_N)\}</script><p>二元逻辑回归就是在分类数是 2 的情况下，也就是二项分布的情况下的逻辑回归。回忆一下伯努利分布，其中的 $y=1$ 事件对应的概率分布就是由逻辑函数 $f(x)$ 给出，由于与 $x$ 有关，因此很明显是条件概率，如下所示</p><script type="math/tex; mode=display">p(y=1|\, x)={\frac {1}{1+e^{-(x-\mu )/s}}}</script><p>由于是二项分布，因此</p><script type="math/tex; mode=display">p(y=0|\, x)=1 - p(y=1|\, x)</script><p>我们用 $p(x)$ 对 $p(y=1|\, x)$ 进行简写，同时把上式标准化</p><script type="math/tex; mode=display">\displaystyle p(x)={\frac {1}{1+e^{-(\beta _{0}+\beta _{1}x)}}}</script><p>其中 $\beta_0=-\mu/s$ 称为截距，$\beta_1=1/s$。那么对特征 $x_k$ 的类别 $y_k$ 概率拟合就是</p><script type="math/tex; mode=display">p_k=p(x_k)</script><p>有了概率分布之后，我们只需要用最大似然估计确定参数的值即可。如前所说，二元逻辑回归就是在伯努利分布的情况下，那么伯努利分布的似然函数就是</p><script type="math/tex; mode=display">\begin{aligned}    \displaystyle L&= \prod _{k:y_{k}=1}p_{k}\,\prod _{k:y_{k}=0}(1-p_{k})\\    &= \prod^N_{k=1}p_{k}^{y_k}(1-p_{k})^{1-y_k}\\\end{aligned}</script><p>对 $L$ 取对数，得到对数似然函数</p><script type="math/tex; mode=display">\begin{aligned}    \displaystyle \ell&=\sum _{k:y_{k}=1}\ln(p_{k})+\sum _{k:y_{k}=0}\ln(1-p_{k})\\    &= \sum _{k=1}^{N}\left(\,y_{k}\ln(p_{k})+(1-y_{k})\ln(1-p_{k})\right)\\\end{aligned}</script><p>上式是有关 $\beta_0,\beta_1$ 的函数，为了使对数似然函数最大，分别对 $\beta_0,\beta_1$ 求偏导数</p><script type="math/tex; mode=display">\displaystyle {\frac {\partial \ell }{\partial \beta _{0}}}=\sum _{k=1}^{K}(y_{k}-p_{k})</script><script type="math/tex; mode=display">\displaystyle {\frac {\partial \ell }{\partial \beta _{1}}}=\sum _{k=1}^{K}(y_{k}-p_{k})x_{k}</script><p>结果和线性回归太相似了，$p_k$ 如果是线性函数，那么上式就是线性回归。事实上，$p(x)$ 的作用就是将线性函数 $\beta _{0}+\beta _{1}x$ 的结果映射到 $[0,1]$ 概率区间。如果让上式分别等于 0，则得到似然方程。</p><p>不过，尽管结果相似，但上式是非线性的，因此无法像线性回归一样，求出似然方程组的解析解。因此，需要用数值方法，如牛顿迭代法和梯度下降法等等。牛顿迭代法是求解的似然方程组，梯度下降法则是直接求似然函数的极值，区别在于牛顿迭代法需要二次导数。下面给出梯度下降法的计算公式，其实很简单，沿与梯度相反的方向移动即可，导数已经给出，梯度则为</p><script type="math/tex; mode=display">\bigtriangledown p(\beta_0,\beta_1)=(\frac {\partial \ell }{\partial \beta _{0}},\frac {\partial \ell }{\partial \beta _{1}})</script><p>假设第 $t$ 次的迭代结果为 $\beta^t_0,\beta^t_1$，则</p><script type="math/tex; mode=display">\beta^{t+1}_0=\beta^t_0-\alpha\sum _{k=1}^{K}(y_{k}-{\frac {1}{1+e^{-(\beta^t_0+\beta^t_1x_k)}}})</script><script type="math/tex; mode=display">\beta^{t+1}_1=\beta^t_1-\alpha\sum _{k=1}^{K}(y_{k}-{\frac {1}{1+e^{-(\beta^t_0+\beta^t_1x_k)}}})x_{k}</script><p>上面求解的是简单的情况，只有一个特征。进一步地，将上面结果推广到具有多个特征的情况。</p><p>用矩阵形式表述如下：$X$ 是样本特征矩阵，大小为 $m\times n$，$n$ 是特征维度加1，$m$ 是样本数量，第 $i$ 行形如 $[1, x_1^{(i)}, x_2^{(i)}, x_3^{(i)},\dots, , x_{n-1}^{(i)}]$；$\mathbf{w}$ 是 $n\times1$ 系数向量，形如 $[\beta_1,\beta_2,\dots,\beta_n]^T$；$\mathbf y$ 是 $m\times1$ 列向量，形如 $[y_1,y_2,\dots,y_m]^T$，每个元素取值 $0$ 或 $1$，其中只有一个元素为 $1$；$\mathbf 1^T$ 为值均为 $1$ 的列向量。逻辑函数为</p><script type="math/tex; mode=display">p(X\mathbf{w})={\frac {1}{1+e^{-X\mathbf{w}}}}</script><p>对数似然函数的矩阵形式为</p><script type="math/tex; mode=display">\ell(\mathbf{w})=\mathbf y^T\ln p(X\mathbf{w})+(\mathbf 1^T-\mathbf y^T)\ln(\mathbf 1-p(X\mathbf{w}))</script><p>根据逐元素函数法则，逻辑函数的微分</p><script type="math/tex; mode=display">\begin{aligned}    \mathrm{d}p(X\mathbf{w})&=p'(X\mathbf{w})\odot\mathrm{d}X\mathbf{w} \\    &= p(X\mathbf{w})\odot(\mathbf 1-p(X\mathbf{w}))\odot ((\mathrm{d}X)\mathbf{w}+X\mathrm{d}\mathbf{w}) \\    &=p(X\mathbf{w})\odot(\mathbf 1-p(X\mathbf{w}))\odot X\mathrm{d}\mathbf{w}\end{aligned}</script><p>$\ln$ 函数的微分</p><script type="math/tex; mode=display">\mathrm{d}\ln Y=Y^{-1}\odot\mathrm{d}Y</script><p>因此可以得到</p><script type="math/tex; mode=display">\begin{aligned}\mathrm{d}\ell(\mathbf{w})&=\mathbf y^T(p(X\mathbf{w}))^{-1}\odot p(X\mathbf{w})\odot(\mathbf 1-p(X\mathbf{w}))\odot X\mathrm{d}\mathbf{w} \\&+(\mathbf 1^T-\mathbf y^T)(\mathbf 1-p(X\mathbf{w}))^{-1}\odot -p(X\mathbf{w})\odot(\mathbf 1-p(X\mathbf{w}))\odot X\mathrm{d}\mathbf{w} \\&=\mathbf y^T(\mathbf 1-p(X\mathbf{w}))\odot X\mathrm{d}\mathbf{w} - (\mathbf 1^T-\mathbf y^T)p(X\mathbf{w})\odot X\mathrm{d}\mathbf{w} \\\end{aligned}</script><p>将上式套上迹</p><script type="math/tex; mode=display">\begin{aligned}\mathrm{d}\ell(\mathbf{w})&=\mathrm{tr}(\mathbf y^T(\mathbf 1-p(X\mathbf{w}))\odot X\mathrm{d}\mathbf{w}- (\mathbf 1^T-\mathbf y^T)p(X\mathbf{w})\odot X\mathrm{d}\mathbf{w})\\&=\mathrm{tr}([\mathbf y\odot(\mathbf 1-p(X\mathbf{w}))]^TX\mathrm{d}\mathbf{w} - [(\mathbf 1-\mathbf y)\odot p(X\mathbf{w})]^T X\mathrm{d}\mathbf{w})\\&=\mathrm{tr}([\mathbf y-\mathbf y\odot p(X\mathbf{w})]^TX\mathrm{d}\mathbf{w} - [p(X\mathbf{w})-\mathbf y\odot p(X\mathbf{w})]^T X\mathrm{d}\mathbf{w})\\&=\mathrm{tr}(\mathbf y ^ TX\mathrm{d}\mathbf{w} - p(X\mathbf{w})^T X\mathrm{d}\mathbf{w})\\&=\mathrm{tr}([X^T(\mathbf y- p(X\mathbf{w}) )]^T\mathrm{d}\mathbf{w})\\\end{aligned}</script><p>根据微分与导数的关系</p><script type="math/tex; mode=display">\mathrm{d}f=\mathrm{tr}(\frac {\partial f }{\partial X}^T \mathrm{d}X)</script><p>就可以得到</p><script type="math/tex; mode=display">\frac {\partial f }{\partial \mathbf{w}}=X^T(\mathbf y- p(X\mathbf{w}) )</script><p>迭代公式</p><script type="math/tex; mode=display">\mathbf{w}=\mathbf{w}-\alpha X^T(\mathbf y- p(X\mathbf{w}) )</script><h3 id="2-3-多元逻辑回归"><a href="#2-3-多元逻辑回归" class="headerlink" title="2.3 多元逻辑回归"></a>2.3 多元逻辑回归</h3><p>一个事件的几率（odds）是指该事件的发生的概率与不发生的概率的比值。如果一个事件发生的概率 $p$，则不发生的概率为 $1-p$，那么该事件的几率为 $\displaystyle\frac{p}{1-p}$，该事件的对数几率或 logit 函数是</p><script type="math/tex; mode=display">\mathrm{logit}(p)=\ln \frac{p}{1-p}</script><p>对于逻辑回归，一定满足</p><script type="math/tex; mode=display">\ln \frac{p}{1-p}=\mathbf{w}\cdot\mathbf x</script><p>假设多元逻辑回归事件的类别分别为 $1,2,\dots,K$。多元逻辑回归相较于二元逻辑回归，概率计算公式不变</p><script type="math/tex; mode=display">\displaystyle p(\mathbf x)={\frac {1}{1+e^{-\mathbf{w}\cdot\mathbf x}}}</script><p>区别在于对于同一个实例，它所有类别的概率和为 1。在二元逻辑回归中，$y=0$ 时的概率就是 $1-p$，因此只需要一组参数即可，而在多元逻辑回归中， $K$ 个类别分别对应一组参数</p><script type="math/tex; mode=display">\ln \frac{p(y=1|\mathbf x)}{1-p(y=0|\mathbf x)}=\mathbf w_1\cdot\mathbf x</script><script type="math/tex; mode=display">\ln \frac{p(y=2|\mathbf x)}{1-p(y=0|\mathbf x)}=\mathbf w_2\cdot\mathbf x</script><script type="math/tex; mode=display">\cdots</script><p>同时满足</p><script type="math/tex; mode=display">\sum_{i=1}^Kp(y=i|\mathbf x)=1</script><p>最终解得</p><script type="math/tex; mode=display">p(y=k|\mathbf x)=\frac{e^{\mathbf w_k\cdot\mathbf x}}{\displaystyle 1+\sum_{i=1}^{K-1}e^{\mathbf w_i\cdot\mathbf x}}</script><script type="math/tex; mode=display">p(y=K|\mathbf x)=\frac{1}{\displaystyle 1+\sum_{i=1}^{K-1}e^{\mathbf w_i\cdot\mathbf x}}</script><p>实际上就是 softmax 函数的一种特例，输出的结果为 $k-1$ 个，因为概率和为 1，自然可以求出最后剩下的一个概率值。其实也可以输出 $k$ 个结果，概率的计算公式为</p><script type="math/tex; mode=display">p(y=k|\mathbf x)=\frac{e^{\mathbf w_k\cdot\mathbf x}}{\displaystyle \sum_{i=1}^Ke^{\mathbf w_i\cdot\mathbf x}}</script><p>我们采用后一种方式，似然函数为</p><script type="math/tex; mode=display">L=\prod_{i=0}^mp_1(\mathbf{x}_i)^{y_i^1}p_2(\mathbf{x}_i)^{y_i^2}\dots p_k(\mathbf{x}_i)^{y_i^K}</script><p>对于一组输入 $\mathbf{x}_i$，$(y_i^1,y_i^2,\dots,y_i^K)$ 中只有一个值为 $1$，其他为 $0$。对数似然函数即为</p><script type="math/tex; mode=display">\ell=\sum_{i}\sum_ky_i^k\log p_k(\mathbf{x}_i)</script><p>将对数似然函数写成矩阵形式，对于每一组实例</p><script type="math/tex; mode=display">\ell=\mathbf{y}^T\log \mathrm{softmax}(W\mathbf{x})</script><p>其中，$\mathbf{y}$ 是除一个元素为 $1$ 外其元素为 $0$ 的 $m\times1$ 列向量，$W$ 为 $m\times n$ 矩阵，$\mathbf{x}$ 为 $n\times1$ 列向量，$\displaystyle\mathrm{softmax}(\mathbf{z})=\frac{\exp(\mathbf{z})}{\mathbf{1}^T\exp(\mathbf{z})}$，其中 $\exp$ 表示逐元素求指数，$\mathbf{1}$ 表示值均为 $1$ 的列向量；$\ell$ 为标量。</p><p>将 $\mathrm{softmax}$ 带入 $\ell$</p><script type="math/tex; mode=display">\begin{aligned}    \ell&=\mathbf{y}^T\left(\log \exp(W\mathbf{x})-\mathbf{1}\log \mathbf{1}^T\exp(W\mathbf{x})\right)\\    &=\mathbf{y}^TW\mathbf{x}-\log\left( \mathbf{1}^T\exp(W\mathbf{x})\right)\end{aligned}</script><p>在这里用到了 $\log(\mathbf{u}/c)=\log\mathbf{u}-\mathbf{1}\log c$，以及 $\mathbf{y}^T\mathbf{1}=1$。</p><p>进行微分</p><script type="math/tex; mode=display">\begin{aligned}    \mathrm{d}\ell&=\mathrm{d}(\mathbf{y}^TW\mathbf{x})-\mathrm{d}\left(\log( \mathbf{1}^T\exp(W\mathbf{x}))\right)\\    &=\mathbf{y}^T\mathrm{d}W\mathbf{x}-(\mathbf{1}^T\exp(W\mathbf{x}))^{-1}\odot \mathrm{d}(\mathbf{1}^T\exp(W\mathbf{x}))\\    &=\mathbf{y}^T\mathrm{d}W\mathbf{x}-(\mathbf{1}^T\exp(W\mathbf{x}))^{-1}\odot \mathbf{1}^T\mathrm{d}(\exp(W\mathbf{x}))\\    &=\mathbf{y}^T\mathrm{d}W\mathbf{x}-(\mathbf{1}^T\exp(W\mathbf{x}))^{-1}\odot \mathbf{1}^T\left(\exp(W\mathbf{x})\odot\mathrm{d}(W\mathbf{x})\right)\\\end{aligned}</script><p>其中</p><script type="math/tex; mode=display">\mathbf{1}^T\left(\exp(W\mathbf{x})\odot\mathrm{d}(W\mathbf{x})\right)=(\mathbf{1}\odot \exp(W\mathbf{x}))^T\mathrm{d}(W\mathbf{x})=\exp(W\mathbf{x})^T\mathrm{d}(W\mathbf{x})</script><p>带入原式并且套上迹</p><script type="math/tex; mode=display">\begin{aligned}    \mathrm{d}\ell&=\mathrm{tr}\left(\mathbf{y}^T\mathrm{d}W\mathbf{x}-\frac{\exp(W\mathbf{x})^T\mathrm{d}(W\mathbf{x})}{\mathbf{1}^T\exp(W\mathbf{x})}\right)\\    &=\mathrm{tr}\left(\mathbf{y}^T\mathrm{d}W\mathbf{x}-\mathrm{softmax}(W\mathbf{x})^T\mathrm{d}(W\mathbf{x})\right)\\    &=\mathrm{tr}\left(\mathbf{x}(\mathbf{y}-\mathrm{softmax}(W\mathbf{x}))^T\mathrm{d}W\right)\\\end{aligned}</script><p>根据微分与导数的关系</p><script type="math/tex; mode=display">\mathrm{d}f=\mathrm{tr}(\frac {\partial f }{\partial X}^T \mathrm{d}X)</script><p>因此</p><script type="math/tex; mode=display">\frac {\partial f }{\partial W}=(\mathbf y- \mathrm{softmax}(W\mathbf{x}))\mathbf{x}^T</script><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><blockquote><p><a href="https://en.wikipedia.org/wiki/Logistic_regression">1. Logistic regression - Wikipedia</a><br><a href="https://papers.tinbergen.nl/02119.pdf">2. Cramer, J. S. (2002). The origins of logistic regression</a><br><a href="https://synapse.koreamed.org/upload/synapsedata/pdfdata/0006jkan/jkan-43-154.pdf">3. An Introduction to Logistic Regression: From Basic Concepts to Interpretation with Particular Attention to Nursing Domain</a><br><a href="https://ftp.idu.ac.id/wp-content/uploads/ebook/ip/REGRESI%20LOGISTIK/Practical%20Guide%20to%20Logistic%20Regression%20(%20PDFDrive%20">4. Practical Guide to Logistic Regression</a>.pdf)<br><a href="https://en.wikipedia.org/wiki/Logistic_function">5. Logistic function - Wikipedia</a><br><a href="https://www.cnblogs.com/pinard/p/6029432.html">6. 逻辑回归原理小结 - 刘建平</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;h1 id=&quot;逻辑回归&quot;&gt;&lt;a href=&quot;#逻辑回归&quot; class=&quot;headerlink&quot; title=&quot;逻辑回归&quot;&gt;&lt;/a&gt;逻辑回归&lt;/h1&gt;&lt;h2 id=&quot;1-历史背景&quot;&gt;&lt;a href=&quot;#1-历史背景&quot; class=&quot;</summary>
      
    
    
    
    <category term="Machine learning" scheme="http://example.com/categories/Machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2022/02/07/ProbabilityStatistics/1.random%20events%20and%20their%20probabilities/"/>
    <id>http://example.com/2022/02/07/ProbabilityStatistics/1.random%20events%20and%20their%20probabilities/</id>
    <published>2022-02-07T01:35:19.954Z</published>
    <updated>2022-03-28T00:31:30.411Z</updated>
    
    <content type="html"><![CDATA[<h1 id="随机事件及其概率"><a href="#随机事件及其概率" class="headerlink" title="随机事件及其概率"></a>随机事件及其概率</h1><h2 id="1-随机事件及其运算"><a href="#1-随机事件及其运算" class="headerlink" title="1. 随机事件及其运算"></a>1. 随机事件及其运算</h2><ul><li><strong>随机现象</strong>：在一定条件下，并不总是出现相同结果的现象。</li><li><strong>随机试验</strong>：可重复的随机现象。</li><li><strong>基本结果 $\omega$</strong>：随机现象的最简单的结果，它将是统计中抽样的基本单元，故又称样本点。</li><li><strong>基本空间 $\Omega$</strong>：随机现象所有基本结果的全体。</li><li><strong>随机事件</strong>：随机现象某些基本结果组成的集合，简称“事件”。</li></ul><blockquote><p>抛硬币的结果就是一个随机现象，具有两个基本结果，正面和反面。随机现象所有基本结果的全体就称为这个随机现象的基本空间。在统计学中，基本结果 $\omega$ 是抽样的基本单元，故基本结果又称 <strong>样本点</strong>，基本空间又称 <strong>样本空间</strong> ，抛硬币的基本空间：</p><script type="math/tex; mode=display">\Omega_1=\{\omega_0,\omega_1\}=\{正面，反面\}</script><p>掷一颗骰子，“出现6点”、“出现偶数点”、“出现点数不超过2”都是<strong>随机事件</strong>，可以用其基本空间 $\Omega =\{1,2,3,4,5,6\}$ 的某个子集表示，例如“出现偶数点”可以表示为：</p><script type="math/tex; mode=display">A=\{2,4,6\}</script></blockquote><ul><li><strong>必然事件</strong> </li><li><strong>不可能事件</strong> </li><li><strong>事件的关系</strong><ul><li>事件的包含</li><li>事件的相等</li><li>事件的互不相容</li></ul></li><li><strong>事件的运算</strong> ：事件的基本运算对立、并、交和差，与集合的四种运算余、并、交和差是完全一样的。<ul><li>对立事件：设 $A$ 为一个试验里的事件，则由不在 $A$ 中的一切基本结果组成的事件称为 $A$ 的对立事件，记为 $\overline{A}$。必然事件和不可能事件互为对立事件。</li><li>事件 $A$ 和 $B$ 的并：由事件 $A$ 和 $B$中所有的基本结果组成的一个新事件，记作$A\bigcup B$</li><li>事件 $A$ 和 $B$ 的交：由事件 $A$ 和 $B$中公共的的基本结果组成的一个新事件，记作$A\bigcap B$ 或者 $AB$</li><li>事件 $A$ 对 $B$ 的差：由在事件 $A$ 而不在事件 $B$ 中的基本结果组成的一个新事件，记作$A-B$。$A-B=A-AB=A\overline{B}$</li></ul></li></ul><h2 id="2-事件的概率"><a href="#2-事件的概率" class="headerlink" title="2. 事件的概率"></a>2. 事件的概率</h2><h3 id="2-1-事件的概率"><a href="#2-1-事件的概率" class="headerlink" title="2.1 事件的概率"></a>2.1 事件的概率</h3><p>随机事件的发生是带有偶然性的。但随机事件发生的可能性还是有大小之别的，是可以设法度量的。例如抛硬币正反面的可能性都是$1/2$，用一个 $0$ 到 $1$ 的数来表示一个随机事件发生的可能性大小。概率论中，这种比率就是概率的原形。</p><p><strong>定义1</strong> 在一个随机现象中，用来表示任一个随机事件 $A$ 发生可能性大小的实数（即比率）成为该事件的概率，记为 $P(A)$，并规定</p><ol><li>非负性公理：对任一事件 $A$，必有 $P(A)\ge 0$</li><li>正则性公理：必然事件的概率 $P(\Omega)=1$</li><li>可加性公理：若 $A_1$ 与 $A_2$ 是两个互不相容事件（即$A_1A_2=\emptyset$），则有 $P(A_1\bigcup A_2)=P(A_1)+P(A_2)$</li></ol><p>这就是概率的公理化定义，它虽然刻划了概率的本质，但没有告诉人们如何去确定概率。历史上概率的古典定义、概率的统计定义和概率的主观定义都有各自确定概率的方法，在有了公理化定义之后，把它们看作确定概率的三种方法是很恰当的。</p><h3 id="2-2-排列与组合"><a href="#2-2-排列与组合" class="headerlink" title="2.2 排列与组合"></a>2.2 排列与组合</h3><p>排列和组合是两类计数公式，基于如下两条计数原理：</p><ul><li><strong>乘法原理</strong></li><li><strong>加法原理</strong></li></ul><p>乘法原理，某件事需要 $k$ 个步骤，则每个步骤能选择的方法数量相乘就是总的可选择方法。加法原理，就是某件事由 $k$ 类方法可以完成，那么总的可选择方法就是这几类方法相加。</p><ul><li><strong>排列</strong>　从 $n$ 个不同元素中任取 $r(r\le n)$ 个元素排成一列称为一个排列，按乘法原理，此种排列共有 $n\times (n-1)\times \cdots \times(n-r+1)$ 个，记为 $P^r_n$。若 $r=n$，称为全排列，全排列数共有 $n!$ 个，记为 $P_n$。</li><li><strong>重复排列</strong>　从 $n$ 个不同元素中每次取出一个，放回后再取下一个，如此连续取 $r$ 次所得的排列称为重复排列，此种重复排列数共有 $n^r$ 个。这里 $r$ 允许大于 $n$。</li><li><strong>组合</strong>　从 $n$ 个不同元素中任取 $r(r\le n)$ 个元素并成一组（不考虑其间顺序）称为一个组合，按乘法原理，此种组合总数为<script type="math/tex; mode=display">\dbinom{n}{r}=\frac{P_n^r}{r!}=\frac{n\times (n-1)\times \cdots \times(n-r+1)}{r!}=\frac{n!}{r!(n-r)!}</script>并规定 $0!=1$ 和 $\dbinom{n}{r}=1$，同时 $\dbinom{n}{r}=1$ 还是二项式展开式的系数，即<script type="math/tex; mode=display">(a+b)^n=\sum^n_{r=0}\dbinom{n}{r}a^rb^{n-r}</script>若在上式中令 $a=b=1$ ，可得一重要组合恒等式：<script type="math/tex; mode=display">\dbinom{n}{0}+\dbinom{n}{1}+\cdots+\dbinom{n}{n}=2^n</script></li><li><strong>重复组合</strong>　从 $n$ 个不同元素每次取出一个，放回后再取下一个，如此连续取 $r$ 次所得的组合称为重复组合。重复组合总数为 $\dbinom{n+r-1}{r}$。</li></ul><h3 id="2-3-古典方法"><a href="#2-3-古典方法" class="headerlink" title="2.3 古典方法"></a>2.3 古典方法</h3><p>古典方法是在经验事实的基础上对被考察事件发生可能性进行符合逻辑分析后得出该事件的概率。这种方法简单、直观、不需要做试验，但只能在一类特定的随机现象中使用。基本思想如下：</p><ul><li>所涉及的随机现象只有有限个基本结果</li><li>每个基本结果出现的可能性是相同的（等可能性）</li><li>假如被考察的事件 $A$ 含有 $k$ 个基本结果，则事件 $A$ 的概率就是<script type="math/tex; mode=display">P(A)=\frac{k}{n}=\frac{A中含基本结果的个数}{\Omega中基本结果总数}</script></li></ul><p>下面以扑克游戏为例，计算每种牌型的概率。一副标准的扑克牌由52张组成，有两种颜色、四种花式和13种牌型，假设每张牌被抽出的可能性是相同的。下面来研究一些事件的概率。</p><ol><li>事件 $A=$ “抽五张牌，恰好是同花顺”。在抽五张牌的试验中，共有 $\dbinom{52}{5}$ 个等可能基本结果，事件 $A$ 包含的基本结果总数为 $10\times 4$。故事件 $A=$ 的概率为<script type="math/tex; mode=display">P(A)=\frac{10\times 4}{\dbinom{52}{5}}=\frac{40}{2598960}=0.00001539</script> 发生概率10万分之1.5</li><li>事件 $B=$ “抽五张牌，四张牌型一样”。事件 $B$ 包含的基本结果总数为 $13\times 48$。故事件 $B=$ 的概率为<script type="math/tex; mode=display">P(B)=\frac{624}{\dbinom{52}{5}}=\frac{624}{2598960}=0.00024</script> 发生的概率是万分之二，平均4167次才会发生一次。</li><li>事件 $C=$ “抽五张牌，恰好是葫芦”。事件 $C$ 包含的基本结果总数为 $13\times \dbinom{4}{3}\times 12 \times\dbinom{4}{2}=3744$<script type="math/tex; mode=display">P(C)=\frac{3744}{\dbinom{52}{5}}=\frac{3744}{2598960}=0.00144=\frac{1}{694}</script></li><li>事件 $D=$ “抽五张牌，恰好是同花，但不是顺子”。事件 $D$ 包含的基本结果总数为 $\dbinom{13}{5}\times 4 - 40=5108$<script type="math/tex; mode=display">P(D)=\frac{5108}{\dbinom{52}{5}}=\frac{5108}{2598960}=0.0019654=\frac{1}{508}</script></li><li>事件 $E=$ “抽五张牌，恰好是顺子，但不是同花”。一共有十种顺子，每种顺子按照花色的不同共有 $4^5-4$ 种结果。因此，事件 $E$ 包含的基本结果总数为 $10\times (4^5-4)=10200$<script type="math/tex; mode=display">P(E)=\frac{10200}{\dbinom{52}{5}}=\frac{10200}{2598960}=0.003924=\frac{1}{254}</script></li><li>事件 $F=$ “抽五张牌，恰好是三条，但不是葫芦”。事件 $F$ 包含的基本结果总数为 $13\times \dbinom{4}{3}\times \dbinom{48}{2} - 3744=54912$<script type="math/tex; mode=display">P(F)=\frac{54912}{\dbinom{52}{5}}=\frac{54912}{2598960}=0.021128=\frac{1}{47}</script></li><li>事件 $G=$ “抽五张牌，恰好是两对”。事件 $F$ 包含的基本结果总数为 $\dbinom{4}{2}\times \dbinom{4}{2}\times \dbinom{13}{2}\times \dbinom{11}{1}\times 4=123552$<script type="math/tex; mode=display">P(F)=\frac{54912}{\dbinom{52}{5}}=\frac{54912}{2598960}=0.04753=\frac{1}{21}</script></li><li>事件 $H=$ “抽五张牌，恰好有一对”。事件 $F$ 包含的基本结果总数为 $\dbinom{4}{2}\times \dbinom{13}{1}\times \dbinom{12}{3}\times 4^3=1098240$<script type="math/tex; mode=display">P(F)=\frac{1098240}{\dbinom{52}{5}}=\frac{1098240}{2598960}=0.42256=\frac{1}{2}</script></li></ol><h3 id="2-3-频率方法"><a href="#2-3-频率方法" class="headerlink" title="2.3 频率方法"></a>2.3 频率方法</h3><p>频率方法是在大量重复试验中用频率去获取概率近似值的一个方法。它是最常用，也是最基本获得概率的方法。基本思想如下：</p><ul><li>与考察事件 $A$ 有关的随机现象是允许进行大量重复试验的。</li><li>假如在 $N$ 次重复试验中，事件 $A$ 发生 $K_N$ 次，则事件 $A$ 发生的频率为<script type="math/tex; mode=display">P^*_N(A)=\frac{K_N}{N}=\frac{事件A发生的次数}{重复试验次数}</script></li><li>频率 $P^<em>_N(A)$ 依赖于重复次数 $N$。随着重复次数 $N$ 的增加，频率 $P^</em>_N(A)$ 会稳定在某一常数附近，这个频率的稳定值已与 $N$ 无关，就是事件 $A$ 发生的概率。在现实世界中，我们无法将一个试验无限次的重复下去，在重复次数 $N$ 较大时，频率 $P^*_N(A)$ 就很接近概率 $P(A)$ 。在统计学中把频率称为概率的估计值，实际频率当作概率近似值使用。</li></ul><h3 id="2-4-主观方法"><a href="#2-4-主观方法" class="headerlink" title="2.4 主观方法"></a>2.4 主观方法</h3><p>统计学中有一个贝叶斯学派，他们在研究随机现象之后认为，<strong>一个事件的概率是人们根据经验对该事件发生可能性所给出的个人信念</strong>。这样给出的概率就称为主观概率。</p><p>以经验为基础的主观概率和纯主观还是不同的。主观概率要求当事人对所考察的事件有较为透彻的了解和经验，并能对周围信息和历史信息进行仔细分析，在这个基础上确定的主观概率就能符合实际。</p><p>主观概率在遇到随机现象不能大量重复、无法用频率方法确定事件概率时就变得极为有用，因此在经济领域和决策分析中使用较为广泛。在某种意义上看，主观概率至少是频率方法和古典方法的一种补充，有了主观概率至少使人们在频率观点不适用时也能谈论概率，使用概率与统计方法。</p><h2 id="3-概率的性质"><a href="#3-概率的性质" class="headerlink" title="3. 概率的性质"></a>3. 概率的性质</h2><p>一些概率的常用性质</p><ul><li>定理1　$P(\overline{A})=1-P(A)$</li><li>定理2　$P(\phi)=0$</li><li>定理3　对 $n$ 个互不相容事件 $A_1,\cdots,A_n$，有<script type="math/tex; mode=display">P(\bigcap\limits^n_{i=1} A_i)=\sum^n_{i=1}P(A_i)</script></li><li>定理4　对任意两个事件 $A$ 和 $B$，若$A\supset B$，则<ul><li>$P(A-B)=P(A)-P(B)$</li><li>$P(A)\le P(B)$</li></ul></li><li>定理5　对任一事件 $A$，总有 $0\le P(A)\le 1$</li><li>定理6　对任意两个事件 $A$ 与 $B$，有<ul><li>$P(A\bigcup B)=P(A)+P(B)-P(AB)$</li><li>$P(A\bigcup B)\le P(A)+P(B)$</li></ul></li><li>定理7　对任意三个事件 $A,B,C$，有<ul><li>$P(A\bigcup B \bigcup C)=P(A)+P(B)+P(C)-P(AB)-P(AC)-P(BC)+P(ABC)$</li><li>$P(A\bigcup B \bigcup C)\le P(A)+P(B)+P(C)$</li></ul></li></ul><h2 id="4-独立性"><a href="#4-独立性" class="headerlink" title="4. 独立性"></a>4. 独立性</h2><h3 id="4-1-事件的独立性"><a href="#4-1-事件的独立性" class="headerlink" title="4.1 事件的独立性"></a>4.1 事件的独立性</h3><ul><li>定义1　对任意两个事件 $A$ 和 $B$，若有 $P(AB)=P(A)P(B)$，则称事件 $A$ 与 $B$ 相互独立，简称 $A$ 与 $B$ 独立。否则称事件 $A$ 与 $B$ 不独立。</li></ul><p>两个事件的独立性是指一个事件的发生不影响另一个事件的发生。在概率角度讲，两个事件之间的独立性与这两个事件同时发生的概率有密切关系，即两独立事件同时发生的概率等于它们各自概率的乘积。</p><p>投掷两个骰子，两个骰子的点数是互不影响的，显然任何两个分别与两个骰子相关的事件都是独立的，例如事件 $A=$ “第一颗骰子出现1点”、事件 $B=$ “第二颗骰子出现偶数点”。</p><p>但是，两事件是否具有独立性并不总是显然的。例如同样两个事件 $A=$ “家中男女孩都有”、事件 $B=$ “家里至多一个女孩”。在家中有三个小孩的情况下，这两个事件是独立的。但是，家中有两个或四个小孩时，就不再独立了。</p><ul><li>定理1　若事件 $A$ 和 $B$独立，则事件 $A$ 和 $\overline{B}$ 独立；$\overline A$ 和 $B$ 独立；$\overline A$ 和 $\overline{B}$ 独立。</li></ul><p>证：由事件的运算性质知</p><script type="math/tex; mode=display">A\overline{B}=A(1-B)=A-AB</script><p>其中 $A\supset AB$，再由 $A$ 和 $B$ 的独立性</p><script type="math/tex; mode=display">\begin{aligned}    P(A\overline{B})&= P(A)-P(AB)\\    &= P(A)-P(A)P(B)\\    &= P(A)[1-P(B)]\\    &= P(A)P(\overline{B})\\\end{aligned}</script><h3 id="4-1-试验的独立性"><a href="#4-1-试验的独立性" class="headerlink" title="4.1 试验的独立性"></a>4.1 试验的独立性</h3><p>利用事件的独立性可以定义两个或更多个试验的独立性。假设有两个试验 $E_1$ 和 $E_2$，假如试验 $E_1$ 的任一个结果与试验 $E_2$ 的任一个结果都是相互独立事件，则称这两个试验相互独立。类似的如果 $n$ 个试验相互间的任一结果之间都是相互独立的事件，则这些试验都相互独立。如果这 $n$ 个试验还是相同的，则称其为 $n$ 重独立重复试验。</p><p>$n$ 重伯努利试验是一类常见的随机模型。</p><p><strong>伯努利试验</strong>　只有两个结果的实验就称为伯努利试验，例如抛硬币（正面和反面）、检查一个产品（合格与不合格）等等。在一次伯努利试验中，设成功的概率为 $p$，即</p><script type="math/tex; mode=display">P(A)=p,P(\overline{A})=1-p</script><p><strong>$n$ 重伯努利试验</strong>　由 $n$ 个（次）相同的、独立的伯努利试验组成的随机试验称为 $n$ 重伯努利试验。伯努利试验基本结果可用长为 $n$ 的序列表示，例如$AA\overline{A}AA$ 表示第三次失败，其余四次成功。在 $n$ 重伯努利试验中，在人们最关心的是成功次数。因为成功次数是基本结果中所含的最重要信息，而 $A$ 与 $\overline{A}$ 的排列次序在实际中往往是不感兴趣的信息。记</p><script type="math/tex; mode=display">B_{n,k}=“n重伯努利试验中A出现k次”</script><p>一般概率公式为</p><script type="math/tex; mode=display">P(B_{n,k})=\dbinom{n}{k}p^k(1-p)^{n-k}</script><h2 id="5-条件概率"><a href="#5-条件概率" class="headerlink" title="5. 条件概率"></a>5. 条件概率</h2><h3 id="5-1-条件概率"><a href="#5-1-条件概率" class="headerlink" title="5.1 条件概率"></a>5.1 条件概率</h3><p>假设苹果有两个属性，一个是好看，一个是好吃。现对25个苹果进行统计，得到结果如下</p><div class="table-container"><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">$B:$好看</th><th style="text-align:center">$\overline{B}:$不好看</th><th style="text-align:center"></th></tr></thead><tbody><tr><td style="text-align:center">$A:$好吃</td><td style="text-align:center">10</td><td style="text-align:center">5</td><td style="text-align:center">15</td></tr><tr><td style="text-align:center">$\overline{A}:$不好吃</td><td style="text-align:center">8</td><td style="text-align:center">2</td><td style="text-align:center">10</td></tr><tr><td style="text-align:center"></td><td style="text-align:center">18</td><td style="text-align:center">7</td><td style="text-align:center">25</td></tr></tbody></table></div><p>思考问题，当事件 $B$ 发生后，事件 $A$ 再发生的概率是多少？由于事件 $B$ 发生了，给人们带来新的信息，即 $\overline{B}$ 不可能再发生了，所有可能发生的基本结果局限在 $B$ 的 $18$ 个结果，这时事件 $A$ 所包含的基本结果在 $\Omega_B$ 中所占的比率为 $10/18$，这就是在事件 $B$ 已经发生的情况下，事件 $A$ 的条件概率，即 $P(A|B)=10/18$。</p><p>条件概率 $P(A|B)=10/18$ 中分母是事件 $B$ 中的基本结果数，记为 $N(B)=18$。分子是事件 $A$ 和 $B$ 同时发生的基本结果数，即交事件 $AB$，记为记为 $N(AB)=10$。分子分母同时除以原基本空间 $\Omega$ 中的基本结果数 $N(\Omega)=25$，得到如下关系式</p><script type="math/tex; mode=display">P(A|B)=\frac{N(AB)}{N(B)}=\frac{N(AB)/N(\Omega)}{N(B)/N(\Omega)}=\frac{P(AB)}{P(B)}</script><p>这表明条件概率可用两个特定的无条件概率之商表示，我们可以进一步得到条件概率的一般定义。</p><p><strong>定义1</strong>　设 $A$ 与 $B$ 是基本空间 $\Omega$ 中的两个事件，且$P(B)&gt;0$，在事件 $B$ 已发生的条件下，事件 $A$ 的条件概率 $P(A|B)$ 定义为 $P(AB)/P(B)$，即</p><script type="math/tex; mode=display">P(A|B)=\frac{P(AB)}{P(B)}</script><p>其中 $P(A|B)$ 也称为给定事件 $B$ 下事件 $A$ 的条件概率。</p><p>条件概率满足概率的三条公理，非负、正则、可加。当 $B=\Omega$ 时，条件概率转化为无条件概率，因此把无条件概率看作特殊场合下的条件概率也未尝不可。</p><p>除此之外，条件概率还有一些特殊性质。</p><p><strong>定理1(乘法公式)</strong>　对任意两个事件 $A$ 和 $B$，有</p><script type="math/tex; mode=display">P(AB)=P(A|B)P(B)=P(B|A)P(A)</script><p>对两个等式，分别要求 $P(B)&gt;0$ 和  $P(A)&gt;0$。这个定理表明任意两个事件交的概率等于一事件的概率乘以在这时间已发生的条件下另一事件的条件概率，只要它们的概率都不为零。</p><p><strong>定理2</strong>　假如事件 $A$ 与 $B$ 独立，且 $P(B)&gt;0$，则 $P(A|B)=P(A)$，反之亦然。<br><br>这个性质表明，若两事件独立，则其条件概率就等于其概率，这里事件 $B$ 的发生对事件 $A$ 是否发生没有任何影响，反之，若有 $P(A|B)=P(A)$，则有乘法公式可以得出 $P(AB)=P(A)P(B)$，故 $A$ 与 $B$ 独立。</p><p><strong>定理3(一般乘法公式)</strong>　对任意三个事件 $A_1$、$A_2$、$A_3$，有</p><script type="math/tex; mode=display">P(A_1A_2A_3)=P(A_1)P(A_2|A_1)P(A_3|A_1A_2)</script><p>其中 $P(A_1A_2)&gt;0$。</p><h3 id="5-2-全概率公式"><a href="#5-2-全概率公式" class="headerlink" title="5.2 全概率公式"></a>5.2 全概率公式</h3><p>全概率公式是概率论中的一个基本公式。它可以使一个复杂事件的概率计算化繁就简，得以解决。</p><p><strong>定理4</strong>　设 $A$ 与 $B$ 是任意两个事件，假如 $0&lt;P(B)&lt;1$，则</p><script type="math/tex; mode=display">P(A)=P(A|B)P(B)+P(A|\overline{B})P(\overline{B})</script><p>证：由 $B\bigcup \overline{B}=\Omega$ 和事件运算性质可知</p><script type="math/tex; mode=display">A=A\Omega=A(B\bigcup \overline{B})=AB\bigcup A\overline{B}</script><p>显然 $AB$ 与 $A\overline{B}$ 是互不相容事件，由加法公式和乘法公式得</p><script type="math/tex; mode=display">\begin{aligned}    P(A)&= P(AB)+P(A\overline{B})\\    &= P(A|B)P(B)+P(A|\overline{B})P(\overline{B})\\\end{aligned}</script><p>由于 $P(B)$ 不为0与1，所有 $P(\overline{B})&gt;0$，从而上述两个条件概率 $P(A|B)$ 与 $P(A|\overline{B})$ 都是有意义的。</p><p>将上述全概率公式推广到一般形式，需要一个“分割”的概念。简而言之，两个互为对立的事件组成全集，当多个事件彼此之间没有交集且组成全集的时候，它们就是一个分割。</p><p><strong>定义2</strong>　把基本空间 $\Omega$ 分成 $n$ 个事件 $B_1,B_2,\cdots,B_n$，假如满足如下条件</p><ul><li>$P(B_i)&gt;0,i=1,2,\cdots,n$</li><li>$B_1,B_2,\cdots,B_n$ 互不相容</li><li>$\bigcap\limits^n_{i=1} B_i=\Omega$<br>则称事件组 $B_1,B_2,\cdots,B_n$ 为基本空间 $\Omega$ 的一个分割。</li></ul><p><strong>定理5</strong>　 设 $B_1,B_2,\cdots,B_n$ 是基本空间 $\Omega$ 的一个分割，则对 $\Omega$ 中任一事件 $A$，有</p><script type="math/tex; mode=display">P(A)=\sum_{i=1}^nP(A|B_i)P(B_i)</script><p>由全概率公式可以推出一个很著名的公式。</p><p><strong>定理6(贝叶斯公式)</strong>　设 $B_1,B_2,\cdots,B_n$ 是基本空间 $\Omega$ 的一个分割，且它们各自概率 $P(B_1),P(B_2),\cdots,P(B_n)$ 皆已知且为正，又设 $A$ 是 $\Omega$ 中的一个事件，$P(A)&gt;0$，且在诸 $B_i$ 下事件 $A$ 的条件概率 $P(A|B_1),P(A|B_2),\cdots,P(A|B_n)$ 可通过试验等手段获得，则再 $A$ 给定下，事件 $B_k$ 的条件概率为</p><script type="math/tex; mode=display">P(B_k|A)=\frac{P(A|B_k)P(B_k)}{\sum\limits^n_{i=1}P(A|B_i)P(B_i)},k=1,2,\cdots,n</script>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;随机事件及其概率&quot;&gt;&lt;a href=&quot;#随机事件及其概率&quot; class=&quot;headerlink&quot; title=&quot;随机事件及其概率&quot;&gt;&lt;/a&gt;随机事件及其概率&lt;/h1&gt;&lt;h2 id=&quot;1-随机事件及其运算&quot;&gt;&lt;a href=&quot;#1-随机事件及其运算&quot; class=&quot;</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2022/01/12/ProbabilityStatistics/4.statistics%20and%20their%20disribution/"/>
    <id>http://example.com/2022/01/12/ProbabilityStatistics/4.statistics%20and%20their%20disribution/</id>
    <published>2022-01-12T00:33:57.364Z</published>
    <updated>2022-01-12T00:33:57.365Z</updated>
    
    <content type="html"><![CDATA[<h1 id="参数估计"><a href="#参数估计" class="headerlink" title="参数估计"></a>参数估计</h1><p>参数估计不仅指总体分布 $F(x;\theta)$ 中所含的参数 $\theta$，还指分布的各种特征数，如均值、方差、标准差、相关矩，也包括各种事件的概率等。对这些参数要精确确定是困难的，只能通过样本所提供的的信息对其作出某种估计。</p><p>在本章中，设 $\theta$ 是总体的一个待估参数，$\theta$ 的一切可能取值构成的参数空间记为 $\Theta$。$X_1,X_2,\cdots,X_n$ 为从总体中抽取了一个容量为 $n$ 的样本，其观测值记为 $x_1,x_2,\cdots,x_n$</p><p>参数估计的形式主要有两种：点估计与区间估计。</p><p>参数的点估计，是构造一个统计量 $\hat{\theta}=\hat{\theta}(X_1,X_2,\cdots,X_n)$，然后用 $\hat{\theta}$ 去估计 $\theta$，称 $\hat{\theta}$ 为 $\theta$ 的点估计或估计量，简称估计，将样本观测值带入后便得到了 $\theta$ 的一个点估计值 $\hat{\theta}(x_1,x_2,\cdots,x_n)$。</p><p>参数的区间估计，则是构造两个统计量 $\hat{\theta}_L$ 与 $\hat{\theta}_U$，且$\hat{\theta}_L&lt;\hat{\theta}_U$，然后以区间$[\hat{\theta}_L,\hat{\theta}_U]$ 的形式给出未知参数 $\theta$ 的估计，事件“区间$[\hat{\theta}_L,\hat{\theta}_U]$含有$\theta$” 的概率称为置信水平。</p><p>点估计的方法有两种矩法估计与极大似然估计。</p><h2 id="1-矩法估计"><a href="#1-矩法估计" class="headerlink" title="1. 矩法估计"></a>1. 矩法估计</h2><p>1900年英国统计学家 K.Pearson 提出了一个替换原则，用样本矩去替换总体矩，后来人们就称此为矩法估计。</p><p>矩法估计的基本点是：用样本矩估计总体矩，用样本矩的相应函数估计总体矩的函数。</p><p>设 $X_1,X_2,\cdots,X_n$ 是来自某总体 $X$ 的一个样本，则样本的 $k$ 阶原点矩为：</p><script type="math/tex; mode=display">A_k=\frac{1}{n}\sum^n_{i=1}X_i^k,k=1,2,\cdots</script><p>如果总体 $X$ 的 $k$ 阶原点矩 $\mu_k=E(X^k)$ 存在，则用 $A_k$ 去估计 $\mu_k$，记为</p><script type="math/tex; mode=display">\hat{\mu_k}=A_k</script>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;参数估计&quot;&gt;&lt;a href=&quot;#参数估计&quot; class=&quot;headerlink&quot; title=&quot;参数估计&quot;&gt;&lt;/a&gt;参数估计&lt;/h1&gt;&lt;p&gt;参数估计不仅指总体分布 $F(x;\theta)$ 中所含的参数 $\theta$，还指分布的各种特征数，如均值、方差、标准</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2022/01/12/ProbabilityStatistics/2.random%20variables%20and%20its%20probability%20distributions/"/>
    <id>http://example.com/2022/01/12/ProbabilityStatistics/2.random%20variables%20and%20its%20probability%20distributions/</id>
    <published>2022-01-12T00:33:57.362Z</published>
    <updated>2022-01-12T00:33:57.363Z</updated>
    
    <content type="html"><![CDATA[<h1 id="随机变量及其概率分布"><a href="#随机变量及其概率分布" class="headerlink" title="随机变量及其概率分布"></a>随机变量及其概率分布</h1><h2 id="1-随机变量"><a href="#1-随机变量" class="headerlink" title="1. 随机变量"></a>1. 随机变量</h2><h3 id="1-1-随机变量"><a href="#1-1-随机变量" class="headerlink" title="1.1 随机变量"></a>1.1 随机变量</h3><p>人们对随机现象的兴趣常常集中在其结果的某个数量方面。例如，再检查产品的过程中关心的是不合格产品的个数。若记20个产品中不合格的个数为 $X$ ，则这个 $X$ 可能取 $0,1,2,\cdots,20$ 中任意一个数，但最终是哪一个数要看检验结果，事先不能确定，因此 $X$ 的取值带有随机性，这样的变量就称为随机变量。有了随机变量之后，有关事件的表示也方便了。如 $X=2$ 表示“20个产品中有两个不合格产品” 这一事件。</p><blockquote><p>随机变量与随机事件的关系也就类似于变量与常量的关系，所以前文中随机事件都是用 $A,B$ 之类的常量字母表示。直观来说，随机变量就是“随机取值的变量”，或者“取值随机会而定的变量”。</p></blockquote><p><strong>定义1</strong>　假如一个变量在数轴上的取值依赖于随机现象的基本结果，则称此变量为<strong>随机变量</strong>，常用大写字母 $X,Y,Z$ 等表示，其取值用小写字母 $x,y,z$ 等表示。假如一个随机变量仅去数轴上的有限个或可列个孤立点，则称此随机变量为<strong>离散随机变量</strong>。假如一个随机变量的可能取值充满数轴上的一个区间 $(a,b)$ ，则称此随机变量为<strong>连续随机变量</strong>，其中 $a$ 可以是 $-\infty$， $b$ 可以是 $+\infty$ 。</p><h3 id="1-2-随机变量的概率分布"><a href="#1-2-随机变量的概率分布" class="headerlink" title="1.2 随机变量的概率分布"></a>1.2 随机变量的概率分布</h3><p>在定义中有随机变量 $X$ 的“取值依赖于基本结果”的说法，意味着随机变量 $X$ 是基本结果 $\omega$ 的函数，即可以把 $X$ 即为 $X(\omega)$，</p><script type="math/tex; mode=display">X=X(\omega),\omega \in \Omega</script><p>对随机变量 $X$ 来说，不容许基本空间 $\Omega$ 中有一个基本结果 $\omega$ 没有实数与其对应，综上所述，随机变量也可看作定义在基本空间 $\Omega$ 的实值函数。因此，“随机变量 $X$ 的取值为 $x$” 就是满足等式 $X(\omega)=x$ 的一切 $\omega$ 组成的集合，用”$X=x$“表示，即</p><script type="math/tex; mode=display">“X=x”=\{\omega:X(w)=x\}\subset \Omega</script><p>类似的，“随机变量 $X$ 的取值小于或等于 $x$”就是满足不等式 $X(\omega)\le x$ 的一切 $\omega$ 组成的集合，用“$X\le x$”表示，即</p><script type="math/tex; mode=display">“X\le x”=\{\omega:X(w)\le x\}\subset \Omega</script><blockquote><p>当一个函数等于一个值的时候其实它就是一个方程了，因此上述就类似于 $f(x)=a$。</p></blockquote><p>上述两种形式的事件是典型事件。例如，要确定一个离散随机变量 $X$ 取值的概率，只要对其可能取值 $x_i$ 确定形如 “$X=x_i$” 事件的概率即可。而对一般随机变量 $X$ ，要确定它取值的概率，就要对任意实数 $x$ ，确定形如 “$X\le x$” 的事件概率，这类事件的概率 $P(X\le x)$ 是 $x$ 的函数，随 $x$ 变化而变化，将这个函数记为 $F(x)$ ，即为分布函数。</p><p><strong>定义2</strong>　设 $X$ 为一个随机变量，对任意实数 $x$ ，事件 $X\le x$ 的概率是 $x$ 的函数，记为</p><script type="math/tex; mode=display">F(x)=P(X\le x)</script><p>这个函数称为 $X$ 的累积概率分布函数，简称分布函数。</p><p>从分布函数定义可以得到它的一些基本性质。</p><ol><li>$0\le F(x)\le 1$。分布函数值是特定形式事件 “$X\le x$” 的概率，而概率总是在0和1之间。</li><li>$F(-\infty)=\lim\limits_{x\rightarrow -\infty}F(x)=0$。这是因为事件 “$X\le -\infty$” 是不可能事件。</li><li>$F(+\infty)=\lim\limits_{x\rightarrow +\infty}F(x)=1$。这是因为事件 “$X\le +\infty$” 是必然事件。</li><li>$F(x)$ 是非降函数，即对任意 $x_1&lt;x_2$， $F(x_1)\le F(x_2)$。这是因为事件“$X\le x_2$” 包含事件 “$X\le x_1$”。</li><li>$F(x)$ 是右连续函数，即 $F(x)=F(x+0)$，其中 $F(x+0)$ 是函数在 $x$ 处的右极限，对任意给定的 $x$，取一个下降数列 $\{x_n\}$，使其极限为 $x$ ，即<script type="math/tex; mode=display">x_1>x_2>\cdots>x_n>\cdots\rightarrow x</script></li></ol><script type="math/tex; mode=display">F(x+0)=\lim\limits_{x_n\rightarrow x}F(x)</script><p><strong>可列可加性公理</strong>　若 $A_1,A_2,\cdots$ 是一列互不相容事件，则有</p><script type="math/tex; mode=display">P(\bigcup\limits _{n=1}^\infty A_n)=\sum _{n=1}^\infty P(A_n)</script><p>此公理与非负性公理、正则性公理一起组成新的公理体系，它使可列个事件经运算后所得事件可谈及概率。</p><h2 id="2-离散随机变量"><a href="#2-离散随机变量" class="headerlink" title="2. 离散随机变量"></a>2. 离散随机变量</h2><p><strong>定义3</strong>　设 $X$ 是离散随机变量，它的所有可能取值时 $x_1,x_2,\cdots,x_n,\cdots$，假如 $X$ 取 $x_i$ 的概率为</p><script type="math/tex; mode=display">P(X=x_i)=p(x_i)\ge 0,i=1,2,\cdots,n,\cdots</script><p>且满足如下条件：</p><script type="math/tex; mode=display">\sum_{i=1}^\infty p(x_i)=1</script><p>则称这组概率 $\{p(x_i)\}$ 为该随机变量 $X$ 的<strong>分布列</strong>，或 $X$ 的<strong>概率分布</strong>，记为 $X\sim\{p(x_i) \}$，读成随机变量 $X$ 服从分布 $\{p(x_i)\}$ 。<br>若已知离散随机变量 $X$ 的分布列为 $\{p(x_i)\}$ ，容易写出 $X$ 的分布函数</p><script type="math/tex; mode=display">F(x)=\sum_{x_i\le x}p(x_i)</script><p>但在离散随机变量场合，使用分布列更为方便，故常用分布列表示离散随机变量的概率分布，非必要不使用分布函数。</p><p>分布列还有两种图表示方法：线条图与概率直方图。</p><h3 id="2-1-离散随机变量的数学期望"><a href="#2-1-离散随机变量的数学期望" class="headerlink" title="2.1 离散随机变量的数学期望"></a>2.1 离散随机变量的数学期望</h3><p>“期望”在日常生活中常指有根据的希望，或发生可能性较大的希望，例如一台冰箱期望的使用寿命是10年，并不是指到10年的时间就一定坏，而是或早或晚都有可能。“期望”就是指用概率分布算得的一种加权平均。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;随机变量及其概率分布&quot;&gt;&lt;a href=&quot;#随机变量及其概率分布&quot; class=&quot;headerlink&quot; title=&quot;随机变量及其概率分布&quot;&gt;&lt;/a&gt;随机变量及其概率分布&lt;/h1&gt;&lt;h2 id=&quot;1-随机变量&quot;&gt;&lt;a href=&quot;#1-随机变量&quot; class=&quot;</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2022/01/12/ComputerScience/1.information%20layer/"/>
    <id>http://example.com/2022/01/12/ComputerScience/1.information%20layer/</id>
    <published>2022-01-12T00:33:57.350Z</published>
    <updated>2022-01-12T00:33:57.350Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-信息层-数据存储"><a href="#1-信息层-数据存储" class="headerlink" title="1 信息层-数据存储"></a>1 信息层-数据存储</h1><h2 id="1-1-二进制和记数系统"><a href="#1-1-二进制和记数系统" class="headerlink" title="1.1 二进制和记数系统"></a>1.1 二进制和记数系统</h2><p>基数（base）：记数系统的基本数值，规定了这个系统中使用的数字量和数位位置的值。</p><p>位置记数法（positional notation）：一种表达数字的系统，数位按顺序排列，每个数位又一个位置，数字的值是每个数位和位值的乘积之和，即用记数系统的基数的多项式表示值。</p><p>不同进制之间的相互转换</p><ul><li>二进制数字（binary digit）：二进制记数系统中的一位数字，可以是0或1，在计算机中每个存储位为高电平和低电平两种信号，每个存储单元即为一个二进制数字。</li><li>位（bit）：二进制数字的简称。</li><li>字节（byte）：8个二进制位。</li><li>字（word）：一个或多个字节，字中的位数称为计算机的字长</li></ul><h2 id="1-2-数据形式"><a href="#1-2-数据形式" class="headerlink" title="1.2  数据形式"></a>1.2  数据形式</h2><p>计算机可以处理各种各样的信息，可以存储、表示和帮助我们修改各种类型的数据</p><ul><li>数据（data）：基本值或事实，未组织过的，缺少context，</li><li>信息（information）：用有效的方式组织或处理过的数据，可以帮助我们回答问题。</li><li>多媒体（multimedia）：集中不同的媒体类型。</li><li>数据压缩（data compression）：减少存储一段数据所需的空间。</li><li>带宽（bandwidth）：在固定时间内从一个地点传输到另一个地点的最大位数或字节数。</li><li>压缩率（compression ratio）：压缩后的数据大小除以原始数据大小的值。</li><li>无损压缩（lossless compression）：不会丢失信息的数据压缩技术。</li><li>有损压缩（lossy compression）：会丢失信息的数据压缩技术。</li></ul><p>表示数据的方法有两种，模拟法和数字法。模拟数据是一种连续表示法，模拟它表示的真实信息，数字数据是一种离散表示法，把信息分割成独立的元素。模拟数据完全对应于我们周围无限连续的世界。因此，计算机不能很好的处理模拟数据，需要数字化数据，即把信息分割成片段并单独表示每个片段。<br>数字信号只能在两个极端之间跳跃，称为脉冲编码调制（PCM）。数字信号在信息丢失之前会降级相当多，因为大于某个阈值的电平值被看作高电平。数字信号会被周期性重新计时，以恢复到它的原始状态。</p><p>1.3  数字数据表示法<br>1.3.1  负数表示法<br>符号数值表示法 signed-magnitude representation，符号表示数所属的分类（正数或负数）、值表示数的量值的数字表示法。对带符号的整数执行加减法可以被描述为向一个方向或另一个方向移动一定数字单位。符号数值表示法存在问题，即表示0的方法有两种，+0或-0，在计算机中会引起不必要的麻烦。<br>十进制补码 （ten’s complement），一种负数表示法，负数I用10的k次幂减I表示。</p><p>二进制补码（ two’s complement），位模式最左边的二进制位指明了所表示的数值的符号，0为正，1为负（指明符号的同时，0变为1，也可以理解为在数的基础上加2^n，例如八位中，0加上了128，则用128表示-128，127加上128，则用255表示-1。因此，在二进制补码中11111111，不表示-127，而是表示-1）。假定数字只能用八位表示，七位表示数值，一位表示符号，则取值范围为-128～127。与十进制补码相类似：<br>-2 = 2^7 - 2 = 128 - 2 = 126<br>十进制数126用二进制表示为1111110，左边添加一位符号位变为11111110。<br>除了用公式计算，在二进制中还有更简单的方法计算二进制补码，当知道5的二进制数，如何得到-5的二进制数？<br>方法一：将每一位取反再加一<br>5:  00000101<br>取反：11111010<br>    +1：11111011 = 251<br>方法二：从右向左，直到第一个二进制1（包括），他们都是相同的。然后，以这个1为分界线，左面的位模式取反。<br>5:  00000101<br>-5:  11111011<br>二进制补码的加减法：二进制补码记数法的一个主要优点在于，减法可以转化为加法，从而可以使用相同的电路来实现。7-5与7+（-5）是一样的。因此，在计算机中执行7（0111）减去5（0101），将5转换为-5（1011），再执行0111+1011=0010=2。<br>溢出（overflow）：当给结果预留的位数存不下计算出的值的状况时。在二进制补码记数法中，如果两个正值相加的结果是负值，或者两个负值相加的结果为正，那么就发生了溢出问题。<br>127+3 ：01111111+00000011=10000010   在二进制补码中，第一位是符号位结果为-126。但如果表示的不是负数时，结果就是130将是正确的。<br>余码计数法（excess notation）<br>1.3.2  实数表示法<br>在计算中，非整数的值称为实值。实数具有整数部分和小数部分，每个部分都可能是0。位置记数法中，数字的位置表示数值，位值是由基数决定的。在十进制中，小数点左侧的位值有1、10、100等等，它们都是基数的幂，从小数点开始向左，每一位升高一次幂。小数点右侧的位值同样如此，只不过幂是负数。所以小数点右侧的位置是十分位（10^-1或十分之一）、百分位（10^-2或百分之一）。同理，在二进制中，小数点右侧的位置是二分位、四分位，以此类推。<br>一种基于科学计数法的存储方法，称为浮点记数法。任何实值可以由三个属性描述，即符号、指数和尾数，尾数由该数值中的数字构成，指数确定了小数点相对于尾数的位移。数字的个数是固定的，小数点却是浮动的，因此称为浮点记数法。在用浮点形式表示的数值中，正指数将把小数点右移，负指数将小数点左移。<br>假如一个字节由位模式01101011组成，符号为0，指数是110，尾数是1011。解码，尾数左边放置一个小数点，得到.1011，指数110是一个三位的二进制补码，表示整数2，因此小数点右移2位，可以得到10.11=1<em>2+0</em>1+1<em>1/2+1</em>1/4=2.75。<br>截断误差（truncation error）：由于尾数域空间不够大，而导致的存储部分数值丢失。二进制中的无穷展开式多于十进制，在二进制中无法精确表示1/10。<br>单精度浮点（single precision floating point）记数法，具有32位，其中1位表示符号位、8位表示指数、23位表示尾数。因此，单精度浮点最多有7位十进制有效数字，可以表示10^32到10^-37数量级之间的数，也就是说，可以精确地存储前七位十进制有效数字。<br>双精度浮点（double precision floating point）记数法，具有64位，最多有15位十进制有效数字。<br>科学计数法（scientific notation）是浮点表示法的一种形式，小数点总在最左边数字的右侧，也是说只有一位整数部分，12001.32708被写为1.200132708E+4。<br>1.4  文本表示法<br>1.4.1  ASCII字符集<br>字符集（character set）：字符和表示它们的代码的清单<br>ASCII字符集（American Standard Code for Information Interchange），用7位表示每个字符，可以表示128个字符，<br>0～31及127(共33个)是控制字符或通信专用字符（其余为可显示字符），如控制符：LF（换行）、CR（回车）、FF（换页）、DEL（删除）、BS（退格)、BEL（响铃）等；通信专用字符：SOH（文头）、EOT（文尾）、ACK（确认）等；ASCII值为8、9、10 和13 分别转换为退格、制表、换行和回车字符。它们并没有特定的图形显示，但会依不同的应用程序，而对文本显示有不同的影响 [1]  。<br>32～126(共95个)是字符(32是空格），其中48～57为0到9十个阿拉伯数字。<br>65～90为26个大写英文字母，97～122号为26个小写英文字母，其余为一些标点符号、运算符号等。<br>1.4.2 Unicode字符集<br>Unicode每个字符的编码为16位，但如果需要每个字符也可以使用更多空间，以便表示额外的字符。Unicode字符集的一个方便之处是把ASCii字符集作为一个子集，即前256个字符与扩展ASCii字符集中的完全一样。因此，即使底层系统采用Unicode字符集，采用ASCii值的程序也不会受到影响。<br>1.4.3 文本压缩<br>文本压缩主要有三种方式<br>关键字编码（keyword encoding）：用单个字符代替常用的单词。例如用^替代as，~替代the等等。这种方式有一些局限性。首先，用来编码的字符不能出现在原始文本中，否则会产生歧义；其次，The不会被编码，因为大小写是不同的字符；最后常用的单词都比较短，节省空间有限，而长的单词出现频率低也没有替换的必要。<br>行程长度编码（run-length encoding）：把一系列重复字符替换为它们重复出现的次数。将重复字符的序列替换为标志字符，后面加重复字符和说明字符重复次数的数字，例如AAAAAAA可以替换为<em>A7，</em>即为一种标志字符。因为用一个字符记录重复的次数，看似不能对重复次数大于9的序列编码，但实际上，在字符集中一个字符是由多个为表示的，因此可以将次数字符解释为一个二进制数，而不是ASCii数字。因此，能够编码的重复字符重复次数可以是0~255。<br>赫夫曼编码（Huffman encoding）：用变长的二进制串表示字符，使常用的字符具有较短的编码。不同的字符编码长度不同，例如常出现的A编码00，而出现比较少的D则为1011。由于编码是变长的，因此不知道每个字符对应多少位编码，看似很难将一个字符串解码。赫夫曼编码的一个重要特征是用于表示一个字符串的位串不会是另个一字符的位串的前缀。因此，从左到右扫描一个位串时，每当发现一个位串对应于一个字符，那么将唯一对应，不会发生歧义。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;1-信息层-数据存储&quot;&gt;&lt;a href=&quot;#1-信息层-数据存储&quot; class=&quot;headerlink&quot; title=&quot;1 信息层-数据存储&quot;&gt;&lt;/a&gt;1 信息层-数据存储&lt;/h1&gt;&lt;h2 id=&quot;1-1-二进制和记数系统&quot;&gt;&lt;a href=&quot;#1-1-二进制和记</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Hexo</title>
    <link href="http://example.com/2022/01/09/Command/Hexo/"/>
    <id>http://example.com/2022/01/09/Command/Hexo/</id>
    <published>2022-01-08T16:00:00.000Z</published>
    <updated>2022-01-12T00:33:57.347Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><h1 id="Hexo"><a href="#Hexo" class="headerlink" title="Hexo"></a>Hexo</h1><h2 id="1-安装-NodeJs"><a href="#1-安装-NodeJs" class="headerlink" title="1. 安装 NodeJs"></a>1. 安装 NodeJs</h2><p>windows/mac 安装</p><p><a href="https://nodejs.org/en/download/">NodeJs官网</a></p><p>检查是否安装成功</p><pre><code class="lang-bash">node -v</code></pre><p>npm 换源</p><pre><code class="lang-shell">npm config set registry https://registry.npm.taobao.org</code></pre><p>检测是否修改成功</p><pre><code class="lang-shell">npm config get registry</code></pre><h2 id="2-安装-Hexo"><a href="#2-安装-Hexo" class="headerlink" title="2. 安装 Hexo"></a>2. 安装 Hexo</h2><p>安装命令</p><pre><code class="lang-shell">npm install hexo-cli -g</code></pre><p>检查是否安装成功</p><pre><code class="lang-shell">hexo -v</code></pre><p>初始化文件夹</p><pre><code class="lang-shell">hexo init blog</code></pre><h2 id="3-安装相关支持库"><a href="#3-安装相关支持库" class="headerlink" title="3. 安装相关支持库"></a>3. 安装相关支持库</h2><p>git 支持</p><pre><code class="lang-shell">npm install hexo-deployer-git --save</code></pre><p>search 支持</p><pre><code class="lang-shell">npm install hexo-generator-feed --save</code></pre><h2 id="4-公式相关依赖"><a href="#4-公式相关依赖" class="headerlink" title="4. 公式相关依赖"></a>4. 公式相关依赖</h2><pre><code class="lang-shell">npm uninstall hexo-renderer-marked --save</code></pre><pre><code class="lang-shell">npm install hexo-renderer-kramed --save</code></pre><p>打开node_modules/hexo-renderer-kramed/lib/renderer.js，将</p><pre><code class="lang-javascript">// Change inline math rulefunction formatText(text) &#123;    // Fit kramed&#39;s rule: $$ + \1 + $$    return text.replace(/`\$(.*?)\$`/g, &#39;$$$$$1$$$$&#39;);&#125;</code></pre><p>改为</p><pre><code class="lang-javascript">// Change inline math rulefunction formatText(text) &#123;    return text;&#125;</code></pre><pre><code class="lang-shell">npm uninstall hexo-math --save</code></pre><pre><code class="lang-shell">npm install hexo-renderer-mathjax --save</code></pre><p>打开node_modules/hexo-renderer-mathjax/mathjax.html，最后一行改为</p><pre><code class="lang-html">&lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML&quot;&gt;&lt;/script&gt;</code></pre><p>打开node_modules/kramed/lib/rules/inline.js:</p><p>将</p><pre><code class="lang-javascript">escape: /^\\([\\`*&#123;&#125;\[\]()#$+\-.!_&gt;])/,</code></pre><p>改为</p><pre><code class="lang-javascript">escape: /^\\([`*\[\]()# +\-.!_&gt;])/,</code></pre><p>将</p><pre><code class="lang-javascript">em: /^\b_((?:__|[\s\S])+?)_\b|^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,</code></pre><p>改为</p><pre><code class="lang-javascript">em: /^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,</code></pre><p>在home/_config.yml，中添加如下内容</p><pre><code class="lang-yml">mathjax:    enable: true</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;h1 id=&quot;Hexo&quot;&gt;&lt;a href=&quot;#Hexo&quot; class=&quot;headerlink&quot; title=&quot;Hexo&quot;&gt;&lt;/a&gt;Hexo&lt;/h1&gt;&lt;h2 id=&quot;1-安装-NodeJs&quot;&gt;&lt;a href=&quot;#1-安装-NodeJ</summary>
      
    
    
    
    <category term="Command" scheme="http://example.com/categories/Command/"/>
    
    
  </entry>
  
</feed>
