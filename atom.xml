<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>He1o</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2022-06-17T06:15:42.097Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>He1o</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>1. Artificial Neural Network</title>
    <link href="http://example.com/2022/06/16/DeepLearning/1.ArtificialNeuralNetwork/"/>
    <id>http://example.com/2022/06/16/DeepLearning/1.ArtificialNeuralNetwork/</id>
    <published>2022-06-15T16:00:00.000Z</published>
    <updated>2022-06-17T06:15:42.097Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><h1 id="人工神经网络"><a href="#人工神经网络" class="headerlink" title="人工神经网络"></a>人工神经网络</h1><h2 id="1-历史背景"><a href="#1-历史背景" class="headerlink" title="1. 历史背景"></a>1. 历史背景</h2><p>1943 年，Warren McCulloch 和 Walter Pitts 提出形式神经元模型。 </p><p>在 1940 年代后期，D. O. Hebb[4] 基于神经可塑性机制创建了一个学习假设，即赫布学习。 Farley 和 Wesley A. Clark[5] (1954) 首先使用计算机器，然后称为“计算器”来模拟 Hebbian 网络。 </p><p>1958 年，心理学家 Frank Rosenblatt 发明了感知器，这是第一个人工神经网络，由美国海军研究办公室资助。</p><p>1969 年，Minsky 和 ​​Papert 提出感知机无法处理线性不可分问题，他们发现基本感知器无法处理异或电路，并且计算机缺乏足够的能力来处理有用的神经网络。</p><p>1965 年，Ivakhnenko 和 Lapa 提出第一个具有多层的神经网络。</p><p>1960 年，Henry J. Kelley 和 Arthur L. Bryson 使用动态规划原理在控制理论的背景下得出连续反向传播的基础。</p><p>1986 年，Rumelhart, Hinton &amp; Williams 再次提出反向传播一词，并阐述和推广使其在神经网络中的普遍使用，但该技术被独立地重新发现了很多次。</p><h2 id="2-基础预备"><a href="#2-基础预备" class="headerlink" title="2 基础预备"></a>2 基础预备</h2><h3 id="2-1-激活函数"><a href="#2-1-激活函数" class="headerlink" title="2.1 激活函数"></a>2.1 激活函数</h3><p><strong>sigmoid 函数</strong></p><p>该函数将取值为 $(-\infty,+\infty)$ 的数映射到 $(0,1)$ 之间。sigmoid 的公式为 </p><script type="math/tex; mode=display">g(z)=\frac{1}{1+e^{-z}}</script><p>导函数为</p><script type="math/tex; mode=display">g'(z)=g(z)(1-g(z))</script><p>sigmoid函数存在的问题在于</p><ol><li>需要计算指数，计算时间花费多。</li><li>当取值非常大或非常小时，sigmoid 的导数接近于 0，有可能会产生梯度消失。</li><li>函数的输出值不是以 0 为均值，不利于下层的计算，因此最好不用于隐藏层，可以作为输出层使用。</li></ol><p><strong>tanh 函数</strong></p><p>将取值为 $(-\infty,+\infty)$ 的数映射到 $(-1,1)$ 之间。tanh 的公式为</p><script type="math/tex; mode=display">g(z)=\frac{e^z-e^{-z}}{e^z+e^{-z}}</script><p>tanh 函数的导函数为</p><script type="math/tex; mode=display">g'(z)=1-g(z)^2</script><p>tanh 函数均值为 0，弥补了 sigmoid 函数均值为 $0.5$ 的缺点。但由于 $g’(z)$ 在两端取值接近于 0，因此也会有梯度消失的情况发生。</p><p><strong>ReLU 函数</strong></p><p>ReLU 函数又称为修正线性单元（Rectified Linear Unit），是一种分段线性函数，其弥补了 sigmoid 函数以及 tanh 函数的梯度消失问题。</p><p>ReLU 函数的公式为：</p><script type="math/tex; mode=display">{\displaystyle g(z)={    \begin{cases}        z&z\geq 0\\        0&z<0    \end{cases}    }}</script><p>ReLU 函数的导函数为</p><script type="math/tex; mode=display">{\displaystyle g‘(z)={    \begin{cases}        1&z\geq 0\\        0&z<0    \end{cases}    }}</script><p>ReLU 函数的优点在于当输入为正数的时候，不存在梯度消失的问题。同时，由于其线性关系，计算速度会快许多。ReLU 函数的缺点是当输入为负时，仍然会有梯度消失的情况发生。</p><p><strong>Leaky ReLU 函数</strong></p><p>公式为</p><script type="math/tex; mode=display">{\displaystyle g(z)={    \begin{cases}        z&z\geq 0\\        az&z<0    \end{cases}    }}</script><p>其中，$a$ 的取值在 $(0,1)$ 之间。</p><p>导函数为</p><script type="math/tex; mode=display">{\displaystyle g(z)={    \begin{cases}        1&z\geq 0\\        a&z<0    \end{cases}    }}</script><p>Leaky ReLU 函数解决了ReLU函数在输入为负的情况下产生的梯度消失问题。</p><p><strong>Sfotmax 函数</strong></p><p>softmax 函数通常被认为是多个 sigmoid 的组合。当神经网络用于二分类问题时，只需要 sigmoid 输出一个区间在 $[0,1]$ 的值即可。当用于多分类问题时，输出层的神经元数量和类别总数量是一样的，通过 softmax 函数输出每一个类别的概率。</p><script type="math/tex; mode=display">g(\mathbf{z})_j=\frac{e^{z_j}}{\displaystyle \sum^K_{k=1}e^{z_k}} \qquad j=1,2,\dots,K</script><p>求导函数需要分情况讨论，当 $z_i=z_j$ 时</p><script type="math/tex; mode=display">\begin{aligned}    g'(z_i=z_j)&=\frac{e^{z_j}\sum^K_{k=1}e^{z_k}-(e^{z_j})^2}{(\sum^K_{k=1}e^{z_k})^2} \\    &= g(\mathbf{z})_j-g(\mathbf{z})_j^2 \\    &=g(\mathbf{z})_j(1-g(\mathbf{z})_j)\end{aligned}</script><p>当 $z_i\ne z_j$ 时</p><script type="math/tex; mode=display">\begin{aligned}    g'(z_i\ne z_j)&=\frac{0-e^{z_j}e^{z_i}}{(\sum^K_{k=1}e^{z_k})^2} \\    &= -g(\mathbf{z})_j\cdot g(\mathbf{z})_i \\\end{aligned}</script><p>因此偏导数的最终表达式为</p><script type="math/tex; mode=display">{\displaystyle \frac{\partial g(\mathbf{z})_j}{\partial z_i}={    \begin{cases}        g(\mathbf{z})_j(1-g(\mathbf{z})_j)&z_i=z_j\\        -g(\mathbf{z})_j\cdot g(\mathbf{z})_i&z_i\ne z_j    \end{cases}    }}</script><h3 id="2-2-损失函数"><a href="#2-2-损失函数" class="headerlink" title="2.2 损失函数"></a>2.2 损失函数</h3><p>损失函数用来评价模型的预测值和真实值不一样的程度，损失函数越好，通常模型的性能越好。不同的模型用的损失函数一般也不一样。</p><p>损失函数分为经验风险损失函数和结构风险损失函数。经验风险损失函数指预测结果和实际结果的差别，结构风险损失函数是指经验风险损失函数加上正则项。</p><p>平方损失函数</p><script type="math/tex; mode=display">L = \sum_k\frac{1}{2}(r_k-y_k)^2</script><p>交叉熵损失函数</p><script type="math/tex; mode=display">L = -\sum_kr_k\ln y_k</script><p>交叉熵函数实际上是多项式分布的最大似然函数加上一个负号，将最大值问题转换为损失值最小的问题，本质是一样的。在多分类问题中，输出是 softmax 函数，如同逻辑回归一样。</p><p>假设 softmax 函数的输入是 $z_i$，推导一下交叉熵损失函数的偏导数</p><script type="math/tex; mode=display">\frac{\partial L}{\partial z_i}=-\sum_k\frac{r_k}{g(\mathbf{z})_k}\frac{\partial g(\mathbf{z})_k}{\partial z_i}</script><p>分为 $k=i$ 与 $k\ne i$ 进行求和</p><script type="math/tex; mode=display">\begin{aligned}    \frac{\partial L}{\partial z_i}&=\sum_{k\ne i}\frac{r_k}{g(\mathbf{z})_k}g(\mathbf{z})_k\cdot g(\mathbf{z})_i - \frac{r_i}{g(\mathbf{z})_i}g(\mathbf{z})_i(1-g(\mathbf{z})_i)\\    &=\sum_{k\ne i}r_kg(\mathbf{z})_i+r_ig(\mathbf{z})_i-r_i\\    &=g(\mathbf{z})_i\sum_k r_k- r_i\end{aligned}</script><p>多分类问题都采用 one-hot 编码，只有一个类别的标签值为 $1$，其余为 $0$，因此</p><script type="math/tex; mode=display">\sum_k r_k=1</script><p>最终得到</p><script type="math/tex; mode=display">\frac{\partial L}{\partial z_i}=g(\mathbf{z})_i-r_i</script><h2 id="2-多层感知机模型"><a href="#2-多层感知机模型" class="headerlink" title="2. 多层感知机模型"></a>2. 多层感知机模型</h2><p>人工神经网络实际上就是多层感知机模型。感知机最大局限性在于它是一个线性分类器，无法处理非线性分类的问题，而多层感知机就可以解决这样的问题。多层感知器指的是由多层结构的感知器递阶组成的输入值向前传播的网络，也被称为前馈网络或正向传播网络。</p><p>多层感知机的思想就是一个函数不行，就使用多个简单函数共同作用。例如三层的感知机模型，由输入层、中间层和输出层组成。中间层的感知器通过权重与输入层的各单元（unit）相连接，通过阈值函数计算中间层各单元的输出值。中间层与输出层之间同样是通过权重相连接。</p><p>那么，如何确定各层之间的连接权重呢？单层感知器是通过误差修正学习确定输入层与输出层之间的连接权重的。初期的多层感知器使用随机数确定输入层与中间层之间的连接权重，只对中间层与输出层之间的连接权重进行误差修正学习。所以，就会出现输入数据虽然不同，但是中间层的输出值却相同，以至于无法准确分类的情况。直到误差反向传播算法的提出，多层感知机才被广泛应用。</p><h3 id="2-1-前向传播"><a href="#2-1-前向传播" class="headerlink" title="2.1 前向传播"></a>2.1 前向传播</h3><p>多层感知机每一层都有多个神经元，也称为单元。每个单元接受 $n$ 个输入并产生一个输出，并且不同的单元具有各自的权重和偏置。假设输入为 $\mathbf{x}=[x_1,x_2,\cdots,x_n]$，单元 $j$ 的权重为 $\mathbf{w}_j = [w_{j1},w_{j2},\cdots,w_{jn}]$，偏置为 $b_j$，则输出为</p><script type="math/tex; mode=display">z_j=\sum_i w_{ji}x_i+b_j</script><p>为了保证输出的值在区间 $[0,1]$ 之中，并且引入非线性变换，通常再将线性变换的输出值 $z_j$ 放入到激活函数当中。同时，这一层的输出可以作为下一层的输入，因此</p><script type="math/tex; mode=display">x_j=g(z_j)</script><p>我们再定义一层输出层</p><script type="math/tex; mode=display">z_k=\sum_j w_{kj}x_j+b_k</script><p>最终输出结果为</p><script type="math/tex; mode=display">y_k=g(z_k)</script><p>输出结果可以与标注结果进行比对，通过损失函数可以衡量结果的准确性。在这里使用平方误差作为损失函数。</p><script type="math/tex; mode=display">L=\sum_k\frac{1}{2}(r_k-y_k)^2</script><h3 id="2-2-反向传播"><a href="#2-2-反向传播" class="headerlink" title="2.2 反向传播"></a>2.2 反向传播</h3><p>一步一步求偏导数即可，首先是损失函数关于输出 $y_k$ 的导数</p><script type="math/tex; mode=display">\frac{\partial L}{\partial y_k}=-(r_k-y_k)</script><p>激活函数都使用 sigmoid 函数，因此</p><script type="math/tex; mode=display">\frac{\partial y_k}{\partial z_k}=g'(z)=g(z)(1-g(z))=y_k(1-y_k)</script><p>同时</p><script type="math/tex; mode=display">\frac{\partial z_k}{\partial w_{kj}}=x_j</script><p>所以输出层权重的偏导数为</p><script type="math/tex; mode=display">\frac{\partial L}{\partial w_{kj}}=\frac{\partial L}{\partial y_k}\frac{\partial y_k}{\partial z_k}\frac{\partial z_k}{\partial w_{kj}}=-(r_k-y_k)y_k(1-y_k)x_j</script><p>类似的可以得到偏置</p><script type="math/tex; mode=display">\frac{\partial L}{\partial b_k}=\frac{\partial L}{\partial y_k}\frac{\partial y_k}{\partial z_k}\frac{\partial z_k}{\partial b_k}=-(r_k-y_k)y_k(1-y_k)</script><p>将偏导数再次向前转播</p><script type="math/tex; mode=display">\frac{\partial z_k}{\partial w_{ji}}=\frac{\partial z_k}{\partial x_j}\frac{\partial x_j}{\partial z_j}\frac{\partial z_j}{\partial w_{ji}}=w_{kj}x_j(1-x_j)x_i</script><p>同时，对于输入层权重的偏导数是所有输出单元的导数的加权求和</p><script type="math/tex; mode=display">\frac{\partial L}{\partial w_{ji}}=\sum_k\frac{\partial L}{\partial y_k}\frac{\partial y_k}{\partial z_k}\frac{\partial z_k}{\partial w_{ji}}</script><p>因此</p><script type="math/tex; mode=display">\frac{\partial L}{\partial w_{ji}}=\sum_k-(r_k-y_k)y_k(1-y_k)w_{kj}x_j(1-x_j)x_i</script><p>最终不同层权重的调节值为</p><script type="math/tex; mode=display">\triangle w_{kj}=\eta(r_k-y_k)y_k(1-y_k)x_j</script><script type="math/tex; mode=display">\triangle w_{ji}=\eta\sum_k\left[(r_k-y_k)y_k(1-y_k)w_{kj}\right]x_j(1-x_j)x_i</script><p>$\eta$ 为取值 $(0,1)$ 之间的学习率。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><blockquote><p><a href="https://en.wikipedia.org/wiki/Artificial_neural_network">1. Artificial neural network - Wikipedia</a><br><a href="https://en.wikipedia.org/wiki/Backpropagation">2. Backpropagation - Wikipedia</a><br><a href="https://zhuanlan.zhihu.com/p/80730031">3. 深度学习中【激活函数】存在的意义是什么？</a><br><a href="https://www.datalearner.com/blog/1051508750742453">4. 深度学习基础——激活函数以及什么时候该使用激活函数</a><br><a href="https://www.analyticsvidhya.com/blog/2020/01/fundamentals-deep-learning-activation-functions-when-to-use-them/">5. Fundamentals of Deep Learning – Activation Functions and When to Use Them?</a><br><a href="https://zhuanlan.zhihu.com/p/105722023">6. 一文详解Softmax函数 - zhihu</a><br><a href="https://zhuanlan.zhihu.com/p/58883095">7. 常见的损失函数(loss function)总结 - zhihu</a><br><a href="https://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes03-neuralnets.pdf">8. CS224n: Natural Language Processing with Deep Learning</a><br><a href="https://www.cs.toronto.edu/~urtasun/courses/CSC411_Fall16/10_nn1.pdf">9. CSC 411: Lecture 10: Neural Networks</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;h1 id=&quot;人工神经网络&quot;&gt;&lt;a href=&quot;#人工神经网络&quot; class=&quot;headerlink&quot; title=&quot;人工神经网络&quot;&gt;&lt;/a&gt;人工神经网络&lt;/h1&gt;&lt;h2 id=&quot;1-历史背景&quot;&gt;&lt;a href=&quot;#1-历史背景&quot;</summary>
      
    
    
    
    <category term="Deep learning" scheme="http://example.com/categories/Deep-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>8. Expectation Maximization</title>
    <link href="http://example.com/2022/04/08/MachineLearning/9.ExpectationMaximization/"/>
    <id>http://example.com/2022/04/08/MachineLearning/9.ExpectationMaximization/</id>
    <published>2022-04-07T16:00:00.000Z</published>
    <updated>2022-04-22T05:48:47.853Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><h1 id="期望最大化算法"><a href="#期望最大化算法" class="headerlink" title="期望最大化算法"></a>期望最大化算法</h1><h2 id="1-历史背景"><a href="#1-历史背景" class="headerlink" title="1. 历史背景"></a>1. 历史背景</h2><p>1955 年，Cedric Smith 提出一种用于估计等位基因频率的基因计数方法。H.O. Hartley 于 1958 年、Hartley and Hocking 于 1977 年分别提出类似的方法，都是解决不完整数据中的最大似然求解问题，它们均为 EM 算法的起源。</p><p>1971 年，Rolf Sundberg 在他的几篇论文中探讨了指数族变量不完整数据的最大似然理论，并给出了非常详细的处理。Sundberg 将后来称为 Sundberg 公式的公式归功于其老师 Per Martin-Löf 和 Anders Martin-Löf 以前的手稿。</p><p>1977 年，Arthur Dempster、Nan Laird 和 Donald Rubin Dempster-Laird-Rubin 论文概括了 EM 方法，并对更广泛的问题进行了收敛性分析。 Dempster-Laird-Rubin 的论文将 EM 方法确立为统计分析的重要工具。</p><p>1983 年，由于 Dempster-Laird-Rubin 算法的收敛性分析存在缺陷，C. F. Jeff Wu 发表了正确的收敛性分析。Wu 的证明确立了 EM 方法在指数族之外的收敛性，正如 Dempster-Laird-Rubin 所声称的那样。</p><h2 id="2-基础预备"><a href="#2-基础预备" class="headerlink" title="2. 基础预备"></a>2. 基础预备</h2><p>推导一些有关的不等式，部分是高中知识。</p><p><strong>定义1</strong>　如果 $f$ 是定义在区间 $I=[a,b]$ 上的实值函数，且 $\forall x_1,x_2\in I,\lambda\in I$，满足</p><script type="math/tex; mode=display">f(\lambda x_1+(1-\lambda)x_2)\le \lambda f(x_1)+(1-\lambda)f(x_2)</script><p>则称 $f$ 为凸函数，如果不等式是严格的，则 $f$ 是严格凸的。</p><blockquote><p>实际上 $\lambda x_1+(1-\lambda)x_2=\lambda(x_1-x_2)+x_2$，表示的是区间 $[x_1,x_2]$ 中的一个点。不等式的含义就是区间 $[x_1,x_2]$ 的函数值永远不会高于点 $(x_1,f(x_1))$ 到 $(x_2,f(x_2))$ 的直线。$x^2$ 是凸函数，与高数中定义相反。</p></blockquote><p><strong>定义2</strong>　如果 $f$ 是凹（严格凹）函数，则 $-f$ 是凸（严格凸）函数。</p><p><strong>定理1</strong>　如果 $f(x)$ 在 $[a,b]$ 上是两次可微的，并且 $f’’(x)\ge 0$，则 $f(x)$ 在 $[a,b]$ 是凸的。 </p><p>证明：假设 $x\le y\in[a,b]$，并且 $\lambda\in[0,1]$，让 $z=\lambda y+(1-\lambda)x$，根据定义 1 ，如果满足</p><script type="math/tex; mode=display">f(z)\le \lambda f(y)+(1-\lambda)f(x)</script><p>则可证明 $f$ 是凸函数，$f(z)$ 可以表示为</p><script type="math/tex; mode=display">f(z)=\lambda f(z)+(1-\lambda)f(z)</script><p>联立两个式子可以得到</p><script type="math/tex; mode=display">\lambda(f(y)-f(z))\ge(1-\lambda)(f(z)-f(x))</script><p>根据中值定理，存在 $z\le t\le y$</p><script type="math/tex; mode=display">f(y)-f(z)=f'(t)(y-z)</script><p>同理，存在 $x\le s\le z$</p><script type="math/tex; mode=display">f(z)-f(x)=f'(s)(z-x)</script><p>由于 $f’’(x)\ge 0$，并且 $t\le s$，可知 $f’(t)\le f’(s)$</p><p>根据 $z=\lambda y+(1-\lambda)x$，可以得到</p><script type="math/tex; mode=display">(1-\lambda)(z-x)=\lambda(y-z)</script><p>最终，联立以上各式</p><script type="math/tex; mode=display">\begin{aligned}    \lambda(f(y)-f(z))&=\lambda f'(t)(y-z) \\    &\ge f'(s)\lambda(y-z)\\    &=f'(s)(1-\lambda)(z-x)\\    &=(1-\lambda)(f(z)-f(x))\end{aligned}</script><p><strong>推论1</strong>　$-\ln(x)$ 是在区间 $(0,\infty)$ 是严格凸函数。</p><p>证明：$f(x)=-\ln(x)$，由于 $\displaystyle f’’(x)=\frac{1}{x^2}&gt;0$，因此 $-\ln(x)$ 是在区间 $(0,\infty)$ 是严格凸函数。</p><blockquote><p>将上述凸性的概念扩展到 $n$ 个点，得到的就是 Jensen 不等式。</p></blockquote><p><strong>定理2（Jensen 不等式）</strong>　如果 $f$ 是区间 $I$ 上的凸函数，如果 $x_1,x_2,\dots,x_n\in I$ ， $\lambda_1,\lambda_2,\dots,\lambda_n \ge 0$ 且 $\displaystyle\sum_{i=1}^n \lambda_i = 1$，则有</p><script type="math/tex; mode=display">f\left(\sum_{i=1}^n \lambda_ix_i\right)\le \sum_{i=1}^n \lambda_if(x_i)</script><p>证明：$n=2$ 对应于凸性的定义，为了证明这对所有自然数都是正确的，我们通归纳来证明，假设定理对某些 $n$ 成立，则</p><script type="math/tex; mode=display">\begin{aligned}    f\left(\sum_{i=1}^{n+1} \lambda_ix_i\right) &=f\left(\lambda_{n+1}x_{n+1}+\sum_{i=1}^n \lambda_ix_i\right)\\    &=f\left(\lambda_{n+1}x_{n+1}+(1-\lambda_{n+1})\frac{1}{1-\lambda_{n+1}}\sum_{i=1}^n \lambda_ix_i\right)\\    &\le \lambda_{n+1}f(x_{n+1})+(1-\lambda_{n+1})f\left(\frac{1}{1-\lambda_{n+1}}\sum_{i=1}^n \lambda_ix_i\right) \\    &= \lambda_{n+1}f(x_{n+1})+(1-\lambda_{n+1})f\left(\sum_{i=1}^n \frac{\lambda_i}{1-\lambda_{n+1}}x_i\right) \\    &\le \lambda_{n+1}f(x_{n+1})+(1-\lambda_{n+1})\sum_{i=1}^n \frac{\lambda_i}{1-\lambda_{n+1}}f(x_i) \\    &= \lambda_{n+1}f(x_{n+1})+\sum_{i=1}^n \lambda_if(x_i)\\    &=\sum_{i=1}^{n+1} \lambda_if(x_i)\end{aligned}</script><blockquote><p>由于 $\ln$ 是凹函数，因此通过 Jensen 不等式可以推导出</p><script type="math/tex; mode=display">\ln\sum_{i=1}^n \lambda_ix_i \ge \sum_{i=1}^n \lambda_i\ln(x_i)</script><p>这个公式可以得到一个和的对数的下限，可用于推导 EM 算法。</p><p>Jensen不等式可以证明算术平均值大于等于几何平均值，即</p></blockquote><p><strong>推论2</strong>　</p><script type="math/tex; mode=display">\frac{1}{n}\sum_{i=1}^n x_i\ge \sqrt[n]{x_1x_2\dots x_n}</script><p>证明： 如果 $x_1,x_2,\dots,x_n\ge0$，由于 $\ln$ 是凹函数，可以得到</p><script type="math/tex; mode=display">\begin{aligned}    \ln\left(\frac{1}{n}\sum_{i=1}^{n}x_i\right) &\ge \sum_{i=1}^{n}\frac{1}{n} \ln(x_i) \\    &= \frac{1}{n}\ln(x_1x_2\dots x_n) \\    &=\ln(x_1x_2\dots x_n)^{\frac{1}{n}}\end{aligned}</script><p>因此，有</p><script type="math/tex; mode=display">\frac{1}{n}\sum_{i=1}^n x_i\ge \sqrt[n]{x_1x_2\dots x_n}</script><h2 id="3-算法推导"><a href="#3-算法推导" class="headerlink" title="3. 算法推导"></a>3. 算法推导</h2><p>在概率模型当中，已知样本观察数据，想要得到模型参数，一般使用极大似然估计。</p><p>极大似然估计需要对似然函数的所有未知值、参数求导，并同时求解得到的的方程。而在某些统计模型当中，除了已知的观察数据之外，还有未知的潜在变量。话句话说，也就是模型中缺失了部分的观察变量，而缺失的观察变量和已知的之间存在某种概率关系。如果用极大似然算法，它们之间的导数是一组互锁的方程，其中参数的解需要潜在变量的值，反之亦然，但是将一组方程带入另一组方程会产生一个不可解的方程组。</p><p>EM 算法就是求解上述问题的一种迭代方法，主要思想是简单地为两组未知数中的一组选择任意值，使用它们来估计第二组，然后使用这些新值来找到对第一组的更好估计，然后在两者之间保持交替，直到结果值都收敛到固定点。</p><p>EM 算法是一种通用的算法，无论是离散还是连续，二项式分布或高斯分布，都可以用来求解。</p><p>假设 $\mathbf{X}$ 表示观测随机变量的一组结果，在概率模型参数 $\theta$ 下的条件概率为 $\mathcal{P}(\mathbf{X}|\theta)$，找到最大 $\theta$ 使其概率最大的过程就称为最大似然估计。为了估计 $\theta$，通常引入对数似然函数</p><script type="math/tex; mode=display">L(\theta)=\ln \mathcal{P}(\mathbf{X}|\theta)</script><p>如果概率模型中存在一组隐藏变量 $\mathbf{Z}$，它的结果无法通过观测得到，但其结果会对观测变量 $\mathbf{X}$ 产生影响。$\mathbf{X}$ 和 $\mathbf{Z}$ 一起称为完全数据，观测变量 $\mathbf{X}$ 则又称为不完全数据。假定隐藏变量 $\mathbf{Z}$ 的一组取值为 $\mathbf{z}$，则观测结果 $\mathbf{X}$ 是基于 $\mathbf{z}$ 和参数 $\theta$ 的条件之下产生的，</p><script type="math/tex; mode=display">\mathcal{P}(\mathbf{X}|\mathbf{z}, \theta)=\frac{\mathcal{P}(\mathbf{X}, \mathbf{z}, \theta)}{\mathcal{P}(\mathbf{z}, \theta)}</script><p>而隐藏变量同样是基于 $\theta$ 产生的，</p><script type="math/tex; mode=display">\mathcal{P}(\mathbf{z}|\theta)=\frac{\mathcal{P}(\mathbf{z}, \theta)}{\mathcal{P}(\theta)}</script><p>将两个条件概率相乘，并将隐藏变量所有可能的取值进行累加（隐藏变量的取值似乎都是可数的），就可以得到 $\mathbf{X}$ 在 $\theta$ 下的条件概率，</p><script type="math/tex; mode=display">\sum_{\mathbf{z}}\mathcal{P}(\mathbf{X}|\mathbf{z}, \theta)\mathcal{P}(\mathbf{z}|\theta)=\sum_{\mathbf{z}}\frac{\mathcal{P}(\mathbf{X}, \mathbf{z}, \theta)}{\mathcal{P}(\theta)}=\mathcal{P}(\mathbf{X}|\theta)</script><p>因此将对数似然函数改写为</p><script type="math/tex; mode=display">L(\theta) = \ln\mathcal{P}(\mathbf{X}|\theta)=\ln\sum_{\mathbf{z}}\mathcal{P}(\mathbf{X}|\mathbf{z}, \theta)\mathcal{P}(\mathbf{z}|\theta)</script><p>最终是求 $\theta$ 使上式结果最大化，该问题没有解析解，只能通过迭代的方法求解。假设第 $t$ 次迭代后 $\theta$ 的估计值为 $\theta_t$，我们希望新估计值 $\theta$ 能使 $L(\theta)$ 增加，考虑两者差值</p><script type="math/tex; mode=display">L(\theta)-L(\theta_t)=\ln\sum_{\mathbf{z}}\mathcal{P}(\mathbf{X}|\mathbf{z}, \theta)\mathcal{P}(\mathbf{z}|\theta) - \ln\mathcal{P}(\mathbf{X}|\theta_t)</script><p>这是一个变量为 $\theta$ 的函数，$\theta_t$ 相当于常数，$\sum$ 在 $\ln$ 里面是无法对求解函数极值的，因此利用上述 Jensen 不等式</p><script type="math/tex; mode=display">\ln\sum_{i=1}^n \lambda_ix_i \ge \sum_{i=1}^n \lambda_i\ln(x_i)</script><p>为了提出 $\lambda_i$，需要凑出 $\displaystyle\sum_{i=1}^n \lambda_i = 1$，可以利用条件概率 $\mathcal{P}(\mathbf{z}|\mathbf{X}, \theta_t)$，我们有 $\mathcal{P}(\mathbf{z}|\mathbf{X}, \theta_t)\ge 0$ 且 $\displaystyle\sum_\mathbf{z}\mathcal{P}(\mathbf{z}|\mathbf{X}, \theta_t)= 1$，因此</p><script type="math/tex; mode=display">\begin{aligned}    L(\theta)-L(\theta_t)&=\ln\sum_{\mathbf{z}}\mathcal{P}(\mathbf{X}|\mathbf{z}, \theta)\mathcal{P}(\mathbf{z}|\theta) - \ln\mathcal{P}(\mathbf{X}|\theta_t)\\    &=\ln\sum_{\mathbf{z}}\mathcal{P}(\mathbf{X}|\mathbf{z}, \theta)\mathcal{P}(\mathbf{z}|\theta)\frac{\mathcal{P}(\mathbf{z}|\mathbf{X}, \theta_t)}{\mathcal{P}(\mathbf{z}|\mathbf{X}, \theta_t)} - \ln\mathcal{P}(\mathbf{X}|\theta_t)\\    &\ge\sum_{\mathbf{z}}\mathcal{P}(\mathbf{z}|\mathbf{X}, \theta_t)\ln\frac{\mathcal{P}(\mathbf{X}|\mathbf{z}, \theta)\mathcal{P}(\mathbf{z}|\theta)}{\mathcal{P}(\mathbf{z}|\mathbf{X}, \theta_t)\mathcal{P}(\mathbf{X}|\theta_t)}\end{aligned}</script><p>令</p><script type="math/tex; mode=display">l(\theta|\theta_t)=L(\theta_t)+\sum_{\mathbf{z}}\mathcal{P}(\mathbf{z}|\mathbf{X}, \theta_t)\ln\frac{\mathcal{P}(\mathbf{X}|\mathbf{z}, \theta)\mathcal{P}(\mathbf{z}|\theta)}{\mathcal{P}(\mathbf{z}|\mathbf{X}, \theta_t)\mathcal{P}(\mathbf{X}|\theta_t)}</script><p>则有</p><script type="math/tex; mode=display">L(\theta)\ge l(\theta|\theta_t)</script><p>因此我们有一个函数 $l(\theta|\theta_t)$ 来作为对数似然函数 $L(\theta)$ 的下界，并且当 $\theta=\theta_t$ 时，可以推导出</p><script type="math/tex; mode=display">l(\theta_t|\theta_t)=L(\theta_t)</script><p>因此，任何可以使 $l(\theta|\theta_t)$ 增大的 $\theta$，也可以使 $L(\theta)$ 增大，为了使 $L(\theta)$ 尽可能大的增长，选择 $\theta_{t+1}$ 使 $l(\theta|\theta_t)$ 达到极大值，只与 $\theta_t$ 有关的项为常数项，即</p><script type="math/tex; mode=display">\begin{aligned}    \theta_{t+1}&=\argmax_{\theta} l(\theta|\theta_t)\\    &=\argmax_{\theta} \sum_{\mathbf{z}}\mathcal{P}(\mathbf{z}|\mathbf{X}, \theta_t)\ln\mathcal{P}(\mathbf{X}|\mathbf{z}, \theta)\mathcal{P}(\mathbf{z}|\theta)\\    &=\argmax_{\theta} \sum_{\mathbf{z}}\mathcal{P}(\mathbf{z}|\mathbf{X}, \theta_t)\ln\frac{\mathcal{P}(\mathbf{X}, \mathbf{z}, \theta)}{\mathcal{P}(\mathbf{z}, \theta)}\frac{\mathcal{P}(\mathbf{z}, \theta)}{\mathcal{P}(\theta)}\\    &=\argmax_{\theta} \sum_{\mathbf{z}}\mathcal{P}(\mathbf{z}|\mathbf{X}, \theta_t)\ln\mathcal{P}(\mathbf{X}, \mathbf{z}|\theta)\\    &=\argmax_{\theta} E_{\mathbf{z|\mathbf{X},\theta_t}}\{\ln\mathcal{P}(\mathbf{X}, \mathbf{z}|\theta)\}\\\end{aligned}</script><blockquote><p>最后的一项是完全数据的对数似然函数 $\ln\mathcal{P}(\mathbf{X}, \mathbf{z}|\theta)$ 关于给定观测数据 $\mathbf{X}$ 和当前参数 $\theta_t$ 下对未观测数据 $\mathbf{z}$ 的条件概率分布 $\mathcal{P}(\mathbf{z}|\mathbf{X}, \theta_t)$ 的期望。</p></blockquote><p>总结如下</p><p><strong>EM 算法</strong></p><ul><li><strong>输入</strong>：观测变量 $\mathbf{X}$</li><li><strong>输出</strong>：模型参数 $\theta$</li><li><strong>步骤</strong>：<ol><li>初始化模型参数为 $\theta_0$</li><li>（E 步）假设第 $t$ 次迭代参数 $\theta$ 的估计值为 $\theta_t$，在给定观测数据 $\mathbf{X}$ 和当前参数 $\theta_t$，求得完全数据的对数似然函数关于未观测数据 $\mathbf{z}$ 的概率分布的期望 $\displaystyle \sum_{\mathbf{z}}\mathcal{P}(\mathbf{z}|\mathbf{X}, \theta_t)\ln\mathcal{P}(\mathbf{X}, \mathbf{z}|\theta)$，记为 $Q(\theta,\theta_t)$。</li><li>（M 步）求使 $l(\theta|\theta_t)$ 最大化的 $\theta$，使 $\theta_{t+1}=\argmax_{\theta} Q(\theta,\theta_t)$。</li><li>重复 E 步与 M 步。</li><li>如果满足 $|\theta_{t+1}-\theta_t|&lt;\varepsilon_1$ 或 $|Q(\theta_{t+1},\theta_t)-Q(\theta_t,\theta_t)|&lt;\varepsilon_1$，则停止迭代。</li></ol></li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><blockquote><p><a href="https://www.lri.fr/~sebag/COURS/EM_algorithm.pdf">1. The Expectation Maximization Algorithm: A short tutorial</a><br><a href="https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm">2. Expectation–maximization algorithm - Wikipedia</a><br><a href="https://engineering.purdue.edu/ChanGroup/ECE645Notes/StudentLecture10.pdf">3. Lecture 10: Expectation-Maximization Algorithm</a><br><a href="https://www.cnblogs.com/pinard/p/6912636.html">4. EM算法原理总结 - 刘建平</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;h1 id=&quot;期望最大化算法&quot;&gt;&lt;a href=&quot;#期望最大化算法&quot; class=&quot;headerlink&quot; title=&quot;期望最大化算法&quot;&gt;&lt;/a&gt;期望最大化算法&lt;/h1&gt;&lt;h2 id=&quot;1-历史背景&quot;&gt;&lt;a href=&quot;#1-历</summary>
      
    
    
    
    <category term="Machine learning" scheme="http://example.com/categories/Machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>1. Linear Equation</title>
    <link href="http://example.com/2022/04/02/LinearAlgebra/1.Linear%20Equation/"/>
    <id>http://example.com/2022/04/02/LinearAlgebra/1.Linear%20Equation/</id>
    <published>2022-04-01T16:00:00.000Z</published>
    <updated>2022-04-08T02:40:12.329Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><h1 id="线性方程组"><a href="#线性方程组" class="headerlink" title="线性方程组"></a>线性方程组</h1><h2 id="1-线性方程组"><a href="#1-线性方程组" class="headerlink" title="1. 线性方程组"></a>1. 线性方程组</h2><p><strong>线性方程</strong>形如</p><script type="math/tex; mode=display">a_1x_1+a_2x_2+\dots+a_nx_n=b</script><p>$x_1,x_2,\dots,x_n$ 为变量，$a_1,a_2,\dots,a_n$ 为系数，系数与 $b$ 为实数或复数，通常为已知数，下标 $n$ 可以是任意正整数。</p><p><strong>线性方程组</strong>是由一个或多个有相同变量的线性方程组成的。</p><p>方程组所有可能的解的集合称为线性方程组的<strong>解集</strong>。若两个线性方程组有相同的解集 ，则这两个线性方程组称为<strong>等价</strong>的。</p><p>方程组解的情况可以概括为有唯一解、有无穷多解、无解。</p><p>当方程组有解时称该方程组为 <strong>相容的</strong>，如果无解则称为 <strong>不相容的</strong>。</p><blockquote><p>当方程组有两个变量时，在平面空间一个线性方程就代表一条直线，当两条直线相交时有解，平行时则表示无解，重合时则有无穷多解。三个变量时则是三维空间中的一个平面，当三个平面没有共同交点时无解。</p></blockquote><p>方程组的系数可以由一个<strong>矩阵</strong>表示，称为<strong>系数矩阵</strong>。如果将常数列添加到系数矩阵中则称其为<strong>增广矩阵</strong>。矩阵的维数表示其行数与列数，例如 $m\times n$ 矩阵有 $m$ 行 $n$ 列。</p><p>求解线性方程组的一般思路是将方程组用一个更容易解的等价方程组代替，变化的过程使用行消去法，可以保证变换后的方程组与之前的方程组解一致。这种操作矩阵的方法不仅仅适用于求解方程组，更适用于任意矩阵。</p><p><strong>定义1</strong>　一个矩阵称为阶梯形矩阵，若它有以下三个性质：</p><ol><li>每一非零行都在每一零行之上.</li><li>某一行的先导元素所在的列位于前一行先导元素的右边.</li><li>某一先导元素所在列下方元素都是零.</li></ol><p>如有以下性质，则称为简化阶梯形矩阵</p><ol><li>每一非零行先导元素是 1.</li><li>每一先导元素 1 是该元素所在列唯一的非零元素.</li></ol><p><strong>定理1</strong>　(简化阶梯形矩阵的唯一性〉 每个矩阵行等价于唯一的简化阶梯形矩阵。</p><p>因简化阶梯形矩阵是唯一的，故当给定矩阵化为任何一个阶梯形时，先导元素总是在相同的位置上。这些先导元素对应于简化阶梯形中的先导元素1。</p><p>行化简算法，也就是矩阵形式的消元法，分为向前步骤和向后步骤。向前步骤将增广矩阵化为阶梯形矩阵，向后步骤将阶梯形矩阵化为简化阶梯形矩阵。</p><p><strong>定义2</strong>　矩阵中的主元位置是 A 中对应于它的阶梯形中先导元素 1 的位置。主元列是 A 中含有主元位置的列。</p><p>在方程组的增广矩阵中，主元列对应的变量为基本变量，其他变量称为自由变量。</p><h2 id="2-向量方程"><a href="#2-向量方程" class="headerlink" title="2. 向量方程"></a>2. 向量方程</h2><p>仅含一列的矩阵称为<strong>列向量</strong>，或简称向量</p><script type="math/tex; mode=display">\mathbf{w}=\begin{bmatrix}   w_1 \\   \vdots  \\   w_n \\\end{bmatrix}</script><p>其中 $w_i$ 为任意实数， 所有 $n$ 个元素的向量集记为 $\mathbb{R}^n$，$\mathbb{R}$ 表示向量中的元素是实数，指数 $n$ 表示每个向量中包含 $n$ 个元素。</p><p>所有元素都是零的向量称为<strong>零向量</strong>，用 $\mathbf{0}$ 表示（$\mathbf{0}$ 中元素的个数可由上下文确定）。</p><p>$\mathbb{R}^n$ 中两个向量相等当且仅当其对应元素相等。向量的基础运算有向量加法与向量乘法（数乘），向量减法可以视作两种运算的结合，例如 $\mathbf{u}-\mathbf{v}=\mathbf{u}+(-1)\mathbf{v}$。</p><p>给定 $\mathbb{R}^n$ 中向量 $\mathbf{v}_1,\mathbf{v}_2,\dots,\mathbf{v}_p$ 和标量 $c_1,c_2,\dots,c_p$，向量</p><script type="math/tex; mode=display">\mathbf{y}=c_1\mathbf{v}_1+\cdots+c_p\mathbf{v}_p</script><p>称为向量 $\mathbf{v}_1,\mathbf{v}_2,\dots,\mathbf{v}_p$ 以 $c_1,c_2,\dots,c_p$ 为权的<strong>线性组合</strong>，线性组合中的权可以为任意实数。 </p><blockquote><p>向量 $\mathbf{u}=3\mathbf{v}_1-2\mathbf{v}_2$，可以解释为经过两条直线路径从原点到达 $\mathbf{u}$ 的移动指令。首先在 $\mathbf{v}_1$ 方向移动 3 个单位到达 $3\mathbf{v}_1$，然后在 $\mathbf{v}_2$ 方向移动 -2 个单位</p></blockquote><p>线性代数的一个主要思想是研究可以表示为某一固定向量集合 $\{\mathbf{v}_1,\mathbf{v}_2,\dots,\mathbf{v}_p\}$ 的线性组合的所有向量。</p><p><strong>定义</strong>　若 $\mathbf{v}_1,\mathbf{v}_2,\dots,\mathbf{v}_p$ 是 $\mathbb{R}^n$ 中的向量，则 $\mathbf{v}_1,\mathbf{v}_2,\dots,\mathbf{v}_p$ 的所有线性组合的集合用记号 $\mathrm{Span}\{\mathbf{v}_1,\mathbf{v}_2,\dots,\mathbf{v}_p\}$ 表示，称为由 $\mathbf{v}_1,\mathbf{v}_2,\dots,\mathbf{v}_p$ 所生成的 $\mathbb{R}^n$ 的子集。也就是说 $\mathrm{Span}\{\mathbf{v}_1,\mathbf{v}_2,\dots,\mathbf{v}_p\}$ 是所有形如</p><script type="math/tex; mode=display">c_1\mathbf{v}_1+\cdots+c_p\mathbf{v}_p</script><p>的向量的集合，其中 $c_1,c_2,\dots,c_p$ 为标量。</p><p>要判断向量 $\mathbf{b}$ 是否属于 $\mathrm{Span}\{\mathbf{v}_1,\mathbf{v}_2,\dots,\mathbf{v}_p\}$，就是判断<strong>向量方程</strong></p><script type="math/tex; mode=display">x_1\mathbf{v}_1+x_2\mathbf{v}_2+\cdots+x_n\mathbf{v}_n=\mathbf{b}</script><p>是否有解，它与增广矩阵为</p><script type="math/tex; mode=display">\begin{bmatrix}   \mathbf{v}_1 &\mathbf{v}_2 &\cdots &\mathbf{v}_n & \mathbf{b}\end{bmatrix}</script><p>的线性方程组有相同的解集，即等价。</p><h2 id="3-矩阵方程"><a href="#3-矩阵方程" class="headerlink" title="3. 矩阵方程"></a>3. 矩阵方程</h2><p>向量的线性组合可以看作矩阵与向量的积。</p><p><strong>定义</strong>　若 $A$ 是 $m\times n$ 矩阵，它的各列为 $\mathbf{a}_1,\mathbf{a}_2,\dots,\mathbf{a}_n$，若 $\mathbf{x}$ 是 $\mathbb{R}^n$ 中的向量，则 $A$ 与 $\mathbf{x}$ 的积（记为 $A\mathbf{x}$ ） 就是 $A$ 的各列以 $\mathbf{x}$ 中对应元素为权的线性组合，即</p><script type="math/tex; mode=display">A\mathbf{x}=\begin{bmatrix} \mathbf{a}_1& \mathbf{a}_2 &\cdots  &\mathbf{a}_n \end{bmatrix}\begin{bmatrix}   x_1 \\   x_2 \\   \vdots  \\   x_n \\\end{bmatrix}= x_1\mathbf{a}_1+x_2\mathbf{a}_2+\cdots+x_n\mathbf{a}_n</script><p>当且仅当 $A$ 中的列数等于 $\mathbf{x}$ 中元素个数时 $A\mathbf{x}$ 才有定义。</p><p>线性方程组可以用矩阵方程表示</p><p><strong>定理1</strong>　若 $A$ 是 $m\times n$ 矩阵，它的各列为 $\mathbf{a}_1,\mathbf{a}_2,\dots,\mathbf{a}_n$，同时 $\mathbf{b}$ 属于 $\mathbb{R}^n$，则矩阵方程</p><script type="math/tex; mode=display">A\mathbf{x}=\mathbf{b}</script><p>与向量方程</p><script type="math/tex; mode=display">x_1\mathbf{a}_1+x_2\mathbf{a}_2+\cdots+x_n\mathbf{a}_n=\mathbf{b}</script><p>以及与增广矩阵为</p><script type="math/tex; mode=display">\begin{bmatrix}   \mathbf{a}_1 &\mathbf{a}_2 &\cdots &\mathbf{a}_n & \mathbf{b}\end{bmatrix}</script><p>的线性方程组都有相同的解集。</p><p>上述定理是研究线性代数问题的有力工具，使我们现在可将线性方程组用三种不同但彼此等价的观点来研究：作为矩阵方程、作为向量方程或作为线性方程组。当构造实际生活中某个问题的数学模型时，我们可自由地选择任何一种最自然的观点。于是我们可在方便的时候由一种观点转向另一种观点。任何情况下，矩阵方程、向量方程以及线性方程组都用相同方法来解——用行化简算法来化简增广矩阵。</p><p>下面讨论线性方程组解的情况。</p><p><strong>定理2</strong>　若 $A$ 是 $m\times n$ 矩阵，则下列命题逻辑上是等价的。即同时成立或同时不成立。</p><ol><li>对 $\mathbb{R}^n$ 中每个 $\mathbf{b}$，方程 $A\mathbf{x}=\mathbf{b}$ 有解。</li><li></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;h1 id=&quot;线性方程组&quot;&gt;&lt;a href=&quot;#线性方程组&quot; class=&quot;headerlink&quot; title=&quot;线性方程组&quot;&gt;&lt;/a&gt;线性方程组&lt;/h1&gt;&lt;h2 id=&quot;1-线性方程组&quot;&gt;&lt;a href=&quot;#1-线性方程组&quot; c</summary>
      
    
    
    
    <category term="Linear Algebra" scheme="http://example.com/categories/Linear-Algebra/"/>
    
    
  </entry>
  
  <entry>
    <title>8. Adaptive Boost</title>
    <link href="http://example.com/2022/03/19/MachineLearning/8.AdaptiveBoost/"/>
    <id>http://example.com/2022/03/19/MachineLearning/8.AdaptiveBoost/</id>
    <published>2022-03-18T16:00:00.000Z</published>
    <updated>2022-05-06T01:05:56.066Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><h2 id="1-历史背景"><a href="#1-历史背景" class="headerlink" title="1. 历史背景"></a>1. 历史背景</h2><p>1984 年，Leslie Valiant 提出概率近似正确（probably approximately correct，PAC）学习框架。当存在算法满足 $P[R(h_S)\le\epsilon]\ge 1-\delta$，$R(h_S)$ 是算法 $h$ 数据集 $S$ 上的经验误差，同时样本量 $m\ge poly(1/\epsilon,1/\delta,n,size(c))$，则称该算法为 PAC可学习的（learnable）。当 $\epsilon \in (0, 0.5)$ 且 $\delta \in (0, 0.5)$ 时，即算法学习成功的概率大于 $0.5$，且误分类率 $err(h)&lt;\epsilon$，则称算法拟合的那个概念是强可学习的；如果满足 $\delta \in [0, 0.5]$ 的基础上，算法的误差率 $err(h)&lt;1/2-\gamma$，则称为弱可学习。</p><p>1988 年，Michael Kearns 提出问题 “is weakly learnability equivalent to strong learnability?” 是提升机器学习算法（boosting）的起源。</p><p>1990 年，Yoav Freund 提出 Boost-by-majority 算法，并给予证明，即 PAC 学习架构下强可学习和弱可学习是充分必要条件，但该算法并不实用。</p><p>1995 年，Yoav Freund 和 Robert Schapire 提出 AdaBoost 算法，他们的工作获得了 2003 年哥德尔奖。</p><p>2000 年，Friedman 等人提出 Boosting Tree 算法。</p><h2 id="2-Adaboost-算法"><a href="#2-Adaboost-算法" class="headerlink" title="2. Adaboost 算法"></a>2. Adaboost 算法</h2><p>boosting 算法是一种集成算法，主要作用就是将弱可学习分类器转化为强可学习分类器，因为在分类问题中，给定一个训练样本集，弱分类器是比较容易得到的。Adaboost 是自适应算法，通过调整训练数据的概率分布，使随后的弱学习器更关注那些被先前分类器错误分类的实例，这样就保证在不同的弱分类器中，使得所有训练数据都能被有效的分类，最后通过多个弱学习器加权多数表决的方法，得到最终分类结果。        </p><p>给定二元分类训练数据集：</p><script type="math/tex; mode=display">T=\{(\mathbf x_1,y_1),(\mathbf x_2,y_2),...,(\mathbf x_N,y_N)\}</script><p>其中，${\displaystyle \mathbf x_i\in \mathcal{X}\subseteq R^n}$ 表示实例的特征向量，$y\in \mathcal{Y}=\{-1,+1\}$ 表示实例的类别，也就是标记（label）。给定实例特征向量$\mathbf x$，输出所属的类 $y$ 。</p><p>首先初始化训练数据集的权重</p><script type="math/tex; mode=display">D_1=(1/N,1/N,\dots,1/N)</script><p>假设第 $t$ 轮的权重为 $D_t$，通过弱分类算法 $A$ 产生一个弱分类器 $h_t\in \mathcal{H},h_t:\mathcal{X}\rightarrow \mathcal{Y}$，</p><p>弱分类器的误分类率为</p><script type="math/tex; mode=display">\begin{aligned}    \epsilon_t &= error_{D_t}(h_t)\\    &=P(h_t(\mathbf x_i)\ne y_i) \\    &=\sum_{i=t}^N D_t(i)\cdot I (h_t(\mathbf x_i)\ne y_i)\\    &=\sum_{h_t(\mathbf x_i)\ne y_i} D_t(i)\end{aligned}</script><p>弱分类算法 $A$ 的损失函数就是最小化误分类率 $\epsilon_t$，在这里需要保证 $\epsilon_t&lt;1/2$，否则就不是弱分类器，算法停止。</p><p>计算弱分类器 $h_t$ 的系数 </p><script type="math/tex; mode=display">\alpha_t=\frac{1}{2}\ln \frac{1-\epsilon_t}{\epsilon_t}</script><p>从公式中可以看出，当 $\epsilon_t<1/2$ 时，$\alpha_t>0$，且 $\alpha_t$ 随着 $\epsilon_t$ 的减小而增加，因此分类误差率越小的弱分类器在最后多数表决时起的作用越大。</p><p>更新训练数据集的权重</p><script type="math/tex; mode=display">D_{t+1}(i)=\frac{D_t(i)}{Z_t}e^{-\alpha_ty_ih_t(\mathbf x_i)}</script><p>$Z_t$ 是规范化因子，它保证了更新后的权重也是一个概率分布</p><script type="math/tex; mode=display">Z_t=\sum_{i=1}^N D_t(i)e^{-\alpha_ty_ih_t(\mathbf x_i)}</script><p>从更新公式中可以看出，当分类正确时，权重乘以 $e^{-\alpha}$ 会降低 ，当分类错误时，权重乘以 $e^{\alpha}$ 会增加。相较于正确分类样本，误分类样本的权值被放大 $\displaystyle e^{2\alpha}=\frac{1-\epsilon}{\epsilon}$倍。</p><p>将以上步骤重复 $T$ 次，就得到了 $T$ 个弱分类器，最终 Adaboost 的输出结果为</p><script type="math/tex; mode=display">H(\mathbf x)=\mathrm{sign}\left(\sum_{t=1}^T \alpha_t h_t(\mathbf x)\right)</script><p>在式中，$\displaystyle \sum_{t=1}^T \alpha_t h_t(\mathbf x)$ 的正负号决定了实例 $\mathbf{x}$ 的分类结果，绝对值表示分类的确信度。</p><h2 id="2-Adaboost-算法分析与证明"><a href="#2-Adaboost-算法分析与证明" class="headerlink" title="2. Adaboost 算法分析与证明"></a>2. Adaboost 算法分析与证明</h2><p>Adaboost 算法对于给定的训练数据集，对于足够多的轮次 $T$ 之后，可以证明出最后的分类器 $H$ 的训练误差很小。定义 $H$ 在训练数据集 $S$ 上的训练误差为</p><script type="math/tex; mode=display">err_S(H)=\frac{1}{N}\sum_{i=1}^N \mathbf I (H(\mathbf x_i)\ne y_i)</script><p>对于每一轮 $t$，目前为止构建的弱分类器的线性组合为</p><script type="math/tex; mode=display">F_t(\mathbf x)=\sum_{j=1}^t\alpha_j h_j(\mathbf{x})</script><p><strong>引理 1.</strong> 对于每一轮 $t$，$D_{t+1}(i)\propto e^{-y_iF_t(\mathbf x_i)}$，即分布 $D_{t+1}(i)$ 根据历史弱分类器 $F_t$ 的值对结果进行加权。</p><p>证明：</p><script type="math/tex; mode=display">\begin{aligned}    D_{t+1}(i) &= \frac{D_t(i)}{Z_t}e^{-\alpha_ty_ih_t(\mathbf x_i)}\\    &=\frac{D_{t-1}(i)}{Z_tZ_{t-1}}e^{-\alpha_ty_ih_t(\mathbf x_i)}e^{-\alpha_{t-1}y_ih_{t-1}(\mathbf x_i)} \\    &\dots \\    &= \frac{D_1(i)}{ \prod_{j=1}^t Z_j}e^{ -y_i  \sum_{j=1}^t\alpha_jh_j(\mathbf x_i)} \\    &= \frac{1}{ N\prod_{j=1}^t Z_j}e^{-y_iF_t(\mathbf x_i)}\end{aligned}</script><p>因此，分布 $D_{t+1}$ 根据目前得到的函数 $F_t$ 的间隔（margin） $y_iF_t(\mathbf x_i)$ 为 $S$ 中的样本 $(\mathbf x_i, y_i)$ 分配权重。间隔越小表示分类效果越差，因此权重越大，这迫使第 $t+1$ 轮的弱学习器专注于 $F_t$ 未准确分类的实例。</p><p><strong>引理 2.</strong> $\displaystyle err_S(H)\le \frac{1}{N}\sum_{i=1}^N e^{-y_iF_T(\mathbf x_i)}=\prod_{j=1}^T Z_j$</p><p>证明：当 $H(\mathbf x_i)\ne y_i$ 时，$y_iF_T(\mathbf x_i)\le0$，因此 $e^{-y_iF_T(\mathbf x_i)}\ge1$，从而得到</p><script type="math/tex; mode=display">err_S(H)\le 1 \le \frac{1}{N}\sum_{i=1}^N e^{-y_iF_T(\mathbf x_i)}</script><p>进一步地，由引理 1 得到</p><script type="math/tex; mode=display">\begin{aligned}    \frac{1}{N}&\sum_{i=1}^N e^{-y_iF_T(\mathbf x_i)} \\     &= \prod_{j=1}^t Z_j \sum_{i=1}^ND_{t+1}(i) \end{aligned}</script><p>由于 </p><script type="math/tex; mode=display">\displaystyle \sum_{i=1}^ND_{t+1}(i) =1</script><p>因此 </p><script type="math/tex; mode=display">\displaystyle \frac{1}{N}\sum_{i=1}^N e^{-y_iF_T(\mathbf x_i)}=\prod_{j=1}^T Z_j</script><p><strong>引理 3.</strong> 对于给定的 $\alpha_t$，每一轮归一化常数具有简单形式 $Z_t=2\sqrt{\epsilon_t(1-\epsilon_t)}$</p><p>证明：根据前面可知</p><script type="math/tex; mode=display">\displaystyle e^{2\alpha_t}=\frac{1-\epsilon_t}{\epsilon_t}</script><p>推出</p><script type="math/tex; mode=display">\displaystyle e^{-\alpha_t}=\sqrt{\frac{\epsilon_t}{1-\epsilon_t}}</script><p>并且</p><script type="math/tex; mode=display">{\displaystyle y_ih_t(\mathbf x_i)={    \begin{cases}        +1&\mathrm{if}\quad h_t(\mathbf x_i)=y_i\\        -1&\mathrm{otherwise}    \end{cases}    }}</script><p>因此</p><script type="math/tex; mode=display">\begin{aligned}     Z_t&=\sum_{i=1}^N D_t(i)e^{-\alpha_ty_ih_t(\mathbf x_i)}\\     &= \sum_{i=1}^N D_t(i)\left(e^{-\alpha_t}I( h_t(\mathbf x_i)=y_i)+e^{\alpha_t}I( h_t(\mathbf x_i)\ne y_i)\right)\\     &=e^{-\alpha_t}\sum_{i=1}^N D_t(i)\cdot I( h_t(\mathbf x_i)=y_i) + e^{\alpha_t}\sum_{i=1}^N D_t(i)\cdot I( h_t(\mathbf x_i)\ne y_i)\\     &= \sqrt{\frac{\epsilon_t}{1-\epsilon_t}} (1-\epsilon_t)+\sqrt{\frac{1-\epsilon_t}{\epsilon_t}}\epsilon_t \\     &=2\sqrt{\epsilon_t(1-\epsilon_t)}\end{aligned}</script><p><strong>引理 4.</strong> $\displaystyle\gamma \in (0,\frac{1}{2}]$时，如果 $\displaystyle\epsilon_t\le \frac{1}{2}-\gamma$，存在 $err_S(H)\le e^{-2T\gamma^2}$</p><p>证明：由引理 2 和引理 3 可得</p><script type="math/tex; mode=display">\begin{aligned}     err_S(H)&\le \prod_{t=1}^T Z_j\\      &= \prod_{t=1}^T 2\sqrt{\epsilon_t(1-\epsilon_t)}\\     &\le2^T\prod_{t=1}^T \sqrt{(\frac{1}{2}-\gamma)(\frac{1}{2}+\gamma)},\\     &\qquad \text{ since } \epsilon_t\le \frac{1}{2}-\gamma，\mathrm{and} \sqrt{x(1-x)} \text{ is an increasing function of } x \text{ on }  (0,\frac{1}{2}]\\     &= 2^T\prod_{t=1}^T \sqrt{\frac{1}{4}-\gamma^2} \\     &= (1-4\gamma^2)^{T/2}\\     &\le e^{-2T\gamma^2},\text{ since } 1-x\le e^{-x}\end{aligned}</script><p>从引理中可以看出，如果弱学习器的分类结果比随机预测 $(0.5)$ 的结果要好，那么最终分类器 $H$ 的误差将随着 $T$ 的增加呈指数下降，且对于足够大的 $T$，误差会变得足够小。</p><h2 id="3-Adaboost-损失函数"><a href="#3-Adaboost-损失函数" class="headerlink" title="3. Adaboost 损失函数"></a>3. Adaboost 损失函数</h2><p>前面的算法过程是直接给出了 $\alpha$ 的取值方式，如果给定 Adaboost 的损失函数，事实上每一步 $\alpha_t$ 的取值都是为了使损失函数最小。</p><p>定义指数损失函数为</p><script type="math/tex; mode=display">L(y,f)=e^{-yf}</script><p>定义 Adaboost 的损失函数为指数损失函数</p><script type="math/tex; mode=display">L(Y,F_T(X))=\sum_{i=1}^N e^{-y_iF_T(\mathbf x_i)}</script><p>其中</p><script type="math/tex; mode=display">F_T(\mathbf x)=\sum_{j=1}^T\alpha_j h_j(\mathbf{x})</script><p>求解该损失函数极小化问题是一个复杂的优化问题，可以使用前向分布算法的思想。前向分步算法类似动态规划中的前向计算，每一步只求取一个的最优分类器 $h_j$ 及其参数 $\alpha_j$，与之前的过程无关，即前 $t-1$ 步求取的分类器及参数都当做定值。</p><p>从上述思想中可以得到第 $t$ 次迭代得到的分类器为</p><script type="math/tex; mode=display">F_t(\mathbf{x}_i)=F_{t-1}(\mathbf{x}_i)+\alpha_th_t(\mathbf{x}_i)</script><p>损失函数为</p><script type="math/tex; mode=display">\begin{aligned}    L(Y,F_t(X))&=\sum_{i=1}^N e^{-y_i(F_{t-1}(\mathbf{x}_i)+\alpha_th_t(\mathbf{x}_i))}\\    &=\sum_{i=1}^Ne^{-y_iF_{t-1}(\mathbf{x}_i)} e^{\alpha_t y_ih_t(\mathbf{x}_i)}\\    &=\sum_{i=1}^N (N\prod_{j=1}^{t-1} Z_j) D_{t}(i) e^{\alpha_t y_ih_t(\mathbf{x}_i)}\end{aligned}</script><p>最小化上述损失函数，对于任意的 $\alpha_t&gt;0$，使损失函数最小可以得到</p><script type="math/tex; mode=display">h_t(\mathbf{x})=\argmin_h \sum_{i=1}^N D_{t}(i)I( h_t(\mathbf x_i)\ne y_i)</script><p>其实就是弱分类器的误分类率</p><p>由之间的定理 3 将损失函数进一步拆分</p><script type="math/tex; mode=display">\begin{aligned}     L(Y,F_t(X))&=(N\prod_{j=1}^{t-1} Z_j)\sum_{i=1}^N D_t(i)e^{-\alpha_ty_ih_t(\mathbf x_i)}\\     &= (N\prod_{j=1}^{t-1} Z_j)\sum_{i=1}^N D_t(i)\left(e^{-\alpha_t}I( h_t(\mathbf x_i)=y_i)+e^{\alpha_t}I( h_t(\mathbf x_i)\ne y_i)\right)\\     &= (N\prod_{j=1}^{t-1} Z_j)(e^{-\alpha_t} (1-\epsilon_t)+e^{\alpha_t}\epsilon_t) \\\end{aligned}</script><p>对 $\alpha_t$ 求导，并令导数为 0，可以得到</p><script type="math/tex; mode=display">-e^{-\alpha_t} (1-\epsilon_t)+e^{\alpha_t}\epsilon_t=0</script><p>解得</p><script type="math/tex; mode=display">\alpha_t=\frac{1}{2}\ln{\frac{1-\epsilon_t}{\epsilon_t}}</script><p>结果与前面给出的一致。</p><p>实际上每一步 $t$ 的弱分类器是加权后的误分类率 $\epsilon_t$ 最小，然后确定最小的误分类率之后，$\alpha_t$ 的取值使最终分类器的损失函数最小。</p><h2 id="3-Adaboost-回归"><a href="#3-Adaboost-回归" class="headerlink" title="3. Adaboost 回归"></a>3. Adaboost 回归</h2><p>相对应于分类问题的误分类率，在回归问题中则是误差率，需要归一化处理并最后取平均值得到平均误差率，保证其值在 $[0,1]$ 之间即可。</p><p>首先初始化训练数据集的权重</p><script type="math/tex; mode=display">D_1=(1/N,1/N,\dots,1/N)</script><p>假设第 $t$ 轮的权重为 $D_t$，通过弱分类算法 $A$ 产生一个弱学习器 $h_t\in \mathcal{H},h_t:\mathcal{X}\rightarrow \mathcal{Y}$</p><p>每个样本的相对误差</p><script type="math/tex; mode=display">e_i = \frac{|y_i-h(\mathbf x_i)|}{\displaystyle \max_j |y_j-h(\mathbf x_j)|}</script><p>这里是曼哈顿距离，如果是平方误差则为</p><script type="math/tex; mode=display">e_i = \frac{(y_i-h(\mathbf x_i))^2}{\displaystyle \max_j (y_j-h(\mathbf x_j))^2}</script><p>指数误差则为（存疑）</p><script type="math/tex; mode=display">e_i = 1-\exp({\frac{|y_i-h(\mathbf x_i)|}{\displaystyle\max_j |y_j-h(\mathbf x_j)|}})</script><p>第 $t$ 轮弱学习器的误差率为</p><script type="math/tex; mode=display">\epsilon_t = \sum_i^N D_t(i)e_i</script><p>计算弱学习器 $h_t$ 的系数 </p><script type="math/tex; mode=display">\alpha_t=\frac{1}{1-\epsilon_t}-1=\frac{\epsilon_t}{1-\epsilon_t}</script><p>更新训练数据集的权重</p><script type="math/tex; mode=display">D_{t+1}(i)=\frac{D_t(i)}{Z_t}\alpha_t^{1-e_i}</script><p>$Z_t$ 是规范化因子</p><script type="math/tex; mode=display">Z_t=\sum_{i=1}^N D_t(i)\alpha_t^{1-e_i}</script><p>最后是结合策略，采用的是对加权的弱学习器取权重中位数对应的弱学习器作为强学习器的方法，最终的强回归器为</p><script type="math/tex; mode=display">\ln \frac{1}{\alpha_t},t=1,2,3,\dots,T</script><p>的中位数值序号 $t^<em>$ 对应的学习器 $h_{t^</em>}$</p><blockquote><p><a href="https://zhuanlan.zhihu.com/p/66799567">1. 【Mohri-机器学习基础】第2章: PAC学习框架-zhihu</a><br><a href="https://blog.csdn.net/rongxiang20054209/article/details/77601091?utm_medium=distribute.pc_aggpage_search_result.none-task-blog-2~aggregatepage~first_rank_ecpm_v1~rank_v31_ecpm-1-77601091.pc_agg_new_rank&amp;utm_term=pac%E5%BC%B1%E5%8F%AF%E5%AD%A6%E4%B9%A0&amp;spm=1000.2123.3001.4430">2. PAC（probably approximately correct） 学习架构介绍-csdn</a><br><a href="https://en.wikipedia.org/wiki/Boosting_(machine_learning">3. Boosting (machine learning)-wiki</a>)</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;h1 id=&quot;决策树&quot;&gt;&lt;a href=&quot;#决策树&quot; class=&quot;headerlink&quot; title=&quot;决策树&quot;&gt;&lt;/a&gt;决策树&lt;/h1&gt;&lt;h2 id=&quot;1-历史背景&quot;&gt;&lt;a href=&quot;#1-历史背景&quot; class=&quot;head</summary>
      
    
    
    
    <category term="Machine learning" scheme="http://example.com/categories/Machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>7. Support Vecor Machine</title>
    <link href="http://example.com/2022/03/17/MachineLearning/7.SupportVecorMachine/"/>
    <id>http://example.com/2022/03/17/MachineLearning/7.SupportVecorMachine/</id>
    <published>2022-03-16T16:00:00.000Z</published>
    <updated>2022-06-06T03:00:43.698Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><h1 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h1><h2 id="1-历史背景"><a href="#1-历史背景" class="headerlink" title="1. 历史背景"></a>1. 历史背景</h2><p>支持向量机的发明可以追溯到 20 世纪中叶一系列事件。</p><p>1950 年，Aronszajn 发表了 “Theory of Reproducing Kernels”。</p><p>1957 年，Frank Rosenblatt 采用上述思想，发明了感知机，一种简单的线性分类器。</p><p>1963 年，Vapnik 和 Lerner 发表了 “Generalized Portrait Algorithm”，这是支持向量机的灵感来源。</p><p>1992 年，Vladimir Vapnik 和同事 Bernhard Boser、Isabelle Guyon 在 AT&amp;T 贝尔实验室开发出支持向量机算法。</p><p>1995 年，Vladimir Vapnik 和 Cortes 开发出软边距（soft margin）分类器。</p><p>1998 年，Shawe、Taylor 等人，对硬间隔（hard margin）支持向量机的泛化做出了重大贡献。</p><p>2001 年，Vladimir Vapnik 和 Hava Siegelmann 开发出支持向量聚类（Support Vector Clustering，SVC），可以用于未标记的数据。</p><h2 id="2-基础预备"><a href="#2-基础预备" class="headerlink" title="2. 基础预备"></a>2. 基础预备</h2><h3 id="2-1-拉格朗日乘数法-3"><a href="#2-1-拉格朗日乘数法-3" class="headerlink" title="2.1 拉格朗日乘数法[3]"></a>2.1 拉格朗日乘数法<a href="#refer-anchor-1"><sup>[3]</sup></a></h3><p>假设 $f(x,y)$ 与 $g(x,y)$ 都具有连续的一阶导数，即在 $\R^n$ 上是连续可微函数，考虑最优化问题</p><script type="math/tex; mode=display">{\min f(x,y)} \\{\displaystyle s.t \quad  g(x,y)=0}</script><p>如果 $f(x,y)$ 与 $g(x,y)$ 在 $(x_0,y_0)$ 处取极值，它们必定相切，因此梯度平行</p><script type="math/tex; mode=display">\triangledown f(x,y)=\lambda\triangledown g(x,y)</script><p>同时必定满足</p><script type="math/tex; mode=display">g(x,y)=0</script><p>将它们联立起来即可求解出 $(x_0,y_0)$ 的取值。</p><p>拉格朗日乘数法将上述优化问题构造为一个新的函数称作拉格朗日函数</p><script type="math/tex; mode=display">{\displaystyle {\mathcal {L}}(x,y,\lambda )=f(x,y)-\lambda g(x,y)}</script><p>然后直接求解拉格朗日函数的极值点，即</p><script type="math/tex; mode=display">{\displaystyle {    \begin{cases}        \triangledown_x{\mathcal {L}}(x,y,\lambda )=0\\        \triangledown_y{\mathcal {L}}(x,y,\lambda )=0\\        \triangledown_\lambda{\mathcal {L}}(x,y,\lambda )=0    \end{cases}    }}</script><p>事实上，这与下式是完全一样的。</p><script type="math/tex; mode=display">{\displaystyle {    \begin{cases}        \triangledown f(x,y)=\lambda\triangledown g(x,y)\\        \;\\        g(x,y)=0\\    \end{cases}    }}</script><p>因此拉格朗日乘数法只是一种构造方法，本质是极值点处的两个曲线相切。</p><h3 id="2-2-广义拉格朗日乘数法"><a href="#2-2-广义拉格朗日乘数法" class="headerlink" title="2.2 广义拉格朗日乘数法"></a>2.2 广义拉格朗日乘数法</h3><p>Harold W. Kuhn 和 Albert W. Tucker 将拉格朗日乘数法进行了推广，在满足 Karush-Kuhn-Tucker (KKT) 条件的情况下，允许不等式约束。</p><h4 id="2-2-1-原始问题"><a href="#2-2-1-原始问题" class="headerlink" title="2.2.1 原始问题"></a>2.2.1 原始问题</h4><p>考虑如下最优化问题，$f,g,h$ 都具有连续的一阶导数，即在 $\R^n$ 上是连续可微函数</p><script type="math/tex; mode=display">\begin{aligned}    &\min_{\mathbf x} f(\mathbf x) \\    \displaystyle s.t \quad  &g_i(\mathbf x)\le 0 & i=1,2,\dots,k\\    &h_j(\mathbf x) =0 & j=1,2,\dots,l\\\end{aligned}</script><p>构造如下拉格朗日函数</p><script type="math/tex; mode=display">{\displaystyle L(\mathbf x,\mu ,\lambda )=f(\mathbf x)+\sum _{i=1}^{k}\mu _{i}g_{i}(\mathbf x)+\sum _{j=1}^{l }\lambda _{j}h_{j}(\mathbf x)}</script><p>其中，$\mu_i,\lambda_j$ 是拉格朗日乘子。考虑如下目标函数</p><script type="math/tex; mode=display">\theta_{\mathcal P}(\mathbf x)=\max_{\mu,\lambda:\mu_i\ge 0}L(\mathbf x,\mu ,\lambda )</script><p>这里，$\mathcal P$ 代表原始（primal）问题，相对的是对偶（dual）问题 $\mathcal  D$。</p><p>假设给定 $\mathbf x$，如果 $\mathbf x$ 不满足任一约束条件，即存在 $g_i(\mathbf x)&gt; 0$ 或者 $h_j(\mathbf x)\ne0$，会导致</p><script type="math/tex; mode=display">\theta_{\mathcal P}(\mathbf x)=\max_{\mu,\lambda:\mu_i\ge 0}L(\mathbf x,\mu ,\lambda )=+\infty</script><p>因为，当 $g_i(\mathbf x)&gt; 0$ 时，$\theta_{\mathcal P}(\mathbf x)$ 随 $\mu_i$ 的增大而增大，最终趋于正无穷；当 $h_j(\mathbf x)\ne0$ 时，如果 $h_j(\mathbf x)&gt;0$，$\theta_{\mathcal P}(\mathbf x)$ 随 $\lambda_j$ 的增大而增大，反之随 $\lambda_j$ 的减小而增大，最终都趋于正无穷。</p><p>如果 $\mathbf x$ 满足约束条件，可以得到 $\theta_{\mathcal P}(\mathbf x)=f(\mathbf x)$。因此</p><script type="math/tex; mode=display">{\displaystyle \theta_{\mathcal P}(\mathbf x)={    \begin{cases}        f(\mathbf x)&\text{if }\mathbf x \text{ satisfies primal constraints}\\        +\infty&\text{otherwise}    \end{cases}    }}</script><p>所以，对于满足原始约束的 $\mathbf{x}$ 的所有值，$\theta_{\mathcal P}(\mathbf x)$ 与最优化问题中的目标值相同，如果不满足原始约束，则值为正无穷大。因此，如果考虑最小化问题</p><script type="math/tex; mode=display">\min_{\mathbf x}\theta_{\mathcal P}(\mathbf x)=\min_{\mathbf x}\max_{\mu,\lambda:\mu_i\ge 0}L(\mathbf x,\mu ,\lambda )</script><p>它与原始最优化问题是等价的，即具有相同的解。定义原始最优问题的最优解为</p><script type="math/tex; mode=display">p^*=\min_{\mathbf{x}}\theta_{\mathcal P}(\mathbf x)</script><h4 id="2-2-2-对偶问题"><a href="#2-2-2-对偶问题" class="headerlink" title="2.2.2 对偶问题"></a>2.2.2 对偶问题</h4><p>定义对偶问题</p><script type="math/tex; mode=display">\theta_{\mathcal D}(\mu,\lambda)=\min_{\mathbf{x}}L(\mathbf x,\mu ,\lambda )</script><p>再将上式极大化</p><script type="math/tex; mode=display">\max_{\mu,\lambda:\mu_i\ge 0}\theta_{\mathcal D}(\mu,\lambda)=\max_{\mu,\lambda:\mu_i\ge 0}\min_{\mathbf x}L(\mathbf x,\mu ,\lambda )</script><p>定义对偶问题的最优值</p><script type="math/tex; mode=display">d^*=\max_{\mu,\lambda:\mu_i\ge 0}\theta_{\mathcal D}(\mu,\lambda)</script><blockquote><p>用函数值集合理解对偶问题<a href="#refer-anchor-1"><sup>[7]</sup></a>。</p><p>将问题简单化，只考虑一个不等式约束，假设 $f,g$ 映射后的值为 $a,b$，那拉格朗日函数即为 $a+\lambda b$，其中 $b\le 0$。原始问题中是先对于不同的 $\mathbf{x}$，即每一组 $a,b$ 都求最大化的 $a+\lambda b$，由于 $b\le 0$，因此 $\lambda=0$ 时，$a+\lambda b$ 值最大，因此然后只需要再最小化 $a$ 即 $f(\mathbf{x})$ 即可。</p><p>反之，在对偶问题中，则是对于每一个斜率 $\lambda$，都求得一个最小化的 $a+\lambda b$，最后再在所有 $\lambda$ 中选一个能使 $a+\lambda b$ 最大化的即可，而 $a+\lambda b$ 实际上是该直线的截距。</p></blockquote><h4 id="2-2-3-原始问题与对偶问题关系"><a href="#2-2-3-原始问题与对偶问题关系" class="headerlink" title="2.2.3 原始问题与对偶问题关系"></a>2.2.3 原始问题与对偶问题关系</h4><p><strong>定理1. （弱对偶性）</strong> 若原始问题和对偶问题都有最优值，则</p><script type="math/tex; mode=display">d^*=\max_{\mu,\lambda:\mu_i\ge 0}\min_{\mathbf x}L(\mathbf x,\mu ,\lambda )\le \min_{\mathbf x}\max_{\mu,\lambda:\mu_i\ge 0}L(\mathbf x,\mu ,\lambda )=p^*</script><p>证明：对于任意的 $\mu ,\lambda$</p><script type="math/tex; mode=display">\theta_{\mathcal D}(\mu,\lambda)=\min_{\mathbf{x}}L(\mathbf x,\mu ,\lambda )\le L(\mathbf x,\mu ,\lambda )</script><p>对于任意的 $\mathbf x$，有</p><script type="math/tex; mode=display">\theta_{\mathcal P}(\mathbf x)=\max_{\mu,\lambda:\mu_i\ge 0}L(\mathbf x,\mu ,\lambda )\ge L(\mathbf x,\mu ,\lambda )</script><p>因此</p><script type="math/tex; mode=display">\theta_{\mathcal D}(\mu,\lambda)\le \theta_{\mathcal P}(\mathbf x)</script><p>已知原始问题和对偶问题均有最优值，因此</p><script type="math/tex; mode=display">\max_{\mu,\lambda:\mu_i\ge 0}\theta_{\mathcal D}(\mu,\lambda)\le \min_{\mathbf x}\theta_{\mathcal P}(\mathbf x)</script><p>即</p><script type="math/tex; mode=display">d^*=\max_{\mu,\lambda:\mu_i\ge 0}\min_{\mathbf x}L(\mathbf x,\mu ,\lambda )\le \min_{\mathbf x}\max_{\mu,\lambda:\mu_i\ge 0}L(\mathbf x,\mu ,\lambda )=p^*</script><p><strong>定理2. （强对偶性的充分条件）</strong> 如果函数 $f,g_i$ 是凸函数，$h_j$ 是仿射函数，并且不等式约束 $g$ 是严格执行的，即存在 $\mathbf{x}$ 对所有 $i$ 有 $g_i(\mathbf{x})&lt;0$，则存在 $\mathbf{x}^<em>,\mu^</em>,\lambda^<em>$，使 $\mathbf{x}^</em>$ 是原始问题的解，$\mu^<em>,\lambda^</em>$ 是对偶问题的解，并且</p><script type="math/tex; mode=display">p^*=d^*=L(\mathbf{x}^*,\mu^*,\lambda^*)</script><p><strong>定理3. （强对偶性的充要条件）</strong> 如果函数 $f,g_i$ 是凸函数，$h_j$ 是仿射函数，并且不等式约束 $g$ 是严格执行的，则存 $\mathbf{x}^<em>$ 和 $\mu^</em>,\lambda^<em>$ 分别是原始问题和对偶问题的解的充要条件是 $\mathbf{x}^</em>,\mu^<em>,\lambda^</em>$ 满足如下 Karush-Kuhn-Tucker (KKT) 条件</p><script type="math/tex; mode=display">\triangledown_{\mathbf{x}}L(\mathbf{x}^*,\mu^*,\lambda^*)=0</script><script type="math/tex; mode=display">\mu_ig_i(\mathbf{x}^*)=0,\quad i=1,2,\cdots,k</script><script type="math/tex; mode=display">g_i(\mathbf{x}^*)\le0,\quad i=1,2,\cdots,k</script><script type="math/tex; mode=display">\mu_i^*\ge0,\quad i=1,2,\cdots,k</script><script type="math/tex; mode=display">h_j(\mathbf{x}^*)=0,\quad j=1,2,\cdots,l</script><p>后面三个关系式其实就是约束条件。第二个关系式是对偶互补条件，类似于线性规划中互补松弛性，当影子价格 $\mu_i^<em>&gt;0$，则 $g_i(\mathbf{x}^</em>)=0$，如果 $g_i(\mathbf{x}^<em>)&lt;0$，则 $\mu_i^</em>=0$。</p><h2 id="3-基本概念"><a href="#3-基本概念" class="headerlink" title="3. 基本概念"></a>3. 基本概念</h2><p>假设训练数据集：</p><script type="math/tex; mode=display">T=\{(\mathbf x_1,y_1),(\mathbf x_2,y_2),...,(\mathbf x_N,y_N)\}</script><p>其中，${\displaystyle \mathbf x_i\in \mathcal{X}\subseteq R^n}$ 表示实例的特征向量，$y\in \mathcal{Y}=\{+1,-1\}$ 表示实例的类别。</p><p>在感知机中，通过超平面对线性可分的数据进行分类，超平面为</p><script type="math/tex; mode=display">{\displaystyle f(\mathbf x)=\mathbf w\cdot \mathbf x+b}</script><p>超平面将特征空间分为两部分，法向量指向的一侧为正类，另一侧为负类，即 $\mathbf w\cdot \mathbf x+b &gt; 0$ 时为正，反之为负。</p><p>在感知机算法中，满足条件的超平面有多个，而支持向量机就是寻找最优的一个。至于哪一个是最优的，直观的想法就是距离正负实例都尽可能的远，可能最终影响到超平面位置的只有两个实例，距离超平面最近的一正一负两实例。</p><p>实例到超平面的距离还有另一种解释，就是分类的确信程度，距离越远表示分类的确信度越大，距离越近表示确信度越小。为了衡量实例到超平面的距离，引入函数间隔和几何间隔。</p><p>对于分离超平面 $\mathbf w\cdot \mathbf x+b=0$，定义样本点 $(\mathbf x_i,y_i)$ 函数间隔 $\hat{\gamma}_i$ 为</p><script type="math/tex; mode=display">\hat{\gamma}_i = y_i(\mathbf w\cdot \mathbf x_i+b)</script><p>样本集 $T$ 关于超平面的函数间隔则为每个样本点函数间隔的最小值</p><script type="math/tex; mode=display">\hat{\gamma}=\min_i \hat{\gamma}_i</script><p>可以发现，当超平面分类正确时，$w\cdot \mathbf x+b$ 与 $y_i$ 同号，函数间隔为正，当分类错误时，函数间隔为负。</p><p>在感知机中使用的损失函数就是函数间隔，而函数间隔的问题在于并没有正常反映样本点到超平面的距离，例如 $\mathbf w,b$ 同时扩大 $2$ 倍，超平面并没有改变，但同一样本点的函数距离也扩大了 $2$ 倍。因此，在感知机中其实只用到了 $y_i(\mathbf w\cdot \mathbf x_i+b)$ 的符号，当所有样本正确分类则结束算法，在支持向量机中想要考虑距离因素则必须引入几何间隔。</p><p>定义几何间隔</p><script type="math/tex; mode=display">\gamma_i=\frac{y_i(\mathbf w\cdot \mathbf x_i+b)}{\left\|\mathbf w\right\|}</script><p>同理，样本集 $T$ 关于超平面的几何间隔为每个样本点几何间隔的最小值</p><script type="math/tex; mode=display">{\gamma}=\min_i {\gamma}_i</script><p>几何间隔与函数间隔存在如下关系</p><script type="math/tex; mode=display">\gamma=\frac{\hat{\gamma}}{\left\|\mathbf w\right\|}</script><p>如果可以保证 ${\left|\mathbf w\right|}=1$，则几何间隔与函数间隔相等，简化计算。</p><h2 id="4-线性可分：硬间隔支持向量机"><a href="#4-线性可分：硬间隔支持向量机" class="headerlink" title="4. 线性可分：硬间隔支持向量机"></a>4. 线性可分：硬间隔支持向量机</h2><p>支持向量机的核心思想就是在满足正确分类的情况下，同时希望超平面的几何间隔尽可能大，这就是一个条件约束问题。</p><script type="math/tex; mode=display">\begin{aligned}    \max\quad &\gamma \\    \displaystyle s.t \quad  &\frac{y_i(\mathbf w\cdot \mathbf x_i+b)}{\left\|\mathbf w\right\|}\ge \gamma \quad i=1,2,\dots,N\end{aligned}</script><p>根据几何间隔与函数间隔的关系，上式替换为</p><script type="math/tex; mode=display">\begin{aligned}    \max\quad &\frac{\hat{\gamma}}{\left\|\mathbf w\right\|} \\    \displaystyle s.t \quad  &y_i(\mathbf w\cdot \mathbf x_i+b)\ge \hat{\gamma}\quad i=1,2,\dots,N\end{aligned}</script><p>上面的约束问题中，$\hat{\gamma}$ 的取值实际上不影响解的结果，$\mathbf w,b$ 同时扩大 $\lambda$ 倍，$\hat{\gamma}$ 则变为 $\lambda\hat{\gamma}$，对于目标函数来说并没有改变。因此，取 $\hat{\gamma}=1$，同时将最大化 $\displaystyle \frac{1}{\left|\mathbf w\right|}$ 转换为最小化 $\displaystyle\frac{1}{2}\left|\mathbf w\right|^2$，因此最终线性可分支持向量机的最优化问题为</p><script type="math/tex; mode=display">\begin{aligned}    \min\quad &\frac{1}{2}\left\|\mathbf w\right\|^2 \\    \displaystyle s.t \quad  &y_i(\mathbf w\cdot \mathbf x_i+b)-1\ge 0\quad i=1,2,\dots,N\end{aligned}</script><p>该优化问题是具有凸二次目标函数，同时只有线性约束的优化问题。</p><p>求解该凸二次优化问题，需要用到拉格朗日乘子法，并转换为对偶问题求解，优点在于对偶问题更容易求解，且自然引入核函数的概念。</p><p>首先构建拉格朗日函数</p><script type="math/tex; mode=display">L(\mathbf w,b,\alpha)=\frac{1}{2}\left\|\mathbf w\right\|^2-\sum_{i=1}^N\alpha_{i}\left[y_{i}(\mathbf{w}\cdot \mathbf{x}_{i}+b)-1\right]</script><p>原始问题转变为</p><script type="math/tex; mode=display">\min_{\mathbf w,b}\max_{\alpha\ge 0}L(\mathbf w,b,\alpha)</script><p>对偶问题即为</p><script type="math/tex; mode=display">\max_{\alpha\ge 0}\min_{\mathbf w,b}L(\mathbf w,b,\alpha)</script><p>第一步先求 $\displaystyle \min_{\mathbf w,b}L(\mathbf w,b,\alpha)$，分别对 $\mathbf w,b$ 求偏导数并令其等于 $0$。</p><script type="math/tex; mode=display">\triangledown_{\mathbf w}L(\mathbf w,b,\alpha)=\mathbf w-\sum_{i=1}^N \alpha_{i}y_i\mathbf{x}_{i}=0</script><script type="math/tex; mode=display">\triangledown_{b}L(\mathbf w,b,\alpha)=-\sum_{i=1}^N \alpha_{i}y_i=0</script><p>得到</p><script type="math/tex; mode=display">\mathbf w=\sum_{i=1}^N \alpha_{i}y_i\mathbf{x}_{i}</script><script type="math/tex; mode=display">\sum_{i=1}^N \alpha_{i}y_i=0</script><p>将 $\mathbf{w}$ 的表达式带入拉格朗日函数</p><script type="math/tex; mode=display">\begin{aligned}    L(\mathbf w,b,\alpha)&=\frac{1}{2}(\sum_{i=1}^N \alpha_{i}y_i\mathbf{x}_{i})^2-\sum_{i=1}^N\alpha_{i}\left[y_{i}(\sum_{j=1}^N \alpha_{j}y_j\mathbf{x}_{j}\cdot \mathbf{x}_{i}+b)-1\right]\\    &=-\frac{1}{2}(\sum_{i=1}^N \alpha_{i}y_i\mathbf{x}_{i})\cdot(\sum_{j=1}^N \alpha_{j}y_j\mathbf{x}_{j})+\sum_{j=1}^N \alpha_i\end{aligned}</script><p>第二步再求 $\displaystyle\max_{\alpha\ge 0}\min_{\mathbf w,b}L(\mathbf w,b,\alpha)$，优化对偶问题为</p><script type="math/tex; mode=display">\begin{aligned}    \max_{\alpha} &-\frac{1}{2}(\sum_{i=1}^N \alpha_{i}y_i\mathbf{x}_{i})\cdot(\sum_{j=1}^N \alpha_{j}y_j\mathbf{x}_{j})+\sum_{j=1}^N \alpha_i \\    \displaystyle s.t \quad  &\sum_{i=1}^N \alpha_{i}y_i=0 \\    &\alpha_i\ge 0,\qquad i=1,2,\cdots,N \\\end{aligned}</script><p>对目标函数进行变换，改变正负号，由求最大改为最小，得到等价对偶优化问题</p><script type="math/tex; mode=display">\begin{aligned}    \min_{\alpha}\quad &\frac{1}{2}(\sum_{i=1}^N \alpha_{i}y_i\mathbf{x}_{i})\cdot(\sum_{j=1}^N \alpha_{j}y_j\mathbf{x}_{j})-\sum_{j=1}^N \alpha_i \\    \displaystyle s.t \quad  &\sum_{i=1}^N \alpha_{i}y_i=0 \\    &\alpha_i\ge 0,\qquad i=1,2,\cdots,N \\\end{aligned}</script><p>假设求得对偶最优化问题的解为 $\alpha^*$，根据 KKT 条件有</p><script type="math/tex; mode=display">\triangledown_{\mathbf{w}}L(\mathbf w^*,b^*,\alpha^*)=\mathbf w^*-\sum_{i=1}^N \alpha^*_{i}y_i\mathbf{x}_{i}=0</script><script type="math/tex; mode=display">\triangledown_{b}L(\mathbf w^*,b^*,\alpha^*)=-\sum_{i=1}^N \alpha^*_{i}y_i=0</script><script type="math/tex; mode=display">\alpha^*_i[y_i(\mathbf w^*\cdot \mathbf x_i+b^*)-1]=0,\quad i=1,2,\cdots,N</script><script type="math/tex; mode=display">y_i(\mathbf w^*\cdot \mathbf x_i+b^*)-1\ge0,\quad i=1,2,\cdots,N</script><script type="math/tex; mode=display">\alpha_i^*\ge0,\quad i=1,2,\cdots,N</script><p>根据第一个公式可以得到</p><script type="math/tex; mode=display">\mathbf w^*=\sum_{i=1}^N \alpha^*_{i}y_i\mathbf{x}_{i}</script><p>利用反证法可以知道一定存在一个 $\alpha_j^*&gt;0$，因此根据第三个公式也就是互补性可知</p><script type="math/tex; mode=display">y_j(\mathbf w^*\cdot \mathbf x_j+b^*)-1=0</script><p>联立两个式子可以得到</p><script type="math/tex; mode=display">b^*=y_j-\sum_{i=1}^N \alpha^*_{i}y_i\mathbf{x}_{i}\cdot \mathbf x_j</script><p>分离超平面</p><script type="math/tex; mode=display">\begin{aligned}    f(\mathbf x)&=\mathbf w^*\cdot \mathbf x+b^*\\    &=\sum_{i=1}^N \alpha^*_{i}y_i\mathbf{x}_{i}\cdot \mathbf x+y_j-\sum_{i=1}^N \alpha^*_{i}y_i\mathbf{x}_{i}\cdot \mathbf x_j\\    &=\sum_{i=1}^N \alpha^*_{i}y_i\mathbf{x}_{i}\cdot (\mathbf x-\mathbf x_j) + y_i\end{aligned}</script><p>由以上可知，$\mathbf w^<em>$ 和 $b^</em>$ 只依赖于训练数据中对应 $\alpha_j^*&gt;0$ 的样本点 $(\mathbf{x}_i,y_i)$，而其他样本点则没有影响，这个样本点就称为支持向量。</p><blockquote><p>与线性规划相类比，其实这个实例点就是起到桎梏作用的点，如同工厂生产中最紧缺的材料，再增加减少其它材料都不会影响最优解，只有增减该种材料才会影响结果，在支持向量机图中就是移动距离超平面最近的点，自然会影响到超平面的位置。</p></blockquote><h2 id="5-线性近似可分：软间隔支持向量机"><a href="#5-线性近似可分：软间隔支持向量机" class="headerlink" title="5. 线性近似可分：软间隔支持向量机"></a>5. 线性近似可分：软间隔支持向量机</h2><p>在上述硬间隔支持向量机中，所有的约束都是硬约束，如果没有满足所有约束条件的可行解的话就求不出结果。所以，对应于线性近似可分的数据集，如果只有少数异常点无法通过分离超平面区分出来，那么可以给这些不满足的约束条件一个惩罚，最终求出一个近似最优解。其实，这就是线性规划中的目标规划，将原本的硬约束条件改为软约束条件即可。</p><p>根据上述思想，软间隔支持向量机原始问题为</p><script type="math/tex; mode=display">\begin{aligned}    \min\quad &\frac{1}{2}\left\|\mathbf w\right\|^2 + C\sum_{i=1}^N\xi_i \\    \displaystyle s.t \quad  &y_i(\mathbf w\cdot \mathbf x_i+b)\ge 1-\xi_i\quad i=1,2,\dots,N \\    &\xi_i\ge0\quad i=1,2,\dots,N\end{aligned}</script><p>拉格朗日函数为</p><script type="math/tex; mode=display">L(\mathbf w,b,\xi,\alpha,\mu)=\frac{1}{2}\left\|\mathbf w\right\|^2+ C\sum_{i=1}^N\xi_i -\sum_{i=1}^N\alpha_{i}\left[y_{i}(\mathbf{w}\cdot \mathbf{x}_{i}+b)-1+\xi_i\right]-\sum_{i=1}^N \mu_i\xi_i</script><p>原始问题转换为</p><script type="math/tex; mode=display">\min_{\mathbf w,b,\xi}\max_{\alpha\ge 0,\mu\ge 0}L(\mathbf w,b,\xi,\alpha,\mu)</script><p>因此对偶问题为</p><script type="math/tex; mode=display">\max_{\alpha\ge 0,\mu\ge 0}\min_{\mathbf w,b,\xi}L(\mathbf w,b,\xi,\alpha,\mu)</script><p>先求 $\displaystyle\min_{\mathbf w,b,\xi}L(\mathbf w,b,\xi,\alpha,\mu)$，对三个变量 $\mathbf w,b,\xi$ 分别求偏导并令其等于 $0$</p><script type="math/tex; mode=display">\triangledown_{\mathbf w}L(\mathbf w,b,\xi,\alpha,\mu)=\mathbf w-\sum_{i=1}^N \alpha_{i}y_i\mathbf{x}_{i}=0</script><script type="math/tex; mode=display">\triangledown_{b}L(\mathbf w,b,\xi,\alpha,\mu)=-\sum_{i=1}^N \alpha_{i}y_i=0</script><script type="math/tex; mode=display">\triangledown_{\xi_i}L(\mathbf w,b,\xi,\alpha,\mu)=C-\alpha_i-\mu_i=0</script><p>将结果带入 $L$ 得</p><script type="math/tex; mode=display">\begin{aligned}    L(\alpha,\mu)&=\frac{1}{2}(\sum_{i=1}^N \alpha_{i}y_i\mathbf{x}_{i})^2-\sum_{i=1}^N\alpha_{i}\left[y_{i}(\sum_{j=1}^N \alpha_{j}y_j\mathbf{x}_{j}\cdot \mathbf{x}_{i}+b)-1\right]+\sum_{i=1}^N(C-\alpha_i-\mu_i)\xi_i\\    &=-\frac{1}{2}(\sum_{i=1}^N \alpha_{i}y_i\mathbf{x}_{i})\cdot(\sum_{j=1}^N \alpha_{j}y_j\mathbf{x}_{j})+\sum_{j=1}^N \alpha_i\end{aligned}</script><p>再求 $\displaystyle\max_{\alpha\ge 0,\mu\ge 0}L(\alpha,\mu)$，优化对偶问题为</p><script type="math/tex; mode=display">\begin{aligned}    \max_{\alpha,\mu} &-\frac{1}{2}(\sum_{i=1}^N \alpha_{i}y_i\mathbf{x}_{i})\cdot(\sum_{j=1}^N \alpha_{j}y_j\mathbf{x}_{j})+\sum_{j=1}^N \alpha_i \\    \displaystyle s.t \quad  &\sum_{i=1}^N \alpha_{i}y_i=0 \\    &C-\alpha_i-\mu_i=0\\    &\alpha_i\ge 0\\    &\mu_i\ge 0,\qquad i=1,2,\cdots,N \\\end{aligned}</script><p>将目标函数极大转为极小，同时将 $\mu_i$ 的关系式带入消去 $\mu_i$，得到等价优化问题</p><script type="math/tex; mode=display">\begin{aligned}    \min_{\alpha}\quad &\frac{1}{2}(\sum_{i=1}^N \alpha_{i}y_i\mathbf{x}_{i})\cdot(\sum_{j=1}^N \alpha_{j}y_j\mathbf{x}_{j})-\sum_{j=1}^N \alpha_i \\    \displaystyle s.t \quad  &\sum_{i=1}^N \alpha_{i}y_i=0 \\    &0\le\alpha_i\le C,\qquad i=1,2,\cdots,N \\\end{aligned}</script><p>假设求得的最优解为 $\mathbf w^<em>,b^</em>,\xi^<em>,\alpha^</em>,\mu^*$</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><blockquote><p><a href="https://holypython.com/svm/support-vector-machine-history/">1. Support Vector Machine History</a><br><a href="https://www.zhihu.com/question/64044033">2. 构造拉格朗日函数有何意义？-zhihu</a><br><a href="https://www.zhihu.com/question/38586401">3. 如何理解拉格朗日乘子法？-zhihu</a><br><a href="https://en.wikipedia.org/wiki/Lagrange_multiplier">4. Lagrange multiplier - Wikipedia</a><br><a href="https://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions">5. Karush–Kuhn–Tucker conditions - Wikipedia</a><br><a href="https://www.zhihu.com/question/26658861">6. 为什么我们要考虑线性规划的对偶问题？-zhihu</a><br><a href="https://www.zhihu.com/question/58584814">7. 如何通俗地讲解对偶问题，尤其是拉格朗日对偶 lagrangian duality？-zhihu</a></p><p><a href="https://en.wikipedia.org/wiki/Logistic_function">8. Logistic function - Wikipedia</a><br><a href="https://www.cnblogs.com/pinard/p/6029432.html">9. 逻辑回归原理小结 - 刘建平</a></p><div id="refer-anchor-1"></div></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;h1 id=&quot;支持向量机&quot;&gt;&lt;a href=&quot;#支持向量机&quot; class=&quot;headerlink&quot; title=&quot;支持向量机&quot;&gt;&lt;/a&gt;支持向量机&lt;/h1&gt;&lt;h2 id=&quot;1-历史背景&quot;&gt;&lt;a href=&quot;#1-历史背景&quot; cla</summary>
      
    
    
    
    <category term="Machine learning" scheme="http://example.com/categories/Machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>6. Logistic Regression</title>
    <link href="http://example.com/2022/02/20/MachineLearning/6.LogisticRegression/"/>
    <id>http://example.com/2022/02/20/MachineLearning/6.LogisticRegression/</id>
    <published>2022-02-19T16:00:00.000Z</published>
    <updated>2022-06-16T09:26:53.187Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><h1 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h1><h2 id="1-历史背景"><a href="#1-历史背景" class="headerlink" title="1. 历史背景"></a>1. 历史背景</h2><p>1830 年代和 1840 年代，在 Adolphe Quetelet 的指导下，Pierre François Verhulst 将逻辑函数（logistic function）作为人口增长模型并命名为“逻辑函数”。Verhulst 在 1830 年代中期首先设计了这个函数，但没有具体说明他如何将曲线拟合到数据中。随后，在 1838 年发表了一篇简短的笔记。最后在 1844 年进行了扩展分析并命名了这个函数（1845 年出版），Verhulst 通过使曲线通过三个观察点来确定模型的三个参数，这产生了较差的预测。逻辑函数最早应用就是作为人口增长的通用模型，满足微分方程式 $\displaystyle {\frac {dP}{dt}}=rP\left(1-{\frac {P}{K}}\right)$，其中，$P$ 代表种群大小，$t$ 代表时间，常数 $r$ 定义为增长率，$K$ 是承载容量，微分方程结果为 $\displaystyle P(t)={\frac {K}{1+\left({\frac {K-P_{0}}{P_{0}}}\right)e^{-rt}}}$，$\displaystyle \frac {K-P_{0}}{P_{0}}$ 是常数可以移动到指数上，相当于对 $t$ 进行平移，就可以得到逻辑函数标准形式。</p><p>1883 年，逻辑函数在化学领域中独立开发出来作为自催化模型（Wilhelm Ostwald）。自催化反应是指反应中的一种产物本身就是同一反应的催化剂，而其中一种反应物的供应是固定的。出于与人口增长相同的原因，这自然会产生逻辑方程：反应是自我强化的，但受到限制。</p><p>1920 年，逻辑函数被 Raymond Pearl 和 Lowell Reed 再次独立地发现为人口增长的模型，这导致它在现代统计学中的应用。Pearl 和 Reed 将该模型首次应用于美国人口，并通过三个点对曲线进行了初步拟合，与 Verhulst 一样，这再次产生了糟糕的结果。他们最初不知道 Verhulst 的工作，大概是从 L. Gustave du Pasquier 那里了解到的，但他们没有给他多少信任，也没有采用他的术语。 在 1925 年，Verhulst 的优先权得到承认，Udny Yule 重新使用了“logistic”一词，并一直沿用至今。</p><p>1930 年代，概率模型（probit model）由 Chester Ittner Bliss 开发和系统化，并且 John Gaddum 通过 Ronald A. Fisher 的最大似然估计拟合该模型。probit 模型主要用于生物测定，早在 1860 年的工作就已经开始了。probit 模型影响了 logit 模型的后续发展。</p><p>1943 年，逻辑模型（logistic model）可能首先被 Edwin Bidwell Wilson 和他的学生 Jane Worcester 用作生物测定中概率模型的替代方案。然而，logistic 模型作为 probit 模型的一般替代方案的发展主要归功于 Joseph Berkson 数十年来的工作，从 1944年开始，他通过与“probit”类比创造了“logit”。logit 模型最初被认为不如 probit 模型，但“逐渐达到了与 probit 平等的地位”，特别是在 1960 年至 1970 年间。到 1970 年，统计期刊中使用logit 模型与 probit 模型数量相当，然后前者超越了后者。这种相对流行是由于在生物测定之外采用了 logit，而不是在生物测定中取代 probit，以及它在实践中的非正式使用；logit 的受欢迎程度归功于 logit 模型的计算简单性、数学特性和通用性，允许其在各种领域中使用。</p><p>1966年，多项式logit模型由 David Cox 引入，大大增加了logit模型的应用范围和普及度。1973 年，Daniel McFadden 将多项式 logit 与离散选择理论，特别是 Luce 的选择公理联系起来，表明多项式 logit 遵循 independence of irrelevant alternatives (IIA) 假设并将备选方案的几率解释为相对偏好，这给出了一个逻辑回归的理论基础。</p><h2 id="2-算法模型"><a href="#2-算法模型" class="headerlink" title="2. 算法模型"></a>2. 算法模型</h2><p>逻辑回归实际上是分类模型，之所以名字中带有回归，我想是因为它是对概率值进行回归的。逻辑回归是对事件发生的概率进行建模，根据分类事件的数量分为二元逻辑回归和多元逻辑回归，</p><h3 id="2-1-逻辑函数"><a href="#2-1-逻辑函数" class="headerlink" title="2.1 逻辑函数"></a>2.1 逻辑函数</h3><p>阐述逻辑回归模型之前，先介绍一下逻辑函数（logistic function）。</p><p>逻辑函数的公式如下</p><script type="math/tex; mode=display">\displaystyle f(x)={\frac {L}{1+e^{-k(x-x_{0})}}}</script><p>式中，$x_0$ 是曲线的中点坐标，$L$ 是曲线的最大值，$k$ 是逻辑增长率或曲线的陡度。逻辑函数最早用于人口增长预测，$f(x)$ 是人口数量，$x$ 代表时间。</p><p>当 $\displaystyle L=1,k=1,x_{0}=0$ 时就得到了 sigmoid 函数</p><script type="math/tex; mode=display">\displaystyle f(x)={\frac {1}{1+e^{-x}}}</script><p>与正态分布函数进行类比，逻辑函数改为</p><script type="math/tex; mode=display">\displaystyle f(x)={\frac {1}{1+e^{-(x-\mu )/s}}}</script><p>该函数图形如图所示，是一条 S 形曲线（sigmoid curve），可以发现形状与正态分布函数相似。该函数曲线以点 $\displaystyle(\mu,\frac{1}{2})$ 为中心对称，满足 </p><script type="math/tex; mode=display">f(x)=1-f(-x)</script><p>逻辑函数还有一个非常好的性质，就是其导数易求</p><script type="math/tex; mode=display">f'(x)=f(x)(1-f(x))</script><p>逻辑函数的导函数满足概率密度公式的要求，因此逻辑函数就是一种概率分布函数，至于为什么在分类问题中比正态分布好用还需考证。</p><p>logistic model 与 probit model 的区别就是在于使用逻辑函数取代了正态分布函数。</p><h3 id="2-2-二元逻辑回归"><a href="#2-2-二元逻辑回归" class="headerlink" title="2.2 二元逻辑回归"></a>2.2 二元逻辑回归</h3><p>假设有数据集</p><script type="math/tex; mode=display">D=\{(x_1,y_1),(x_2,y_2),\dots,(x_k,y_k),\dots,(x_N,y_N)\}</script><p>二元逻辑回归就是在分类数是 2 的情况下，也就是二项分布的情况下的逻辑回归。回忆一下伯努利分布，其中的 $y=1$ 事件对应的概率分布就是由逻辑函数 $f(x)$ 给出，由于与 $x$ 有关，因此很明显是条件概率，如下所示</p><script type="math/tex; mode=display">p(y=1|\, x)={\frac {1}{1+e^{-(x-\mu )/s}}}</script><p>由于是二项分布，因此</p><script type="math/tex; mode=display">p(y=0|\, x)=1 - p(y=1|\, x)</script><p>我们用 $p(x)$ 对 $p(y=1|\, x)$ 进行简写，同时把上式标准化</p><script type="math/tex; mode=display">\displaystyle p(x)={\frac {1}{1+e^{-(\beta _{0}+\beta _{1}x)}}}</script><p>其中 $\beta_0=-\mu/s$ 称为截距，$\beta_1=1/s$。那么对特征 $x_k$ 的类别 $y_k$ 概率拟合就是</p><script type="math/tex; mode=display">p_k=p(x_k)</script><p>有了概率分布之后，我们只需要用最大似然估计确定参数的值即可。如前所说，二元逻辑回归就是在伯努利分布的情况下，那么伯努利分布的似然函数就是</p><script type="math/tex; mode=display">\begin{aligned}    \displaystyle L&= \prod _{k:y_{k}=1}p_{k}\,\prod _{k:y_{k}=0}(1-p_{k})\\    &= \prod^N_{k=1}p_{k}^{y_k}(1-p_{k})^{1-y_k}\\\end{aligned}</script><p>对 $L$ 取对数，得到对数似然函数</p><script type="math/tex; mode=display">\begin{aligned}    \displaystyle \ell&=\sum _{k:y_{k}=1}\ln(p_{k})+\sum _{k:y_{k}=0}\ln(1-p_{k})\\    &= \sum _{k=1}^{N}\left(\,y_{k}\ln(p_{k})+(1-y_{k})\ln(1-p_{k})\right)\\\end{aligned}</script><p>上式是有关 $\beta_0,\beta_1$ 的函数，为了使对数似然函数最大，分别对 $\beta_0,\beta_1$ 求偏导数</p><script type="math/tex; mode=display">\displaystyle {\frac {\partial \ell }{\partial \beta _{0}}}=\sum _{k=1}^{K}(y_{k}-p_{k})</script><script type="math/tex; mode=display">\displaystyle {\frac {\partial \ell }{\partial \beta _{1}}}=\sum _{k=1}^{K}(y_{k}-p_{k})x_{k}</script><p>结果和线性回归太相似了，$p_k$ 如果是线性函数，那么上式就是线性回归。事实上，$p(x)$ 的作用就是将线性函数 $\beta _{0}+\beta _{1}x$ 的结果映射到 $[0,1]$ 概率区间。如果让上式分别等于 0，则得到似然方程。</p><p>不过，尽管结果相似，但上式是非线性的，因此无法像线性回归一样，求出似然方程组的解析解。因此，需要用数值方法，如牛顿迭代法和梯度下降法等等。牛顿迭代法是求解的似然方程组，梯度下降法则是直接求似然函数的极值，区别在于牛顿迭代法需要二次导数。下面给出梯度下降法的计算公式，其实很简单，沿与梯度相反的方向移动即可，导数已经给出，梯度则为</p><script type="math/tex; mode=display">\bigtriangledown p(\beta_0,\beta_1)=(\frac {\partial \ell }{\partial \beta _{0}},\frac {\partial \ell }{\partial \beta _{1}})</script><p>假设第 $t$ 次的迭代结果为 $\beta^t_0,\beta^t_1$，则</p><script type="math/tex; mode=display">\beta^{t+1}_0=\beta^t_0-\alpha\sum _{k=1}^{K}(y_{k}-{\frac {1}{1+e^{-(\beta^t_0+\beta^t_1x)}}})</script><script type="math/tex; mode=display">\beta^{t+1}_1=\beta^t_1-\alpha\sum _{k=1}^{K}(y_{k}-{\frac {1}{1+e^{-(\beta^t_0+\beta^t_1x)}}})x_{k}</script><p>上面求解的是简单的情况，只有一个特征。进一步地，将上面结果推广到具有多个特征的情况。</p><p>用矩阵形式表述如下：$X$ 是样本特征矩阵，大小为 $m\times n$，$n$ 是特征维度加1，$m$ 是样本数量，第 $i$ 行形如 $[1, x_1^{(i)}, x_2^{(i)}, x_3^{(i)},\dots, , x_{n-1}^{(i)}]$；$\boldsymbol w$ 是 $n\times1$ 系数向量，形如 $[\beta_1,\beta_2,\dots,\beta_n]^T$；$\boldsymbol y$ 是 $m\times1$ 列向量，形如 $[y_1,y_2,\dots,y_m]^T$，每个元素取值 $0$ 或 $1$；$\boldsymbol 1$ 为值均为 $1$ 的向量。逻辑函数为</p><script type="math/tex; mode=display">p(X\boldsymbol w)={\frac {1}{1+e^{-X\boldsymbol w}}}</script><p>对数似然函数的矩阵形式为</p><script type="math/tex; mode=display">\ell(\boldsymbol w)=\boldsymbol y^T\ln p(X\boldsymbol w)+(\boldsymbol 1-\boldsymbol y^T)\ln(\boldsymbol 1^T-p(X\boldsymbol w))</script><p>根据逐元素函数法则，逻辑函数的微分</p><script type="math/tex; mode=display">\begin{aligned}    \mathrm{d}p(X\boldsymbol w)&=p'(X\boldsymbol w)\odot\mathrm{d}X\boldsymbol w \\    &= p(X\boldsymbol w)\odot(\boldsymbol 1^T-p(X\boldsymbol w))\odot ((\mathrm{d}X)\boldsymbol w+X\mathrm{d}\boldsymbol w) \\    &=p(X\boldsymbol w)\odot(\boldsymbol 1^T-p(X\boldsymbol w))\odot X\mathrm{d}\boldsymbol w\end{aligned}</script><p>$\ln$ 函数的微分</p><script type="math/tex; mode=display">\mathrm{d}\ln Y=Y^{-1}\odot\mathrm{d}Y</script><p>因此可以得到</p><script type="math/tex; mode=display">\begin{aligned}\mathrm{d}\ell(\boldsymbol w)&=\boldsymbol y^T(p(X\boldsymbol w))^{-1}\odot p(X\boldsymbol w)\odot(\boldsymbol 1^T-p(X\boldsymbol w))\odot X\mathrm{d}\boldsymbol w \\&+(\boldsymbol 1-\boldsymbol y^T)(\boldsymbol 1^T-p(X\boldsymbol w))^{-1}\odot -p(X\boldsymbol w)\odot(\boldsymbol 1^T-p(X\boldsymbol w))\odot X\mathrm{d}\boldsymbol w \\&=\boldsymbol y^T(\boldsymbol 1^T-p(X\boldsymbol w))\odot X\mathrm{d}\boldsymbol w - (\boldsymbol 1-\boldsymbol y^T)p(X\boldsymbol w)\odot X\mathrm{d}\boldsymbol w \\\end{aligned}</script><p>将上式套上迹</p><script type="math/tex; mode=display">\begin{aligned}\mathrm{d}\ell(\boldsymbol w)&=\mathrm{tr}(\boldsymbol y^T(\boldsymbol 1^T-p(X\boldsymbol w))\odot X\mathrm{d}\boldsymbol w- (\boldsymbol 1-\boldsymbol y^T)p(X\boldsymbol w)\odot X\mathrm{d}\boldsymbol w)\\&=\mathrm{tr}([\boldsymbol y\odot(\boldsymbol 1^T-p(X\boldsymbol w))]^TX\mathrm{d}\boldsymbol w - [(\boldsymbol 1-\boldsymbol y^T)^T\odot p(X\boldsymbol w)]^T X\mathrm{d}\boldsymbol w)\\&=\mathrm{tr}([\boldsymbol y-\boldsymbol y\odot p(X\boldsymbol w)]^TX\mathrm{d}\boldsymbol w - [p(X\boldsymbol w)-\boldsymbol y^T\odot p(X\boldsymbol w)]^T X\mathrm{d}\boldsymbol w)\\&=\mathrm{tr}(\boldsymbol y ^ TX\mathrm{d}\boldsymbol w - p(X\boldsymbol w)^T X\mathrm{d}\boldsymbol w)\\&=\mathrm{tr}([X^T(\boldsymbol y- p(X\boldsymbol w) )]^T\mathrm{d}\boldsymbol w)\\\end{aligned}</script><p>根据微分与导数的关系</p><script type="math/tex; mode=display">\mathrm{d}f=\mathrm{tr}(\frac {\partial f }{\partial X}^T \mathrm{d}X)</script><p>就可以得到</p><script type="math/tex; mode=display">\frac {\partial f }{\partial X}=X^T(\boldsymbol y- p(X\boldsymbol w) )</script><p>迭代公式</p><script type="math/tex; mode=display">\boldsymbol w=\boldsymbol w-\alpha X^T(\boldsymbol y- p(X\boldsymbol w) )</script><h3 id="2-3-多元逻辑回归"><a href="#2-3-多元逻辑回归" class="headerlink" title="2.3 多元逻辑回归"></a>2.3 多元逻辑回归</h3><p>一个事件的几率（odds）是指该事件的发生的概率与不发生的概率的比值。如果一个事件发生的概率 $p$，则不发生的概率为 $1-p$，那么该事件的几率为 $\displaystyle\frac{p}{1-p}$，该事件的对数几率或 logit 函数是</p><script type="math/tex; mode=display">\mathrm{logit}(p)=\ln \frac{p}{1-p}</script><p>对于逻辑回归，一定满足</p><script type="math/tex; mode=display">\ln \frac{p}{1-p}=\boldsymbol w\cdot\boldsymbol x</script><p>假设多元逻辑回归事件的类别分别为 $1,2,\dots,K$。多元逻辑回归相较于二元逻辑回归，概率计算公式不变</p><script type="math/tex; mode=display">\displaystyle p(\boldsymbol x)={\frac {1}{1+e^{-\boldsymbol w\cdot\boldsymbol x}}}</script><p>区别在于对于同一个实例，它所有类别的概率和为 1。在二元逻辑回归中，$y=0$ 时的概率就是 $1-p$，因此只需要一组参数即可，而在多元逻辑回归中， $K$ 个类别分别对应一组参数</p><script type="math/tex; mode=display">\ln \frac{p(y=1|\boldsymbol x)}{1-p(y=0|\boldsymbol x)}=\boldsymbol w_1\cdot\boldsymbol x</script><script type="math/tex; mode=display">\ln \frac{p(y=2|\boldsymbol x)}{1-p(y=0|\boldsymbol x)}=\boldsymbol w_2\cdot\boldsymbol x</script><script type="math/tex; mode=display">\cdots</script><p>同时满足</p><script type="math/tex; mode=display">\sum_{i=1}^Kp(y=i|\boldsymbol x)=1</script><p>最终解得</p><script type="math/tex; mode=display">p(y=k|\boldsymbol x)=\frac{e^{\boldsymbol w_k\cdot\boldsymbol x}}{\displaystyle 1+\sum_{i=1}^{K-1}e^{\boldsymbol w_i\cdot\boldsymbol x}}</script><script type="math/tex; mode=display">p(y=K|\boldsymbol x)=\frac{1}{\displaystyle 1+\sum_{i=1}^{K-1}e^{\boldsymbol w_i\cdot\boldsymbol x}}</script><p>实际上就是 softmax 函数的一种特例，输出的结果为 $k-1$ 个，因为概率和为 1，自然可以求出最后剩下的一个概率值。其实也可以输出 $k$ 个结果，概率的计算公式为</p><script type="math/tex; mode=display">p(y=k|\boldsymbol x)=\frac{e^{\boldsymbol w_k\cdot\boldsymbol x}}{\displaystyle \sum_{i=1}^Ke^{\boldsymbol w_i\cdot\boldsymbol x}}</script><p>我们采用后一种方式，似然函数为</p><script type="math/tex; mode=display">L=\prod_{i=0}^mp_1(\boldsymbol{x_i})^{y_i^1}p_2(\boldsymbol{x_i})^{y_i^2}\dots p_k(\boldsymbol{x_i})^{y_i^K}</script><p>对于一组输入 $\boldsymbol{x_i}$，$(y_i^1,y_i^2,\dots,y_i^K)$ 中只有一个值为 $1$，其他为 $0$。对数似然函数即为</p><script type="math/tex; mode=display">\ell=\sum_{i}\sum_ky_i^k\log p_k(\boldsymbol{x_i})</script><p>将对数似然函数写成矩阵形式，对于每一组实例</p><script type="math/tex; mode=display">\ell=\boldsymbol{y}^T\log \mathrm{softmax}(W\boldsymbol{x})</script><p>对于所有实例</p><script type="math/tex; mode=display">\ell=\mathrm{tr}(Y^T\log \mathrm{softmax}(WX))</script><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><blockquote><p><a href="https://en.wikipedia.org/wiki/Logistic_regression">1. Logistic regression - Wikipedia</a><br><a href="https://papers.tinbergen.nl/02119.pdf">2. Cramer, J. S. (2002). The origins of logistic regression</a><br><a href="https://synapse.koreamed.org/upload/synapsedata/pdfdata/0006jkan/jkan-43-154.pdf">3. An Introduction to Logistic Regression: From Basic Concepts to Interpretation with Particular Attention to Nursing Domain</a><br><a href="https://ftp.idu.ac.id/wp-content/uploads/ebook/ip/REGRESI%20LOGISTIK/Practical%20Guide%20to%20Logistic%20Regression%20(%20PDFDrive%20">4. Practical Guide to Logistic Regression</a>.pdf)<br><a href="https://en.wikipedia.org/wiki/Logistic_function">5. Logistic function - Wikipedia</a><br><a href="https://www.cnblogs.com/pinard/p/6029432.html">6. 逻辑回归原理小结 - 刘建平</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;h1 id=&quot;逻辑回归&quot;&gt;&lt;a href=&quot;#逻辑回归&quot; class=&quot;headerlink&quot; title=&quot;逻辑回归&quot;&gt;&lt;/a&gt;逻辑回归&lt;/h1&gt;&lt;h2 id=&quot;1-历史背景&quot;&gt;&lt;a href=&quot;#1-历史背景&quot; class=&quot;</summary>
      
    
    
    
    <category term="Machine learning" scheme="http://example.com/categories/Machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2022/02/07/ProbabilityStatistics/1.random%20events%20and%20their%20probabilities/"/>
    <id>http://example.com/2022/02/07/ProbabilityStatistics/1.random%20events%20and%20their%20probabilities/</id>
    <published>2022-02-07T01:35:19.954Z</published>
    <updated>2022-03-28T00:31:30.411Z</updated>
    
    <content type="html"><![CDATA[<h1 id="随机事件及其概率"><a href="#随机事件及其概率" class="headerlink" title="随机事件及其概率"></a>随机事件及其概率</h1><h2 id="1-随机事件及其运算"><a href="#1-随机事件及其运算" class="headerlink" title="1. 随机事件及其运算"></a>1. 随机事件及其运算</h2><ul><li><strong>随机现象</strong>：在一定条件下，并不总是出现相同结果的现象。</li><li><strong>随机试验</strong>：可重复的随机现象。</li><li><strong>基本结果 $\omega$</strong>：随机现象的最简单的结果，它将是统计中抽样的基本单元，故又称样本点。</li><li><strong>基本空间 $\Omega$</strong>：随机现象所有基本结果的全体。</li><li><strong>随机事件</strong>：随机现象某些基本结果组成的集合，简称“事件”。</li></ul><blockquote><p>抛硬币的结果就是一个随机现象，具有两个基本结果，正面和反面。随机现象所有基本结果的全体就称为这个随机现象的基本空间。在统计学中，基本结果 $\omega$ 是抽样的基本单元，故基本结果又称 <strong>样本点</strong>，基本空间又称 <strong>样本空间</strong> ，抛硬币的基本空间：</p><script type="math/tex; mode=display">\Omega_1=\{\omega_0,\omega_1\}=\{正面，反面\}</script><p>掷一颗骰子，“出现6点”、“出现偶数点”、“出现点数不超过2”都是<strong>随机事件</strong>，可以用其基本空间 $\Omega =\{1,2,3,4,5,6\}$ 的某个子集表示，例如“出现偶数点”可以表示为：</p><script type="math/tex; mode=display">A=\{2,4,6\}</script></blockquote><ul><li><strong>必然事件</strong> </li><li><strong>不可能事件</strong> </li><li><strong>事件的关系</strong><ul><li>事件的包含</li><li>事件的相等</li><li>事件的互不相容</li></ul></li><li><strong>事件的运算</strong> ：事件的基本运算对立、并、交和差，与集合的四种运算余、并、交和差是完全一样的。<ul><li>对立事件：设 $A$ 为一个试验里的事件，则由不在 $A$ 中的一切基本结果组成的事件称为 $A$ 的对立事件，记为 $\overline{A}$。必然事件和不可能事件互为对立事件。</li><li>事件 $A$ 和 $B$ 的并：由事件 $A$ 和 $B$中所有的基本结果组成的一个新事件，记作$A\bigcup B$</li><li>事件 $A$ 和 $B$ 的交：由事件 $A$ 和 $B$中公共的的基本结果组成的一个新事件，记作$A\bigcap B$ 或者 $AB$</li><li>事件 $A$ 对 $B$ 的差：由在事件 $A$ 而不在事件 $B$ 中的基本结果组成的一个新事件，记作$A-B$。$A-B=A-AB=A\overline{B}$</li></ul></li></ul><h2 id="2-事件的概率"><a href="#2-事件的概率" class="headerlink" title="2. 事件的概率"></a>2. 事件的概率</h2><h3 id="2-1-事件的概率"><a href="#2-1-事件的概率" class="headerlink" title="2.1 事件的概率"></a>2.1 事件的概率</h3><p>随机事件的发生是带有偶然性的。但随机事件发生的可能性还是有大小之别的，是可以设法度量的。例如抛硬币正反面的可能性都是$1/2$，用一个 $0$ 到 $1$ 的数来表示一个随机事件发生的可能性大小。概率论中，这种比率就是概率的原形。</p><p><strong>定义1</strong> 在一个随机现象中，用来表示任一个随机事件 $A$ 发生可能性大小的实数（即比率）成为该事件的概率，记为 $P(A)$，并规定</p><ol><li>非负性公理：对任一事件 $A$，必有 $P(A)\ge 0$</li><li>正则性公理：必然事件的概率 $P(\Omega)=1$</li><li>可加性公理：若 $A_1$ 与 $A_2$ 是两个互不相容事件（即$A_1A_2=\emptyset$），则有 $P(A_1\bigcup A_2)=P(A_1)+P(A_2)$</li></ol><p>这就是概率的公理化定义，它虽然刻划了概率的本质，但没有告诉人们如何去确定概率。历史上概率的古典定义、概率的统计定义和概率的主观定义都有各自确定概率的方法，在有了公理化定义之后，把它们看作确定概率的三种方法是很恰当的。</p><h3 id="2-2-排列与组合"><a href="#2-2-排列与组合" class="headerlink" title="2.2 排列与组合"></a>2.2 排列与组合</h3><p>排列和组合是两类计数公式，基于如下两条计数原理：</p><ul><li><strong>乘法原理</strong></li><li><strong>加法原理</strong></li></ul><p>乘法原理，某件事需要 $k$ 个步骤，则每个步骤能选择的方法数量相乘就是总的可选择方法。加法原理，就是某件事由 $k$ 类方法可以完成，那么总的可选择方法就是这几类方法相加。</p><ul><li><strong>排列</strong>　从 $n$ 个不同元素中任取 $r(r\le n)$ 个元素排成一列称为一个排列，按乘法原理，此种排列共有 $n\times (n-1)\times \cdots \times(n-r+1)$ 个，记为 $P^r_n$。若 $r=n$，称为全排列，全排列数共有 $n!$ 个，记为 $P_n$。</li><li><strong>重复排列</strong>　从 $n$ 个不同元素中每次取出一个，放回后再取下一个，如此连续取 $r$ 次所得的排列称为重复排列，此种重复排列数共有 $n^r$ 个。这里 $r$ 允许大于 $n$。</li><li><strong>组合</strong>　从 $n$ 个不同元素中任取 $r(r\le n)$ 个元素并成一组（不考虑其间顺序）称为一个组合，按乘法原理，此种组合总数为<script type="math/tex; mode=display">\dbinom{n}{r}=\frac{P_n^r}{r!}=\frac{n\times (n-1)\times \cdots \times(n-r+1)}{r!}=\frac{n!}{r!(n-r)!}</script>并规定 $0!=1$ 和 $\dbinom{n}{r}=1$，同时 $\dbinom{n}{r}=1$ 还是二项式展开式的系数，即<script type="math/tex; mode=display">(a+b)^n=\sum^n_{r=0}\dbinom{n}{r}a^rb^{n-r}</script>若在上式中令 $a=b=1$ ，可得一重要组合恒等式：<script type="math/tex; mode=display">\dbinom{n}{0}+\dbinom{n}{1}+\cdots+\dbinom{n}{n}=2^n</script></li><li><strong>重复组合</strong>　从 $n$ 个不同元素每次取出一个，放回后再取下一个，如此连续取 $r$ 次所得的组合称为重复组合。重复组合总数为 $\dbinom{n+r-1}{r}$。</li></ul><h3 id="2-3-古典方法"><a href="#2-3-古典方法" class="headerlink" title="2.3 古典方法"></a>2.3 古典方法</h3><p>古典方法是在经验事实的基础上对被考察事件发生可能性进行符合逻辑分析后得出该事件的概率。这种方法简单、直观、不需要做试验，但只能在一类特定的随机现象中使用。基本思想如下：</p><ul><li>所涉及的随机现象只有有限个基本结果</li><li>每个基本结果出现的可能性是相同的（等可能性）</li><li>假如被考察的事件 $A$ 含有 $k$ 个基本结果，则事件 $A$ 的概率就是<script type="math/tex; mode=display">P(A)=\frac{k}{n}=\frac{A中含基本结果的个数}{\Omega中基本结果总数}</script></li></ul><p>下面以扑克游戏为例，计算每种牌型的概率。一副标准的扑克牌由52张组成，有两种颜色、四种花式和13种牌型，假设每张牌被抽出的可能性是相同的。下面来研究一些事件的概率。</p><ol><li>事件 $A=$ “抽五张牌，恰好是同花顺”。在抽五张牌的试验中，共有 $\dbinom{52}{5}$ 个等可能基本结果，事件 $A$ 包含的基本结果总数为 $10\times 4$。故事件 $A=$ 的概率为<script type="math/tex; mode=display">P(A)=\frac{10\times 4}{\dbinom{52}{5}}=\frac{40}{2598960}=0.00001539</script> 发生概率10万分之1.5</li><li>事件 $B=$ “抽五张牌，四张牌型一样”。事件 $B$ 包含的基本结果总数为 $13\times 48$。故事件 $B=$ 的概率为<script type="math/tex; mode=display">P(B)=\frac{624}{\dbinom{52}{5}}=\frac{624}{2598960}=0.00024</script> 发生的概率是万分之二，平均4167次才会发生一次。</li><li>事件 $C=$ “抽五张牌，恰好是葫芦”。事件 $C$ 包含的基本结果总数为 $13\times \dbinom{4}{3}\times 12 \times\dbinom{4}{2}=3744$<script type="math/tex; mode=display">P(C)=\frac{3744}{\dbinom{52}{5}}=\frac{3744}{2598960}=0.00144=\frac{1}{694}</script></li><li>事件 $D=$ “抽五张牌，恰好是同花，但不是顺子”。事件 $D$ 包含的基本结果总数为 $\dbinom{13}{5}\times 4 - 40=5108$<script type="math/tex; mode=display">P(D)=\frac{5108}{\dbinom{52}{5}}=\frac{5108}{2598960}=0.0019654=\frac{1}{508}</script></li><li>事件 $E=$ “抽五张牌，恰好是顺子，但不是同花”。一共有十种顺子，每种顺子按照花色的不同共有 $4^5-4$ 种结果。因此，事件 $E$ 包含的基本结果总数为 $10\times (4^5-4)=10200$<script type="math/tex; mode=display">P(E)=\frac{10200}{\dbinom{52}{5}}=\frac{10200}{2598960}=0.003924=\frac{1}{254}</script></li><li>事件 $F=$ “抽五张牌，恰好是三条，但不是葫芦”。事件 $F$ 包含的基本结果总数为 $13\times \dbinom{4}{3}\times \dbinom{48}{2} - 3744=54912$<script type="math/tex; mode=display">P(F)=\frac{54912}{\dbinom{52}{5}}=\frac{54912}{2598960}=0.021128=\frac{1}{47}</script></li><li>事件 $G=$ “抽五张牌，恰好是两对”。事件 $F$ 包含的基本结果总数为 $\dbinom{4}{2}\times \dbinom{4}{2}\times \dbinom{13}{2}\times \dbinom{11}{1}\times 4=123552$<script type="math/tex; mode=display">P(F)=\frac{54912}{\dbinom{52}{5}}=\frac{54912}{2598960}=0.04753=\frac{1}{21}</script></li><li>事件 $H=$ “抽五张牌，恰好有一对”。事件 $F$ 包含的基本结果总数为 $\dbinom{4}{2}\times \dbinom{13}{1}\times \dbinom{12}{3}\times 4^3=1098240$<script type="math/tex; mode=display">P(F)=\frac{1098240}{\dbinom{52}{5}}=\frac{1098240}{2598960}=0.42256=\frac{1}{2}</script></li></ol><h3 id="2-3-频率方法"><a href="#2-3-频率方法" class="headerlink" title="2.3 频率方法"></a>2.3 频率方法</h3><p>频率方法是在大量重复试验中用频率去获取概率近似值的一个方法。它是最常用，也是最基本获得概率的方法。基本思想如下：</p><ul><li>与考察事件 $A$ 有关的随机现象是允许进行大量重复试验的。</li><li>假如在 $N$ 次重复试验中，事件 $A$ 发生 $K_N$ 次，则事件 $A$ 发生的频率为<script type="math/tex; mode=display">P^*_N(A)=\frac{K_N}{N}=\frac{事件A发生的次数}{重复试验次数}</script></li><li>频率 $P^<em>_N(A)$ 依赖于重复次数 $N$。随着重复次数 $N$ 的增加，频率 $P^</em>_N(A)$ 会稳定在某一常数附近，这个频率的稳定值已与 $N$ 无关，就是事件 $A$ 发生的概率。在现实世界中，我们无法将一个试验无限次的重复下去，在重复次数 $N$ 较大时，频率 $P^*_N(A)$ 就很接近概率 $P(A)$ 。在统计学中把频率称为概率的估计值，实际频率当作概率近似值使用。</li></ul><h3 id="2-4-主观方法"><a href="#2-4-主观方法" class="headerlink" title="2.4 主观方法"></a>2.4 主观方法</h3><p>统计学中有一个贝叶斯学派，他们在研究随机现象之后认为，<strong>一个事件的概率是人们根据经验对该事件发生可能性所给出的个人信念</strong>。这样给出的概率就称为主观概率。</p><p>以经验为基础的主观概率和纯主观还是不同的。主观概率要求当事人对所考察的事件有较为透彻的了解和经验，并能对周围信息和历史信息进行仔细分析，在这个基础上确定的主观概率就能符合实际。</p><p>主观概率在遇到随机现象不能大量重复、无法用频率方法确定事件概率时就变得极为有用，因此在经济领域和决策分析中使用较为广泛。在某种意义上看，主观概率至少是频率方法和古典方法的一种补充，有了主观概率至少使人们在频率观点不适用时也能谈论概率，使用概率与统计方法。</p><h2 id="3-概率的性质"><a href="#3-概率的性质" class="headerlink" title="3. 概率的性质"></a>3. 概率的性质</h2><p>一些概率的常用性质</p><ul><li>定理1　$P(\overline{A})=1-P(A)$</li><li>定理2　$P(\phi)=0$</li><li>定理3　对 $n$ 个互不相容事件 $A_1,\cdots,A_n$，有<script type="math/tex; mode=display">P(\bigcap\limits^n_{i=1} A_i)=\sum^n_{i=1}P(A_i)</script></li><li>定理4　对任意两个事件 $A$ 和 $B$，若$A\supset B$，则<ul><li>$P(A-B)=P(A)-P(B)$</li><li>$P(A)\le P(B)$</li></ul></li><li>定理5　对任一事件 $A$，总有 $0\le P(A)\le 1$</li><li>定理6　对任意两个事件 $A$ 与 $B$，有<ul><li>$P(A\bigcup B)=P(A)+P(B)-P(AB)$</li><li>$P(A\bigcup B)\le P(A)+P(B)$</li></ul></li><li>定理7　对任意三个事件 $A,B,C$，有<ul><li>$P(A\bigcup B \bigcup C)=P(A)+P(B)+P(C)-P(AB)-P(AC)-P(BC)+P(ABC)$</li><li>$P(A\bigcup B \bigcup C)\le P(A)+P(B)+P(C)$</li></ul></li></ul><h2 id="4-独立性"><a href="#4-独立性" class="headerlink" title="4. 独立性"></a>4. 独立性</h2><h3 id="4-1-事件的独立性"><a href="#4-1-事件的独立性" class="headerlink" title="4.1 事件的独立性"></a>4.1 事件的独立性</h3><ul><li>定义1　对任意两个事件 $A$ 和 $B$，若有 $P(AB)=P(A)P(B)$，则称事件 $A$ 与 $B$ 相互独立，简称 $A$ 与 $B$ 独立。否则称事件 $A$ 与 $B$ 不独立。</li></ul><p>两个事件的独立性是指一个事件的发生不影响另一个事件的发生。在概率角度讲，两个事件之间的独立性与这两个事件同时发生的概率有密切关系，即两独立事件同时发生的概率等于它们各自概率的乘积。</p><p>投掷两个骰子，两个骰子的点数是互不影响的，显然任何两个分别与两个骰子相关的事件都是独立的，例如事件 $A=$ “第一颗骰子出现1点”、事件 $B=$ “第二颗骰子出现偶数点”。</p><p>但是，两事件是否具有独立性并不总是显然的。例如同样两个事件 $A=$ “家中男女孩都有”、事件 $B=$ “家里至多一个女孩”。在家中有三个小孩的情况下，这两个事件是独立的。但是，家中有两个或四个小孩时，就不再独立了。</p><ul><li>定理1　若事件 $A$ 和 $B$独立，则事件 $A$ 和 $\overline{B}$ 独立；$\overline A$ 和 $B$ 独立；$\overline A$ 和 $\overline{B}$ 独立。</li></ul><p>证：由事件的运算性质知</p><script type="math/tex; mode=display">A\overline{B}=A(1-B)=A-AB</script><p>其中 $A\supset AB$，再由 $A$ 和 $B$ 的独立性</p><script type="math/tex; mode=display">\begin{aligned}    P(A\overline{B})&= P(A)-P(AB)\\    &= P(A)-P(A)P(B)\\    &= P(A)[1-P(B)]\\    &= P(A)P(\overline{B})\\\end{aligned}</script><h3 id="4-1-试验的独立性"><a href="#4-1-试验的独立性" class="headerlink" title="4.1 试验的独立性"></a>4.1 试验的独立性</h3><p>利用事件的独立性可以定义两个或更多个试验的独立性。假设有两个试验 $E_1$ 和 $E_2$，假如试验 $E_1$ 的任一个结果与试验 $E_2$ 的任一个结果都是相互独立事件，则称这两个试验相互独立。类似的如果 $n$ 个试验相互间的任一结果之间都是相互独立的事件，则这些试验都相互独立。如果这 $n$ 个试验还是相同的，则称其为 $n$ 重独立重复试验。</p><p>$n$ 重伯努利试验是一类常见的随机模型。</p><p><strong>伯努利试验</strong>　只有两个结果的实验就称为伯努利试验，例如抛硬币（正面和反面）、检查一个产品（合格与不合格）等等。在一次伯努利试验中，设成功的概率为 $p$，即</p><script type="math/tex; mode=display">P(A)=p,P(\overline{A})=1-p</script><p><strong>$n$ 重伯努利试验</strong>　由 $n$ 个（次）相同的、独立的伯努利试验组成的随机试验称为 $n$ 重伯努利试验。伯努利试验基本结果可用长为 $n$ 的序列表示，例如$AA\overline{A}AA$ 表示第三次失败，其余四次成功。在 $n$ 重伯努利试验中，在人们最关心的是成功次数。因为成功次数是基本结果中所含的最重要信息，而 $A$ 与 $\overline{A}$ 的排列次序在实际中往往是不感兴趣的信息。记</p><script type="math/tex; mode=display">B_{n,k}=“n重伯努利试验中A出现k次”</script><p>一般概率公式为</p><script type="math/tex; mode=display">P(B_{n,k})=\dbinom{n}{k}p^k(1-p)^{n-k}</script><h2 id="5-条件概率"><a href="#5-条件概率" class="headerlink" title="5. 条件概率"></a>5. 条件概率</h2><h3 id="5-1-条件概率"><a href="#5-1-条件概率" class="headerlink" title="5.1 条件概率"></a>5.1 条件概率</h3><p>假设苹果有两个属性，一个是好看，一个是好吃。现对25个苹果进行统计，得到结果如下</p><div class="table-container"><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">$B:$好看</th><th style="text-align:center">$\overline{B}:$不好看</th><th style="text-align:center"></th></tr></thead><tbody><tr><td style="text-align:center">$A:$好吃</td><td style="text-align:center">10</td><td style="text-align:center">5</td><td style="text-align:center">15</td></tr><tr><td style="text-align:center">$\overline{A}:$不好吃</td><td style="text-align:center">8</td><td style="text-align:center">2</td><td style="text-align:center">10</td></tr><tr><td style="text-align:center"></td><td style="text-align:center">18</td><td style="text-align:center">7</td><td style="text-align:center">25</td></tr></tbody></table></div><p>思考问题，当事件 $B$ 发生后，事件 $A$ 再发生的概率是多少？由于事件 $B$ 发生了，给人们带来新的信息，即 $\overline{B}$ 不可能再发生了，所有可能发生的基本结果局限在 $B$ 的 $18$ 个结果，这时事件 $A$ 所包含的基本结果在 $\Omega_B$ 中所占的比率为 $10/18$，这就是在事件 $B$ 已经发生的情况下，事件 $A$ 的条件概率，即 $P(A|B)=10/18$。</p><p>条件概率 $P(A|B)=10/18$ 中分母是事件 $B$ 中的基本结果数，记为 $N(B)=18$。分子是事件 $A$ 和 $B$ 同时发生的基本结果数，即交事件 $AB$，记为记为 $N(AB)=10$。分子分母同时除以原基本空间 $\Omega$ 中的基本结果数 $N(\Omega)=25$，得到如下关系式</p><script type="math/tex; mode=display">P(A|B)=\frac{N(AB)}{N(B)}=\frac{N(AB)/N(\Omega)}{N(B)/N(\Omega)}=\frac{P(AB)}{P(B)}</script><p>这表明条件概率可用两个特定的无条件概率之商表示，我们可以进一步得到条件概率的一般定义。</p><p><strong>定义1</strong>　设 $A$ 与 $B$ 是基本空间 $\Omega$ 中的两个事件，且$P(B)&gt;0$，在事件 $B$ 已发生的条件下，事件 $A$ 的条件概率 $P(A|B)$ 定义为 $P(AB)/P(B)$，即</p><script type="math/tex; mode=display">P(A|B)=\frac{P(AB)}{P(B)}</script><p>其中 $P(A|B)$ 也称为给定事件 $B$ 下事件 $A$ 的条件概率。</p><p>条件概率满足概率的三条公理，非负、正则、可加。当 $B=\Omega$ 时，条件概率转化为无条件概率，因此把无条件概率看作特殊场合下的条件概率也未尝不可。</p><p>除此之外，条件概率还有一些特殊性质。</p><p><strong>定理1(乘法公式)</strong>　对任意两个事件 $A$ 和 $B$，有</p><script type="math/tex; mode=display">P(AB)=P(A|B)P(B)=P(B|A)P(A)</script><p>对两个等式，分别要求 $P(B)&gt;0$ 和  $P(A)&gt;0$。这个定理表明任意两个事件交的概率等于一事件的概率乘以在这时间已发生的条件下另一事件的条件概率，只要它们的概率都不为零。</p><p><strong>定理2</strong>　假如事件 $A$ 与 $B$ 独立，且 $P(B)&gt;0$，则 $P(A|B)=P(A)$，反之亦然。<br><br>这个性质表明，若两事件独立，则其条件概率就等于其概率，这里事件 $B$ 的发生对事件 $A$ 是否发生没有任何影响，反之，若有 $P(A|B)=P(A)$，则有乘法公式可以得出 $P(AB)=P(A)P(B)$，故 $A$ 与 $B$ 独立。</p><p><strong>定理3(一般乘法公式)</strong>　对任意三个事件 $A_1$、$A_2$、$A_3$，有</p><script type="math/tex; mode=display">P(A_1A_2A_3)=P(A_1)P(A_2|A_1)P(A_3|A_1A_2)</script><p>其中 $P(A_1A_2)&gt;0$。</p><h3 id="5-2-全概率公式"><a href="#5-2-全概率公式" class="headerlink" title="5.2 全概率公式"></a>5.2 全概率公式</h3><p>全概率公式是概率论中的一个基本公式。它可以使一个复杂事件的概率计算化繁就简，得以解决。</p><p><strong>定理4</strong>　设 $A$ 与 $B$ 是任意两个事件，假如 $0&lt;P(B)&lt;1$，则</p><script type="math/tex; mode=display">P(A)=P(A|B)P(B)+P(A|\overline{B})P(\overline{B})</script><p>证：由 $B\bigcup \overline{B}=\Omega$ 和事件运算性质可知</p><script type="math/tex; mode=display">A=A\Omega=A(B\bigcup \overline{B})=AB\bigcup A\overline{B}</script><p>显然 $AB$ 与 $A\overline{B}$ 是互不相容事件，由加法公式和乘法公式得</p><script type="math/tex; mode=display">\begin{aligned}    P(A)&= P(AB)+P(A\overline{B})\\    &= P(A|B)P(B)+P(A|\overline{B})P(\overline{B})\\\end{aligned}</script><p>由于 $P(B)$ 不为0与1，所有 $P(\overline{B})&gt;0$，从而上述两个条件概率 $P(A|B)$ 与 $P(A|\overline{B})$ 都是有意义的。</p><p>将上述全概率公式推广到一般形式，需要一个“分割”的概念。简而言之，两个互为对立的事件组成全集，当多个事件彼此之间没有交集且组成全集的时候，它们就是一个分割。</p><p><strong>定义2</strong>　把基本空间 $\Omega$ 分成 $n$ 个事件 $B_1,B_2,\cdots,B_n$，假如满足如下条件</p><ul><li>$P(B_i)&gt;0,i=1,2,\cdots,n$</li><li>$B_1,B_2,\cdots,B_n$ 互不相容</li><li>$\bigcap\limits^n_{i=1} B_i=\Omega$<br>则称事件组 $B_1,B_2,\cdots,B_n$ 为基本空间 $\Omega$ 的一个分割。</li></ul><p><strong>定理5</strong>　 设 $B_1,B_2,\cdots,B_n$ 是基本空间 $\Omega$ 的一个分割，则对 $\Omega$ 中任一事件 $A$，有</p><script type="math/tex; mode=display">P(A)=\sum_{i=1}^nP(A|B_i)P(B_i)</script><p>由全概率公式可以推出一个很著名的公式。</p><p><strong>定理6(贝叶斯公式)</strong>　设 $B_1,B_2,\cdots,B_n$ 是基本空间 $\Omega$ 的一个分割，且它们各自概率 $P(B_1),P(B_2),\cdots,P(B_n)$ 皆已知且为正，又设 $A$ 是 $\Omega$ 中的一个事件，$P(A)&gt;0$，且在诸 $B_i$ 下事件 $A$ 的条件概率 $P(A|B_1),P(A|B_2),\cdots,P(A|B_n)$ 可通过试验等手段获得，则再 $A$ 给定下，事件 $B_k$ 的条件概率为</p><script type="math/tex; mode=display">P(B_k|A)=\frac{P(A|B_k)P(B_k)}{\sum\limits^n_{i=1}P(A|B_i)P(B_i)},k=1,2,\cdots,n</script>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;随机事件及其概率&quot;&gt;&lt;a href=&quot;#随机事件及其概率&quot; class=&quot;headerlink&quot; title=&quot;随机事件及其概率&quot;&gt;&lt;/a&gt;随机事件及其概率&lt;/h1&gt;&lt;h2 id=&quot;1-随机事件及其运算&quot;&gt;&lt;a href=&quot;#1-随机事件及其运算&quot; class=&quot;</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2022/01/12/ProbabilityStatistics/4.statistics%20and%20their%20disribution/"/>
    <id>http://example.com/2022/01/12/ProbabilityStatistics/4.statistics%20and%20their%20disribution/</id>
    <published>2022-01-12T00:33:57.364Z</published>
    <updated>2022-01-12T00:33:57.365Z</updated>
    
    <content type="html"><![CDATA[<h1 id="参数估计"><a href="#参数估计" class="headerlink" title="参数估计"></a>参数估计</h1><p>参数估计不仅指总体分布 $F(x;\theta)$ 中所含的参数 $\theta$，还指分布的各种特征数，如均值、方差、标准差、相关矩，也包括各种事件的概率等。对这些参数要精确确定是困难的，只能通过样本所提供的的信息对其作出某种估计。</p><p>在本章中，设 $\theta$ 是总体的一个待估参数，$\theta$ 的一切可能取值构成的参数空间记为 $\Theta$。$X_1,X_2,\cdots,X_n$ 为从总体中抽取了一个容量为 $n$ 的样本，其观测值记为 $x_1,x_2,\cdots,x_n$</p><p>参数估计的形式主要有两种：点估计与区间估计。</p><p>参数的点估计，是构造一个统计量 $\hat{\theta}=\hat{\theta}(X_1,X_2,\cdots,X_n)$，然后用 $\hat{\theta}$ 去估计 $\theta$，称 $\hat{\theta}$ 为 $\theta$ 的点估计或估计量，简称估计，将样本观测值带入后便得到了 $\theta$ 的一个点估计值 $\hat{\theta}(x_1,x_2,\cdots,x_n)$。</p><p>参数的区间估计，则是构造两个统计量 $\hat{\theta}_L$ 与 $\hat{\theta}_U$，且$\hat{\theta}_L&lt;\hat{\theta}_U$，然后以区间$[\hat{\theta}_L,\hat{\theta}_U]$ 的形式给出未知参数 $\theta$ 的估计，事件“区间$[\hat{\theta}_L,\hat{\theta}_U]$含有$\theta$” 的概率称为置信水平。</p><p>点估计的方法有两种矩法估计与极大似然估计。</p><h2 id="1-矩法估计"><a href="#1-矩法估计" class="headerlink" title="1. 矩法估计"></a>1. 矩法估计</h2><p>1900年英国统计学家 K.Pearson 提出了一个替换原则，用样本矩去替换总体矩，后来人们就称此为矩法估计。</p><p>矩法估计的基本点是：用样本矩估计总体矩，用样本矩的相应函数估计总体矩的函数。</p><p>设 $X_1,X_2,\cdots,X_n$ 是来自某总体 $X$ 的一个样本，则样本的 $k$ 阶原点矩为：</p><script type="math/tex; mode=display">A_k=\frac{1}{n}\sum^n_{i=1}X_i^k,k=1,2,\cdots</script><p>如果总体 $X$ 的 $k$ 阶原点矩 $\mu_k=E(X^k)$ 存在，则用 $A_k$ 去估计 $\mu_k$，记为</p><script type="math/tex; mode=display">\hat{\mu_k}=A_k</script>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;参数估计&quot;&gt;&lt;a href=&quot;#参数估计&quot; class=&quot;headerlink&quot; title=&quot;参数估计&quot;&gt;&lt;/a&gt;参数估计&lt;/h1&gt;&lt;p&gt;参数估计不仅指总体分布 $F(x;\theta)$ 中所含的参数 $\theta$，还指分布的各种特征数，如均值、方差、标准</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2022/01/12/ProbabilityStatistics/2.random%20variables%20and%20its%20probability%20distributions/"/>
    <id>http://example.com/2022/01/12/ProbabilityStatistics/2.random%20variables%20and%20its%20probability%20distributions/</id>
    <published>2022-01-12T00:33:57.362Z</published>
    <updated>2022-01-12T00:33:57.363Z</updated>
    
    <content type="html"><![CDATA[<h1 id="随机变量及其概率分布"><a href="#随机变量及其概率分布" class="headerlink" title="随机变量及其概率分布"></a>随机变量及其概率分布</h1><h2 id="1-随机变量"><a href="#1-随机变量" class="headerlink" title="1. 随机变量"></a>1. 随机变量</h2><h3 id="1-1-随机变量"><a href="#1-1-随机变量" class="headerlink" title="1.1 随机变量"></a>1.1 随机变量</h3><p>人们对随机现象的兴趣常常集中在其结果的某个数量方面。例如，再检查产品的过程中关心的是不合格产品的个数。若记20个产品中不合格的个数为 $X$ ，则这个 $X$ 可能取 $0,1,2,\cdots,20$ 中任意一个数，但最终是哪一个数要看检验结果，事先不能确定，因此 $X$ 的取值带有随机性，这样的变量就称为随机变量。有了随机变量之后，有关事件的表示也方便了。如 $X=2$ 表示“20个产品中有两个不合格产品” 这一事件。</p><blockquote><p>随机变量与随机事件的关系也就类似于变量与常量的关系，所以前文中随机事件都是用 $A,B$ 之类的常量字母表示。直观来说，随机变量就是“随机取值的变量”，或者“取值随机会而定的变量”。</p></blockquote><p><strong>定义1</strong>　假如一个变量在数轴上的取值依赖于随机现象的基本结果，则称此变量为<strong>随机变量</strong>，常用大写字母 $X,Y,Z$ 等表示，其取值用小写字母 $x,y,z$ 等表示。假如一个随机变量仅去数轴上的有限个或可列个孤立点，则称此随机变量为<strong>离散随机变量</strong>。假如一个随机变量的可能取值充满数轴上的一个区间 $(a,b)$ ，则称此随机变量为<strong>连续随机变量</strong>，其中 $a$ 可以是 $-\infty$， $b$ 可以是 $+\infty$ 。</p><h3 id="1-2-随机变量的概率分布"><a href="#1-2-随机变量的概率分布" class="headerlink" title="1.2 随机变量的概率分布"></a>1.2 随机变量的概率分布</h3><p>在定义中有随机变量 $X$ 的“取值依赖于基本结果”的说法，意味着随机变量 $X$ 是基本结果 $\omega$ 的函数，即可以把 $X$ 即为 $X(\omega)$，</p><script type="math/tex; mode=display">X=X(\omega),\omega \in \Omega</script><p>对随机变量 $X$ 来说，不容许基本空间 $\Omega$ 中有一个基本结果 $\omega$ 没有实数与其对应，综上所述，随机变量也可看作定义在基本空间 $\Omega$ 的实值函数。因此，“随机变量 $X$ 的取值为 $x$” 就是满足等式 $X(\omega)=x$ 的一切 $\omega$ 组成的集合，用”$X=x$“表示，即</p><script type="math/tex; mode=display">“X=x”=\{\omega:X(w)=x\}\subset \Omega</script><p>类似的，“随机变量 $X$ 的取值小于或等于 $x$”就是满足不等式 $X(\omega)\le x$ 的一切 $\omega$ 组成的集合，用“$X\le x$”表示，即</p><script type="math/tex; mode=display">“X\le x”=\{\omega:X(w)\le x\}\subset \Omega</script><blockquote><p>当一个函数等于一个值的时候其实它就是一个方程了，因此上述就类似于 $f(x)=a$。</p></blockquote><p>上述两种形式的事件是典型事件。例如，要确定一个离散随机变量 $X$ 取值的概率，只要对其可能取值 $x_i$ 确定形如 “$X=x_i$” 事件的概率即可。而对一般随机变量 $X$ ，要确定它取值的概率，就要对任意实数 $x$ ，确定形如 “$X\le x$” 的事件概率，这类事件的概率 $P(X\le x)$ 是 $x$ 的函数，随 $x$ 变化而变化，将这个函数记为 $F(x)$ ，即为分布函数。</p><p><strong>定义2</strong>　设 $X$ 为一个随机变量，对任意实数 $x$ ，事件 $X\le x$ 的概率是 $x$ 的函数，记为</p><script type="math/tex; mode=display">F(x)=P(X\le x)</script><p>这个函数称为 $X$ 的累积概率分布函数，简称分布函数。</p><p>从分布函数定义可以得到它的一些基本性质。</p><ol><li>$0\le F(x)\le 1$。分布函数值是特定形式事件 “$X\le x$” 的概率，而概率总是在0和1之间。</li><li>$F(-\infty)=\lim\limits_{x\rightarrow -\infty}F(x)=0$。这是因为事件 “$X\le -\infty$” 是不可能事件。</li><li>$F(+\infty)=\lim\limits_{x\rightarrow +\infty}F(x)=1$。这是因为事件 “$X\le +\infty$” 是必然事件。</li><li>$F(x)$ 是非降函数，即对任意 $x_1&lt;x_2$， $F(x_1)\le F(x_2)$。这是因为事件“$X\le x_2$” 包含事件 “$X\le x_1$”。</li><li>$F(x)$ 是右连续函数，即 $F(x)=F(x+0)$，其中 $F(x+0)$ 是函数在 $x$ 处的右极限，对任意给定的 $x$，取一个下降数列 $\{x_n\}$，使其极限为 $x$ ，即<script type="math/tex; mode=display">x_1>x_2>\cdots>x_n>\cdots\rightarrow x</script></li></ol><script type="math/tex; mode=display">F(x+0)=\lim\limits_{x_n\rightarrow x}F(x)</script><p><strong>可列可加性公理</strong>　若 $A_1,A_2,\cdots$ 是一列互不相容事件，则有</p><script type="math/tex; mode=display">P(\bigcup\limits _{n=1}^\infty A_n)=\sum _{n=1}^\infty P(A_n)</script><p>此公理与非负性公理、正则性公理一起组成新的公理体系，它使可列个事件经运算后所得事件可谈及概率。</p><h2 id="2-离散随机变量"><a href="#2-离散随机变量" class="headerlink" title="2. 离散随机变量"></a>2. 离散随机变量</h2><p><strong>定义3</strong>　设 $X$ 是离散随机变量，它的所有可能取值时 $x_1,x_2,\cdots,x_n,\cdots$，假如 $X$ 取 $x_i$ 的概率为</p><script type="math/tex; mode=display">P(X=x_i)=p(x_i)\ge 0,i=1,2,\cdots,n,\cdots</script><p>且满足如下条件：</p><script type="math/tex; mode=display">\sum_{i=1}^\infty p(x_i)=1</script><p>则称这组概率 $\{p(x_i)\}$ 为该随机变量 $X$ 的<strong>分布列</strong>，或 $X$ 的<strong>概率分布</strong>，记为 $X\sim\{p(x_i) \}$，读成随机变量 $X$ 服从分布 $\{p(x_i)\}$ 。<br>若已知离散随机变量 $X$ 的分布列为 $\{p(x_i)\}$ ，容易写出 $X$ 的分布函数</p><script type="math/tex; mode=display">F(x)=\sum_{x_i\le x}p(x_i)</script><p>但在离散随机变量场合，使用分布列更为方便，故常用分布列表示离散随机变量的概率分布，非必要不使用分布函数。</p><p>分布列还有两种图表示方法：线条图与概率直方图。</p><h3 id="2-1-离散随机变量的数学期望"><a href="#2-1-离散随机变量的数学期望" class="headerlink" title="2.1 离散随机变量的数学期望"></a>2.1 离散随机变量的数学期望</h3><p>“期望”在日常生活中常指有根据的希望，或发生可能性较大的希望，例如一台冰箱期望的使用寿命是10年，并不是指到10年的时间就一定坏，而是或早或晚都有可能。“期望”就是指用概率分布算得的一种加权平均。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;随机变量及其概率分布&quot;&gt;&lt;a href=&quot;#随机变量及其概率分布&quot; class=&quot;headerlink&quot; title=&quot;随机变量及其概率分布&quot;&gt;&lt;/a&gt;随机变量及其概率分布&lt;/h1&gt;&lt;h2 id=&quot;1-随机变量&quot;&gt;&lt;a href=&quot;#1-随机变量&quot; class=&quot;</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2022/01/12/ComputerScience/1.information%20layer/"/>
    <id>http://example.com/2022/01/12/ComputerScience/1.information%20layer/</id>
    <published>2022-01-12T00:33:57.350Z</published>
    <updated>2022-01-12T00:33:57.350Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-信息层-数据存储"><a href="#1-信息层-数据存储" class="headerlink" title="1 信息层-数据存储"></a>1 信息层-数据存储</h1><h2 id="1-1-二进制和记数系统"><a href="#1-1-二进制和记数系统" class="headerlink" title="1.1 二进制和记数系统"></a>1.1 二进制和记数系统</h2><p>基数（base）：记数系统的基本数值，规定了这个系统中使用的数字量和数位位置的值。</p><p>位置记数法（positional notation）：一种表达数字的系统，数位按顺序排列，每个数位又一个位置，数字的值是每个数位和位值的乘积之和，即用记数系统的基数的多项式表示值。</p><p>不同进制之间的相互转换</p><ul><li>二进制数字（binary digit）：二进制记数系统中的一位数字，可以是0或1，在计算机中每个存储位为高电平和低电平两种信号，每个存储单元即为一个二进制数字。</li><li>位（bit）：二进制数字的简称。</li><li>字节（byte）：8个二进制位。</li><li>字（word）：一个或多个字节，字中的位数称为计算机的字长</li></ul><h2 id="1-2-数据形式"><a href="#1-2-数据形式" class="headerlink" title="1.2  数据形式"></a>1.2  数据形式</h2><p>计算机可以处理各种各样的信息，可以存储、表示和帮助我们修改各种类型的数据</p><ul><li>数据（data）：基本值或事实，未组织过的，缺少context，</li><li>信息（information）：用有效的方式组织或处理过的数据，可以帮助我们回答问题。</li><li>多媒体（multimedia）：集中不同的媒体类型。</li><li>数据压缩（data compression）：减少存储一段数据所需的空间。</li><li>带宽（bandwidth）：在固定时间内从一个地点传输到另一个地点的最大位数或字节数。</li><li>压缩率（compression ratio）：压缩后的数据大小除以原始数据大小的值。</li><li>无损压缩（lossless compression）：不会丢失信息的数据压缩技术。</li><li>有损压缩（lossy compression）：会丢失信息的数据压缩技术。</li></ul><p>表示数据的方法有两种，模拟法和数字法。模拟数据是一种连续表示法，模拟它表示的真实信息，数字数据是一种离散表示法，把信息分割成独立的元素。模拟数据完全对应于我们周围无限连续的世界。因此，计算机不能很好的处理模拟数据，需要数字化数据，即把信息分割成片段并单独表示每个片段。<br>数字信号只能在两个极端之间跳跃，称为脉冲编码调制（PCM）。数字信号在信息丢失之前会降级相当多，因为大于某个阈值的电平值被看作高电平。数字信号会被周期性重新计时，以恢复到它的原始状态。</p><p>1.3  数字数据表示法<br>1.3.1  负数表示法<br>符号数值表示法 signed-magnitude representation，符号表示数所属的分类（正数或负数）、值表示数的量值的数字表示法。对带符号的整数执行加减法可以被描述为向一个方向或另一个方向移动一定数字单位。符号数值表示法存在问题，即表示0的方法有两种，+0或-0，在计算机中会引起不必要的麻烦。<br>十进制补码 （ten’s complement），一种负数表示法，负数I用10的k次幂减I表示。</p><p>二进制补码（ two’s complement），位模式最左边的二进制位指明了所表示的数值的符号，0为正，1为负（指明符号的同时，0变为1，也可以理解为在数的基础上加2^n，例如八位中，0加上了128，则用128表示-128，127加上128，则用255表示-1。因此，在二进制补码中11111111，不表示-127，而是表示-1）。假定数字只能用八位表示，七位表示数值，一位表示符号，则取值范围为-128～127。与十进制补码相类似：<br>-2 = 2^7 - 2 = 128 - 2 = 126<br>十进制数126用二进制表示为1111110，左边添加一位符号位变为11111110。<br>除了用公式计算，在二进制中还有更简单的方法计算二进制补码，当知道5的二进制数，如何得到-5的二进制数？<br>方法一：将每一位取反再加一<br>5:  00000101<br>取反：11111010<br>    +1：11111011 = 251<br>方法二：从右向左，直到第一个二进制1（包括），他们都是相同的。然后，以这个1为分界线，左面的位模式取反。<br>5:  00000101<br>-5:  11111011<br>二进制补码的加减法：二进制补码记数法的一个主要优点在于，减法可以转化为加法，从而可以使用相同的电路来实现。7-5与7+（-5）是一样的。因此，在计算机中执行7（0111）减去5（0101），将5转换为-5（1011），再执行0111+1011=0010=2。<br>溢出（overflow）：当给结果预留的位数存不下计算出的值的状况时。在二进制补码记数法中，如果两个正值相加的结果是负值，或者两个负值相加的结果为正，那么就发生了溢出问题。<br>127+3 ：01111111+00000011=10000010   在二进制补码中，第一位是符号位结果为-126。但如果表示的不是负数时，结果就是130将是正确的。<br>余码计数法（excess notation）<br>1.3.2  实数表示法<br>在计算中，非整数的值称为实值。实数具有整数部分和小数部分，每个部分都可能是0。位置记数法中，数字的位置表示数值，位值是由基数决定的。在十进制中，小数点左侧的位值有1、10、100等等，它们都是基数的幂，从小数点开始向左，每一位升高一次幂。小数点右侧的位值同样如此，只不过幂是负数。所以小数点右侧的位置是十分位（10^-1或十分之一）、百分位（10^-2或百分之一）。同理，在二进制中，小数点右侧的位置是二分位、四分位，以此类推。<br>一种基于科学计数法的存储方法，称为浮点记数法。任何实值可以由三个属性描述，即符号、指数和尾数，尾数由该数值中的数字构成，指数确定了小数点相对于尾数的位移。数字的个数是固定的，小数点却是浮动的，因此称为浮点记数法。在用浮点形式表示的数值中，正指数将把小数点右移，负指数将小数点左移。<br>假如一个字节由位模式01101011组成，符号为0，指数是110，尾数是1011。解码，尾数左边放置一个小数点，得到.1011，指数110是一个三位的二进制补码，表示整数2，因此小数点右移2位，可以得到10.11=1<em>2+0</em>1+1<em>1/2+1</em>1/4=2.75。<br>截断误差（truncation error）：由于尾数域空间不够大，而导致的存储部分数值丢失。二进制中的无穷展开式多于十进制，在二进制中无法精确表示1/10。<br>单精度浮点（single precision floating point）记数法，具有32位，其中1位表示符号位、8位表示指数、23位表示尾数。因此，单精度浮点最多有7位十进制有效数字，可以表示10^32到10^-37数量级之间的数，也就是说，可以精确地存储前七位十进制有效数字。<br>双精度浮点（double precision floating point）记数法，具有64位，最多有15位十进制有效数字。<br>科学计数法（scientific notation）是浮点表示法的一种形式，小数点总在最左边数字的右侧，也是说只有一位整数部分，12001.32708被写为1.200132708E+4。<br>1.4  文本表示法<br>1.4.1  ASCII字符集<br>字符集（character set）：字符和表示它们的代码的清单<br>ASCII字符集（American Standard Code for Information Interchange），用7位表示每个字符，可以表示128个字符，<br>0～31及127(共33个)是控制字符或通信专用字符（其余为可显示字符），如控制符：LF（换行）、CR（回车）、FF（换页）、DEL（删除）、BS（退格)、BEL（响铃）等；通信专用字符：SOH（文头）、EOT（文尾）、ACK（确认）等；ASCII值为8、9、10 和13 分别转换为退格、制表、换行和回车字符。它们并没有特定的图形显示，但会依不同的应用程序，而对文本显示有不同的影响 [1]  。<br>32～126(共95个)是字符(32是空格），其中48～57为0到9十个阿拉伯数字。<br>65～90为26个大写英文字母，97～122号为26个小写英文字母，其余为一些标点符号、运算符号等。<br>1.4.2 Unicode字符集<br>Unicode每个字符的编码为16位，但如果需要每个字符也可以使用更多空间，以便表示额外的字符。Unicode字符集的一个方便之处是把ASCii字符集作为一个子集，即前256个字符与扩展ASCii字符集中的完全一样。因此，即使底层系统采用Unicode字符集，采用ASCii值的程序也不会受到影响。<br>1.4.3 文本压缩<br>文本压缩主要有三种方式<br>关键字编码（keyword encoding）：用单个字符代替常用的单词。例如用^替代as，~替代the等等。这种方式有一些局限性。首先，用来编码的字符不能出现在原始文本中，否则会产生歧义；其次，The不会被编码，因为大小写是不同的字符；最后常用的单词都比较短，节省空间有限，而长的单词出现频率低也没有替换的必要。<br>行程长度编码（run-length encoding）：把一系列重复字符替换为它们重复出现的次数。将重复字符的序列替换为标志字符，后面加重复字符和说明字符重复次数的数字，例如AAAAAAA可以替换为<em>A7，</em>即为一种标志字符。因为用一个字符记录重复的次数，看似不能对重复次数大于9的序列编码，但实际上，在字符集中一个字符是由多个为表示的，因此可以将次数字符解释为一个二进制数，而不是ASCii数字。因此，能够编码的重复字符重复次数可以是0~255。<br>赫夫曼编码（Huffman encoding）：用变长的二进制串表示字符，使常用的字符具有较短的编码。不同的字符编码长度不同，例如常出现的A编码00，而出现比较少的D则为1011。由于编码是变长的，因此不知道每个字符对应多少位编码，看似很难将一个字符串解码。赫夫曼编码的一个重要特征是用于表示一个字符串的位串不会是另个一字符的位串的前缀。因此，从左到右扫描一个位串时，每当发现一个位串对应于一个字符，那么将唯一对应，不会发生歧义。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;1-信息层-数据存储&quot;&gt;&lt;a href=&quot;#1-信息层-数据存储&quot; class=&quot;headerlink&quot; title=&quot;1 信息层-数据存储&quot;&gt;&lt;/a&gt;1 信息层-数据存储&lt;/h1&gt;&lt;h2 id=&quot;1-1-二进制和记数系统&quot;&gt;&lt;a href=&quot;#1-1-二进制和记</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Hexo</title>
    <link href="http://example.com/2022/01/09/Command/Hexo/"/>
    <id>http://example.com/2022/01/09/Command/Hexo/</id>
    <published>2022-01-08T16:00:00.000Z</published>
    <updated>2022-01-12T00:33:57.347Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><h1 id="Hexo"><a href="#Hexo" class="headerlink" title="Hexo"></a>Hexo</h1><h2 id="1-安装-NodeJs"><a href="#1-安装-NodeJs" class="headerlink" title="1. 安装 NodeJs"></a>1. 安装 NodeJs</h2><p>windows/mac 安装</p><p><a href="https://nodejs.org/en/download/">NodeJs官网</a></p><p>检查是否安装成功</p><pre><code class="lang-bash">node -v</code></pre><p>npm 换源</p><pre><code class="lang-shell">npm config set registry https://registry.npm.taobao.org</code></pre><p>检测是否修改成功</p><pre><code class="lang-shell">npm config get registry</code></pre><h2 id="2-安装-Hexo"><a href="#2-安装-Hexo" class="headerlink" title="2. 安装 Hexo"></a>2. 安装 Hexo</h2><p>安装命令</p><pre><code class="lang-shell">npm install hexo-cli -g</code></pre><p>检查是否安装成功</p><pre><code class="lang-shell">hexo -v</code></pre><p>初始化文件夹</p><pre><code class="lang-shell">hexo init blog</code></pre><h2 id="3-安装相关支持库"><a href="#3-安装相关支持库" class="headerlink" title="3. 安装相关支持库"></a>3. 安装相关支持库</h2><p>git 支持</p><pre><code class="lang-shell">npm install hexo-deployer-git --save</code></pre><p>search 支持</p><pre><code class="lang-shell">npm install hexo-generator-feed --save</code></pre><h2 id="4-公式相关依赖"><a href="#4-公式相关依赖" class="headerlink" title="4. 公式相关依赖"></a>4. 公式相关依赖</h2><pre><code class="lang-shell">npm uninstall hexo-renderer-marked --save</code></pre><pre><code class="lang-shell">npm install hexo-renderer-kramed --save</code></pre><p>打开node_modules/hexo-renderer-kramed/lib/renderer.js，将</p><pre><code class="lang-javascript">// Change inline math rulefunction formatText(text) &#123;    // Fit kramed&#39;s rule: $$ + \1 + $$    return text.replace(/`\$(.*?)\$`/g, &#39;$$$$$1$$$$&#39;);&#125;</code></pre><p>改为</p><pre><code class="lang-javascript">// Change inline math rulefunction formatText(text) &#123;    return text;&#125;</code></pre><pre><code class="lang-shell">npm uninstall hexo-math --save</code></pre><pre><code class="lang-shell">npm install hexo-renderer-mathjax --save</code></pre><p>打开node_modules/hexo-renderer-mathjax/mathjax.html，最后一行改为</p><pre><code class="lang-html">&lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML&quot;&gt;&lt;/script&gt;</code></pre><p>打开node_modules/kramed/lib/rules/inline.js:</p><p>将</p><pre><code class="lang-javascript">escape: /^\\([\\`*&#123;&#125;\[\]()#$+\-.!_&gt;])/,</code></pre><p>改为</p><pre><code class="lang-javascript">escape: /^\\([`*\[\]()# +\-.!_&gt;])/,</code></pre><p>将</p><pre><code class="lang-javascript">em: /^\b_((?:__|[\s\S])+?)_\b|^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,</code></pre><p>改为</p><pre><code class="lang-javascript">em: /^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,</code></pre><p>在home/_config.yml，中添加如下内容</p><pre><code class="lang-yml">mathjax:    enable: true</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;h1 id=&quot;Hexo&quot;&gt;&lt;a href=&quot;#Hexo&quot; class=&quot;headerlink&quot; title=&quot;Hexo&quot;&gt;&lt;/a&gt;Hexo&lt;/h1&gt;&lt;h2 id=&quot;1-安装-NodeJs&quot;&gt;&lt;a href=&quot;#1-安装-NodeJ</summary>
      
    
    
    
    <category term="Command" scheme="http://example.com/categories/Command/"/>
    
    
  </entry>
  
  <entry>
    <title>Python</title>
    <link href="http://example.com/2022/01/09/Command/Python/"/>
    <id>http://example.com/2022/01/09/Command/Python/</id>
    <published>2022-01-08T16:00:00.000Z</published>
    <updated>2022-05-30T07:19:19.080Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><h1 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h1><h2 id=""><a href="#" class="headerlink" title=" "></a> </h2><p>升级 apt-get</p><pre><code class="lang-bash">sudo apt-get update</code></pre><p>安装pip3 </p><pre><code class="lang-bash">sudo apt-get install python3-pip</code></pre><p>vim ~/.bash_profile<br>export PATH=$PATH:/home/ubuntu/.local/bin<br>source ~/.bash_profile</p>]]></content>
    
    
      
      
    <summary type="html">&lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;h1 id=&quot;Linux&quot;&gt;&lt;a href=&quot;#Linux&quot; class=&quot;headerlink&quot; title=&quot;Linux&quot;&gt;&lt;/a&gt;Linux&lt;/h1&gt;&lt;h2 id=&quot;&quot;&gt;&lt;a href=&quot;#&quot; class=&quot;headerli</summary>
      
    
    
    
    <category term="Command" scheme="http://example.com/categories/Command/"/>
    
    
  </entry>
  
  <entry>
    <title>Linux</title>
    <link href="http://example.com/2022/01/09/Command/Linux/"/>
    <id>http://example.com/2022/01/09/Command/Linux/</id>
    <published>2022-01-08T16:00:00.000Z</published>
    <updated>2022-01-24T09:29:56.552Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><h1 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h1><h2 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h2><h3 id="网络第一包慢"><a href="#网络第一包慢" class="headerlink" title="网络第一包慢"></a>网络第一包慢</h3><pre><code class="lang-bash">ping -n refclient.ext.here.com</code></pre><blockquote><p>PING refclient.ext.here.com (108.139.1.24) 56(84) bytes of data.<br>64 bytes from 108.139.1.24: icmp_seq=1 ttl=243 time=1.18 ms<br>64 bytes from 108.139.1.24: icmp_seq=2 ttl=243 time=1.18 ms<br>64 bytes from 108.139.1.24: icmp_seq=3 ttl=243 time=1.14 ms<br>64 bytes from 108.139.1.24: icmp_seq=4 ttl=243 time=1.15 ms<br>64 bytes from 108.139.1.24: icmp_seq=5 ttl=243 time=1.14 ms<br>64 bytes from 108.139.1.24: icmp_seq=6 ttl=243 time=1.14 ms</p></blockquote><pre><code class="lang-bash">time ping -n refclient.ext.here.com -c 1</code></pre><blockquote><p>1 packets transmitted, 1 received, 0% packet loss, time 0ms<br>rtt min/avg/max/mdev = 1.188/1.188/1.188/0.000 ms<br>real    0m5.011s<br>user    0m0.000s<br>sys     0m0.000s</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;h1 id=&quot;Linux&quot;&gt;&lt;a href=&quot;#Linux&quot; class=&quot;headerlink&quot; title=&quot;Linux&quot;&gt;&lt;/a&gt;Linux&lt;/h1&gt;&lt;h2 id=&quot;网络&quot;&gt;&lt;a href=&quot;#网络&quot; class=&quot;head</summary>
      
    
    
    
    <category term="Command" scheme="http://example.com/categories/Command/"/>
    
    
  </entry>
  
  <entry>
    <title>5. Decision Tree</title>
    <link href="http://example.com/2021/12/22/MachineLearning/5.DecisionTree/"/>
    <id>http://example.com/2021/12/22/MachineLearning/5.DecisionTree/</id>
    <published>2021-12-21T16:00:00.000Z</published>
    <updated>2022-02-20T05:20:44.474Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><h2 id="1-历史背景"><a href="#1-历史背景" class="headerlink" title="1. 历史背景"></a>1. 历史背景</h2><p>关于树形结构的历史可以追溯到古巴比伦，在这里就不过多阐述。</p><p>1963：最早的发表在文献中的回归树算法是Automatic Interaction Detection(AID, Morgan &amp; Sonquist)。AID 从根节点开始递归的将数据拆分为两个子节点，选择划分特征的依据是通过类似于方差的公式 $\sum (X-\overline{X})^2$ ，称为不纯函数，计算划分子节点的误差平方和使其越小说明划分效果越好，因为 $\sum (X-\overline{X})^2=\sum X^2-N\overline{X}^2$，所以最终只要计算划分后 $\sum N_i\overline{X_i}^2$ 即可，选择最大的特征进行划分。当划分后的误差平方减少值小于 $0.02(\sum X^2-N\overline{X}^2)$ 则结束算法（亦或0.006，CART书中所写）。</p><p>1972：THeta Automatic Interaction Detection (THAID, Messenger &amp; Mandell) 将上述思想应用到分类问题中，提出了第一个分类树，并用熵函数和基尼指数代替上述不纯函数。</p><p>1980：CHi-squared Automatic Interaction Detector (CHAID) 由 Kass 创建，通过 $\mathcal{X}^2$ 拟合优度检验来找到主要特征，假设有两个类别，默认分布概率都是 $1/2$，计算 $\mathcal{X}^2=\sum\sqrt{(n_i-np_i)/(np_i)}$，选取最大的特征进行分割。卡方拟合优度越大意味着观察频数与默认均匀分布的区别越大，也就是越趋于有序，当同一特征将样本均归于同一类时，卡方拟合优度达到最大，当两个类别各有一半时，卡方拟合优度则为0。</p><p>1984：Classification And Regression Trees (CART) 伯克利的统计学教授 Leo Breiman 和 Charles Stone 以及斯坦福的 Jerome Friedman 和 Richard Olshen 共同建立。它同样使用 AID 的贪婪搜索方法，但增加了新颖的改进。CART 不再使用停止规则，而是生成一颗大树，通过最低交叉验证对树结构进行剪枝。这解决了 AID 和 THAID 的欠拟合和过拟合问题。</p><p>1986：John Ross Quinlan 提出了一个新概念有多个答案的树，而CART 和所有其他算法对每个问题只有两个答案（称为二叉树）。Quinlan 使用称为增益比的杂质标准发明了  Iterative Dichotomiser 3（ID3）。</p><p>1993：C4.5 是 ID3 算法的扩展，C4.5 解决了其前身的缺点，在数据挖掘杰出论文的 Top 10 算法中排名第一（Springer LNCS，2008）。</p><h2 id="2-决策树结构"><a href="#2-决策树结构" class="headerlink" title="2.决策树结构"></a>2.决策树结构</h2><p>决策树模型是一种对实例进行分类或回归的树形结构。树结构的每个节点均代表输入特征空间的部分子区域，对于不再分割的节点称为终端节点（terminal node）也叫叶节点（leaf node），在图中由矩形框表示；除了叶节点以外的称为内部节点（internal node），在图中用圆形表示。</p><p>构建决策树的时候，从根节点开始，通过一定规则选定分割的特征维度和特征值，然后构建下一层的多个节点。特别地，如果每一个节点只通过一个特征的一个值分割为两部分，该决策树则称为二叉决策树。</p><p>对于决策树中的每一个节点的后代节点都是不相交的，也就是它们之间互斥，同时一个节点所有后代子集的并集即为该节点。例如图1中所示，$X_2$ 与 $X_3$ 互斥且 $X=X_2\bigcup X_3$。决策树中的每一层中的节点的并集构成整体输入特征空间。</p><p>终端节点是输入空间的一个子区域，所有终端节点互斥且完备，即所有终端节点的并集构成整体输入空间。在分类问题中，每个终端节点由一个类标签指定，可能有多个终端节点有相同的类标签。分类器最终分类划分是将同一类对应的所有终端子集放在一起得到的。例如，上图的划分结果为</p><script type="math/tex; mode=display">\begin{aligned}    A_1&=X_{15} \\    A_2&=X_{10}\bigcup X_{16}\\    A_3&=X_{11}\bigcup X_{14}\\    A_4&=X_{6}\bigcup X_{17}\\    A_5&=X_8 \\    A_6&=X_{12} \\\end{aligned}</script><p>综上所述，可以发现构建决策树需要解决三个问题：</p><ol><li>在每个中间节点选择拆分的方法</li><li>终止条件</li><li>每个终端叶子节点的输出结果</li></ol><p>进一步地，如果想要决策树模型不仅对训练数据有很好的拟合效果，同时对未知数据有很好的预测，也就是避免过拟合现象的发生，我们还可能需要对已生成的决策树进行自下而上的剪枝，使树结构变得更简单，从而使它具有更好的泛化能力，也就是</p><ol><li>决策树的剪枝 </li></ol><p>有关第一个问题，在这里先定义一个通用的方法和标准。</p><p>定义训练集的输入实例数为 $N$，每个类别的数量为 $N_j$，则每个节点 $t$ 中的某一类别的数量为 $N_j(t)$，落入节点的概率为 $p(t) = N(t)/N$，条件概率$p(t\,|\,j)=N_j(t)/N_j$，属于 $j$ 类且落入节点 $t$ 两事件同时发生的概率为 $p(j,t)=p(t\,|\,j)p(j)$，在这里我们先假设先验概率 $p(j)$ 就是训练集中的类别概率 $p(j)=N_j/N$。因此，根据贝叶斯公式我们可以得到后验概率</p><script type="math/tex; mode=display">\begin{aligned}    P(j\,|\,t)&=\frac{p(t\,|\,j)p(j)}{p(t)}\\    &=\frac{(N_j(t)/N_j) \ast (N_j/N)}{N(t)/N}\\    &=\frac{N_j(t)}{N(t)}\end{aligned}</script><blockquote><p>忙活半天，得到了一个很显而易见的结果 -_-!  但这个显而易见的比例实际上是条件概率。</p></blockquote><p>通常情况下先验概率 $p(j)$ 被视为训练集中的比例 $N_j/N$。但学习样本中的比例无法反映到现实中实际的比例，就例如评价道路的好坏，实际上得到的训练集都是通过 bad case 中的路线，实际上，可能差路线存在的比例会更低。</p><p>因此，我们由其他途径的得到先验概率 $\pi(j)$ 取代训练集中的概率 $p(j)$，联合概率即为 </p><script type="math/tex; mode=display">p(j,t)=\pi(j)N_j(t)/N_j</script><p>同时任何案例落入节点 $t$ 的概率重新带入估计 </p><script type="math/tex; mode=display">p(t)=\sum_jp(j,t)</script><p>最后再去计算条件概率 $p(j\,|\,t)$，可以发现，替换后的条件概率依旧满足 </p><script type="math/tex; mode=display">\sum_jp(j\,|\,t)=1</script><p>决策树划分的目的就是希望能通过特征将实例的类别进行区分出来。决策树的每个内部节点将分割为更多的子区域，每个子区域的条件是一样的，而所希望的就是某一类的条件概率 $P(j\,|\,t)$ 尽可能的大。换句话说，希望每个后代节点中的数据比父节点中的数据更“纯”（purer）。</p><p>例如，假设有个六分类问题，根节点的条件概率 $(p_1,p_2,p_3,p_4,p_5,p_6)$ 为 $\displaystyle(\frac{1}{6},\frac{1}{6},\frac{1}{6},\frac{1}{6},\frac{1}{6},\frac{1}{6})$，一个好的划分结果就是两个子节点的条件概率也就是类别比例为 $\displaystyle(\frac{1}{3},\frac{1}{3},\frac{1}{3},0,0,0)$ 和 $\displaystyle(0,0,0,\frac{1}{3},\frac{1}{3},\frac{1}{3})$ 。</p><p>因此我们需要寻找一个测度去衡量一个节点中子集的不纯度（impurity），定义一个非负函数，要求当所有类均匀混合在一起时它的不纯度最大，当节点中只包含一个类时，该值最小，现将这个函数定义为 $i(t)$。</p><p>对于任何中间节点 $t$，假设有一个节点的候选切分 $s$ 将节点分割为 $t_L$ 和 $t_R$，这样 $t$ 中的事件（case）分别进入 $t_L$ 和 $t_R$ 的比例为 $p_L$ 和 $p_R$，那么最终切分点 $s$ 的好坏定义为不纯度的好坏的减少</p><script type="math/tex; mode=display">\triangle i(s,t)=i(t)-p_Li(t_L)-p_Ri(t_R)</script><p>对于不是二叉树而是多切分节点的算法只需将上公式扩展为多个即可，但始终 $p_1+p_2+\cdots+p_n=1$。</p><p>我们对 $i(t)$ 函数的要求进行总结：</p><ol><li>当每个类别概率相等时，$i(t)$ 值最大。</li><li>当只有一个类别时，$i(t)$ 值最小</li><li>$i(t)$ 是轴对称函数</li></ol><p>至此，我们得到一个通用的标准去衡量切分的好坏程度，在不同的算法中以及回归和分类树中，所不同的只是不纯度函数 $i(t)$ 的不同。</p><h2 id="3-CART-算法"><a href="#3-CART-算法" class="headerlink" title="3. CART 算法"></a>3. CART 算法</h2><p>CART 算法由 Breiman 等人在 1984 年提出。CART 同样由特征选择、树的生成以及剪枝组成，既可用于分类也可以用于回归。</p><p>CART 是在给定输入随机变量 $X$ 条件下输出随机变量 $Y$ 的条件概率分布的学习方法。CART 是二叉树，递归的二分每个特征，分为“是”或“否”，将输入空间即特征空间划分为有限个单元，并在每个单元上确定预测的概率分布。</p><p>CART回归树实际是基于AID的决策树方法，但增加了最优切分点的寻找以及剪枝的过程。CART分类树使用到的基尼指数也不是第一次出现。</p><h3 id="3-1-CART-分类"><a href="#3-1-CART-分类" class="headerlink" title="3.1 CART 分类"></a>3.1 CART 分类</h3><p>我们从前述四个问题出发，先解决最直观的第三个问题</p><ol><li>每个终端叶子节点的输出结果</li></ol><p><strong>定义1</strong> 一个决策树的所有节点的集合为 $T$，终端节点的集合为 $\widetilde{T}$，每个终端节点 $t\in \widetilde{T}$，所有分类标签的集合为 $j\in \{1,2,\cdots,J\}$，则某一节点所分配的类为 $j(t)$。</p><blockquote><p>$j(t)$ 是类分配结果同时也代表一种类分配规则</p></blockquote><p>对于任何一种类分配结果 $j(t)$，如果实例落入节点 $t$，则错误分类概率的重新替换估计（resubstitution estimate）为</p><script type="math/tex; mode=display">\sum_{j\ne j(t)}p(j\,|\,t)</script><p>我们需要最小化这个误分类估计的规则作为我们类分配规则 $j^\ast(t)$。</p><p>由于一个节点最终只能输出一个类别，一个直观的类分配规则就是将某一节点中占比最大的类分配给该节点，这样做的另一个原因就是使误分类的概率最小。</p><p><strong>定义2</strong> 类分配规则 $j^\ast(t)$：如果 $\displaystyle p(j\,|\,t)=\max_i p(i\,|\,t)$，则 $j^\ast(t)=j$，如果两个或多个不同类别达到最大值，则将 $j^\ast(t)$ 任意指定为任何一个最大化类别。</p><p>第三个问题得到解决。</p><p>进一步地，我们就可以得到节点 $t$ 的误分类概率的重新带入估计 $r(t)$ 为</p><script type="math/tex; mode=display">\begin{aligned}    r(t)&=\sum_{j\ne j^*(t)}p(j\,|\,t)\\    &=1-\max_j p(j\,|\,t)\end{aligned}</script><p>整体决策树误分类率的重新代入估计则为 </p><script type="math/tex; mode=display">\begin{aligned}    R(T)&=\sum_{t\in \widetilde{T}}r(t)p(t)\\    &=\sum_{t\in \widetilde{T}}R(t)\end{aligned}</script><p>$R(t)$ 的一个重要特性，以任何方式分割的越多，则 $R(T)$ 就会变得越小。一个节点 $t$ 分割成两部分 $t_L$ 和 $t_R$，则有</p><script type="math/tex; mode=display">R(t)\ge R(t_L)+R(t_R)</script><blockquote><p>以上公式的推导是在假定所有错误分类为 $i$ 类对象的成本或损失都是一样的，在某些问题中希望能将它们区分出来，例如某一类错误分类的代价将会更大，也就是希望尽可能减少其误分类的概率。因此，引入一组错误分类成本 $c(i\,|\,j)$ 代表将 $j$ 类对象误分类为 $i$ 类对象的代价，它应该满足</p><script type="math/tex; mode=display">{\displaystyle c(i\,|\,j)={\begin{cases}C_i(C_i\ge 0)&i\ne j\\0&i=j\end{cases}}}</script><p>随机一个实例落入节点 $t$ 并被分类为类别 $i$，则估计的预期误分类代价为 </p><script type="math/tex; mode=display">\sum_j c(i\,|\,j)p(j\,|\,t)</script><p>一个自然地节点分配规则是选择 $i$ 来最小化这个表达式，因此，<br>令 $j^\ast(t)=i_0$，当 $i_0$ 最小化 $\displaystyle \sum_j c(i\,|\,j)p(j\,|\,t)$，给定节点 $t$ 定义预期错误分类成本的重新替代估计 $r(t)$ 为</p><script type="math/tex; mode=display">r(t)=\min_i \sum_j c(i\,|\,j)p(j\,|\,t)</script><p>当 $c(i\,|\,j)=1,i\ne j$ 可以发现 </p><script type="math/tex; mode=display">\sum_j c(i\,|\,j)p(j\,|\,t)=1-p(i\,|\,t)</script><p>最小化结果与上面相同</p></blockquote><p>接下来，我们解决第一个问题</p><ol><li>在每个中间节点选择拆分的方法</li></ol><p>在第二节，我们已经定义了一个通用的切分准则，需要确定的只是 $i(t)$ 函数是什么。事实上，CART 分类树是通过基尼指数来作为切分函数的，但基尼指数并不是凭空出现的，也不是唯一可行的。通过实验发现，构建决策树的总体误分类率对分割规则的选择并不敏感，只要在合理的规则类别内，区别是不大的，同时原作者给出了其从开始到最终基尼指数的思考过程，在这里我们从头开始追根溯源。</p><p>从误分类率 $r(t)$ 出发，我们可以发现 $r(t)$ 是可以直接作为衡量节点不纯度的标准，当节点中只有一个类别时，$r(t)$ 为 $0$，当节点中均匀分布时，$r(t)$ 最大为 $1-\frac{1}{n}$。因此最好的分割方式就是最大化</p><script type="math/tex; mode=display">r(t)-P_Lr(t_L)-P_Rr(t_R)</script><p>用误分类率 $r(t)$ 作为不纯函数，存在两个严重的缺陷。</p><p>第一个缺陷，用上式对节点 $t$ 进行切分有可能所有拆分结果都为 $0$。证明如下：</p><script type="math/tex; mode=display">\begin{aligned}    r(t)&=\sum_{j}c(j^*(t)\,|\,j)p(j\,|\,t)\\    &=\sum_{j}c(j^*(t)\,|\,j)p(j,t)p(t)\\    &=\sum_{j}c(j^*(t)\,|\,j)[p(j,t_L)+p(j,t_R)]p(t)\end{aligned}</script><p>让 $p(t)=1$，因此</p><script type="math/tex; mode=display">\begin{aligned}    r(t)&-P_Lr(t_L)-P_Rr(t_R)\\    &=\sum_{j}c(j^*(t)\,|\,j)[p(j,t_L)+p(j,t_R)]-\min_i\sum_jc(i\,|\,j)p(j\,|\,t_L)P_L-\min_i\sum_jc(i\,|\,j)p(j\,|\,t_R)P_R\\    &=\sum_{j}c(j^*(t)\,|\,j)[p(j,t_L)+p(j,t_R)]-\min_i\sum_jc(i\,|\,j)p(j,t_L)-\min_i\sum_jc(i\,|\,j)p(j,t_R)\\    &=\sum_{j}c(j^*(t)\,|\,j)p(j,t_L)-\min_i\sum_jc(i\,|\,j)p(j,t_L) + \sum_{j}c(j^*(t)\,|\,j)p(j,t_R)-\min_i\sum_jc(i\,|\,j)p(j,t_R)\\    &=\sum_{j}c(j^*(t)\,|\,j)p(j,t_L)-\sum_jc(j^*(t_L)\,|\,j)p(j,t_L) + \sum_{j}c(j^*(t)\,|\,j)p(j,t_R)-\sum_jc(j^*(t_R)\,|\,j)p(j,t_R)\\\end{aligned}</script><p>等号的右边是大于 $0$ 的，并且仅当 $j^\ast(t)=j^\ast(t_L)=j^\ast(t_R)$ 时等号成立。</p><blockquote><p>这个式子可以这么理解，$j^\ast(t)$ 是使 $\displaystyle\sum_j c(i\,|\,j)p(j\,|\,t)$ 最小化的特征，当节点 $t$ 被切分为两部分后， $j^\ast(t_L)$ 是使 $\displaystyle\sum_j c(i\,|\,j)p(j\,|\,t_L)$ 最小化的特征，那么 $j^\ast(t)$ 无论是什么都不会使 $\displaystyle \sum_{j}c(j^\ast(t)\,|\,j)p(j,t_L)$ 比 $\displaystyle \sum_jc(j^\ast(t_L)\,|\,j)p(j,t_L)$ 更小。</p></blockquote><p>从上式中可以知道，当父节点与切分后的两个节点的最大占比的类别一样时，无论怎么切分 $r(t)-P_Lr(t_L)-P_Rr(t_R)$ 均为 $0$，即不存在单个或少量的最优拆分点。</p><p>第二个缺陷是很难对决策树进行准确的评价。换句话说，降低错误分类率似乎不是整个决策树生长过程的好的目标和标准。</p><p>举一个简单的例子，父节点 $t$ 的分布为 400（类别1）和 400（类别2），一个切分方式生成两个节点，一个节点分布为 300（类别1）、100（类别2），另一个节点分布为 100（类别1）、300（类别2），其中 200 个实例被分类错误，误分类率为 0.25。另一种切分方式为200（类别1）、400（类别2）和 200（类别1）、0（类别2），误分类率同样为 0.25。</p><p>误分类率对两种切分方式评价相同，不纯度值的减少分别为 $\displaystyle \frac{1}{2}-\frac{1}{2}\ast \frac{1}{4}-\frac{1}{2}\ast \frac{1}{4}=0.25$ 和 $\displaystyle \frac{1}{2}-\frac{6}{8}\ast \frac{2}{6}-\frac{2}{8}\ast 0=0.25$。但对于决策树未来的生长来看，第二种切分方式更为可取，虽然一个节点的误分类率为 $\displaystyle\frac{2}{6}$ ，但另一个节点误分类率为 $0$，这个节点是终端，无需进一步切分。</p><p>综上所述，为了解决误分类率作为不纯度函数的缺陷，需要对不纯度函数进行改进。</p><p>从二分类问题出发，误分类率不纯度函数为</p><script type="math/tex; mode=display">\begin{aligned}    \varphi(p_1,p_2)&=1-\max (p_1,p_2)\\    &=\min (p_1,p_2)\\    &=\min (p_1,1-p_1)\\    &={    \begin{cases}        p_1&0\le p_1\le 0.5\\        1-p_1&0.5<p_1\le 1    \end{cases}    }\end{aligned}</script><p>从上述例子可以想到，为了将两种切分方式区分出来，使第二种切分结果得到的评价更高，就要充分奖励更纯的节点。假设 $p_1&gt;0.5$，那么 $\varphi(p_1)=1-p_1$ 是随着 $p_1$ 线性减少的，为了使纯节点的评价更好，需要使 $\varphi(p_1)$ 随着 $p_1$ 的增加而比线性下降更快。也就是当 $p’’_1&gt;p’_1$ 时，$\varphi’(p’’_1)&lt;\varphi’(p’_1)$，因此要求不纯度函数是严格凸函数。如果 $\varphi$ 在 $[0,1]$ 上有连续的二阶导数，则应该满足 $\varphi’’(p_1)&lt;0,0&lt;p_1&lt;1$。</p><p>将不纯函数需要满足的条件用公式表示</p><ol><li>$\varphi(0)=\varphi(1)=0$</li><li>$\varphi(p_1)=\varphi(1-p_1)$</li><li>$\varphi(1/2)=\text{maximum}$ </li><li>$\varphi’’(p_1)&lt;0,0&lt;p_1&lt;1$</li></ol><p>最简单的满足条件的函数就是二次多项式</p><script type="math/tex; mode=display">\varphi(x)=a+bx+cx^2</script><p>由 1 可以得到 $a=0,b+c=0$，因此</p><script type="math/tex; mode=display">\varphi(x)=b(x-x^2)</script><p>公式 4 要求 $b&gt;0$，不失一般性，取 $b=1$，因此得到不纯度函数</p><script type="math/tex; mode=display">i(t)=p(1\,|\,t)p(2\,|\,t)</script><p>这就是基尼指数的原型，公式简单且易于计算。一个直观的解释，假设节点 $t$ 中的所有 1 类对象被赋予数值 1，而 2 类对象被赋予数值 0，那么 $p(1\,|\,t)$ 和 $p(2\,|\,t)$ 是节点中两个类的比例，则节点中数值的样本方差就是 $p(1\,|\,t)p(2\,|\,t)$。</p><blockquote><p>信息熵公式 $i(t)=-p(1\,|\,t)\log p(1\,|\,t)-p(2\,|\,t)\log p(2\,|\,t)$ 同样满足上述条件。原作者说想不出任何内在的原因为什么同样一个满足条件的函数应该优于任何其他函数，并且测试表明两个函数给出了相似的结果，因此依据简单性原则选择基尼指数。</p></blockquote><p>将二分类问题扩展到多分类问题中，给定节点 $t$ 的类估计概率 $p(j\,|\,t),j=1,\cdots,J$，基尼指数定义为</p><script type="math/tex; mode=display">i(t)=\sum_j\sum_{i\ne j}p(j\,|\,t)p(i\,|\,t)</script><p>同样可以写成</p><script type="math/tex; mode=display">i(t)=\sum_jp(j\,|\,t)(1-p(j\,|\,t))=1-\sum_jp^2(j\,|\,t)</script><p>对于二分类问题则有</p><script type="math/tex; mode=display">\begin{aligned}    i(t)&=2p(1\,|\,t)p(2\,|\,t)\\    &=2p(1-p)\\\end{aligned}</script><blockquote><p>这里与上面的不纯度函数不同，具体在于多了 2，基尼指数是在误差分类率上推导出来的，按理说$\displaystyle i(t)=\min_j\sum_{i\ne j}p(j\,|\,t)p(i\,|\,t)$，但实际上是累加的，基尼指数的最大值是1，而误分类率最大值是0.5，有些不解。如果按下述所说的，那么实际难道是随机选择分类吗？</p></blockquote><p>基尼指数的一种解释方法是，不是使用多数选择的规则对节点 $t$ 中的对象进行分类，而是从节点中随机选择实例将该实例的类别分配给对象，因此将以概率 $p(i\,|\,t)$ 分配为类别 $i$，则误分类的概率就是 $\displaystyle \sum_{i\ne j}p(j\,|\,t)p(i\,|\,t)=p(j\,|\,t)(1-p(j\,|\,t))$，然后再对 $j$ 求和。因此</p><script type="math/tex; mode=display">i(t)=\sum_j\sum_{i\ne j}p(j\,|\,t)p(i\,|\,t)</script><p>另一种解释方法如前所说，在节点 $t$ 中，为所有 $j$ 类对象分配值 $1$，为所有其他对象分配值 $0$。那么这些值的样本方差为$p(j\,|\,t)(1-p(j\,|\,t))$。对所有 $J$ 类重复操作并求和，则结果就是</p><script type="math/tex; mode=display">i(t)=\sum_jp(j\,|\,t)(1-p(j\,|\,t))=1-\sum_jp^2(j\,|\,t)</script><p>根据数据特征值是否为指定值 $a$，将节点 $t$ 分为两部分 $t_L$ 和 $t_R$，即</p><script type="math/tex; mode=display">t_L=\{(\mathbf{x},y)\,|\,\mathbf{x}^{(i)}=a\},t_R=t-t_L</script><p>因此不纯值的减少即为</p><script type="math/tex; mode=display">\triangle i(s,t)=i(t)-p_Li(t_L)-p_Ri(t_R)</script><p>最后一个需要解决的问题</p><ol><li>终止条件</li></ol><p>算法停止计算的条件是结点中的样本个数小于预定阀值，或样本集的基尼指数小于预定阔值(样本基本属于同一类)，或者没有更多特征。</p><p><strong>CART回归树算法</strong></p><ul><li><strong>输入</strong>：训练数据集 $D$</li><li><strong>输出</strong>：CART 分类决策树</li><li><strong>步骤</strong>：<ol><li>从初始节点开始，选取特征 $A$，对该特征可取的每个值 $a$，将数据集 $D$ 分为两部分 $\{D_1\,|\,A=a\}$ 和 $\{D_2\,|\,A\ne a\}$，分别计算基尼指数，选择基尼指数最小的特征值作为该特征的最优切分点。</li><li>对所有特征重复步骤 1，再在其中选取基尼指数最小的特征作为最优特征。根据最优特征及其最优切分点将数据集进行切分，把该节点分为两个子节点 $t_L$ 和 $t_R$，节点中的数据集即为 $D_1$ 和 $D_2$。</li><li>对两个子节点递归地重复步骤 1 和步骤 2。</li><li>当某一节点满足终止条件时，则停止切分，返回父节点，继续遍历其他节点。终止条件为节点中样本个数小于预定阈值，或节点中样本均为一个类别，或样本集的基尼指数小于预定阈值（样本基本属于同一类）。</li><li>当所有节点均遍历之后，即生成 CART 分类决策树，结束算法。</li></ol></li></ul><h3 id="3-2-CART-回归"><a href="#3-2-CART-回归" class="headerlink" title="3.2 CART 回归"></a>3.2 CART 回归</h3><p>回归树同样需要解决上面三个问题</p><p>训练数据集：</p><script type="math/tex; mode=display">D=\{(\mathbf x_1,y_1),(\mathbf x_2,y_2),...,(\mathbf x_N,y_N)\}</script><p>第三个问题最直观也最好解决，假设输出值的函数为 $d$，总的均方误差为</p><script type="math/tex; mode=display">R(d)=\frac{1}{N}\sum_n^N(y_n-d(\mathbf x_n))^2</script><p>对于每个叶子节点，假设输入空间为 $t$，根据最小二乘法，为了使 $R(d)$ 最小，输出值应为</p><script type="math/tex; mode=display">d_t(\mathbf x_n)=\overline{y}_t=\frac{1}{N_t}\sum_{\mathbf x_n\in t}y_n</script><p><strong>即回归树建立完后，每个叶子节点的输出值为其分配样本的均值。</strong></p><p>进一步的，将预测值带入每个节点 $t$，并用 $R(T)$ 取代 $R(d)$</p><script type="math/tex; mode=display">R(T)=\frac{1}{N}\sum_{t\in \widetilde{T}}\sum_{\mathbf x_n\in t}(y_n-\overline{y}_t)^2</script><p>定义</p><script type="math/tex; mode=display">R(t)=\frac{1}{N}\sum_{\mathbf x_n\in t}(y_n-\overline{y}_t)^2</script><blockquote><p>注意这里不是 $N_t$ </p></blockquote><p>因此，$R(T)$ 还可以写为</p><script type="math/tex; mode=display">R(T)=\sum_{t\in \widetilde{T}}R(t)</script><p>对以上表达式一个简单的解释就是，对于每个节点 $t$，$\displaystyle \sum_{\mathbf x_n\in t}(y_n-\overline{y}_t)^2$ 是节点内的误差平方和，对 $t$ 求和给出所有节点的总平方和，再除以 $N$ 给出平均值。</p><p>假定分割前的均方误差为 $R(t)$，分割点为特征向量 $j$，分割值为 $s$，输入空间 $t$ 将被分为两个区域</p><script type="math/tex; mode=display">t_L=\{x\,|\,x^{(j)}\le s\},t_R=\{x\,|\,x^{(j)}\ge s\}</script><p>为了使分割更为有效，将使均方误差减少的尽可能多，因此目标函数为</p><script type="math/tex; mode=display">\triangle R(s,t)=R(t)-R(t_L)-R(t_R)</script><p>与 $s$ 相关的变量只有后两项，因此</p><script type="math/tex; mode=display">\max \triangle R(s,t)=\min [R(t_L)+R(t_R)]</script><p>令 $p(t)=\frac{N_t}{N}$ 表示随机选择输入变量落入节点 $t$ 的概率，定义节点内方差</p><script type="math/tex; mode=display">s^2(t)=\frac{1}{N_t}\sum_{\mathbf x_n\in t}(y_n-\overline{y}_t)^2</script><p>因此可得 $R(t)=s^2(t)p(t)$，并且</p><script type="math/tex; mode=display">R(T)=\sum_{t\in \widetilde{T}}s^2(t)p(t)</script><p>$t$ 的最佳分割也就是使加权方差最小化</p><script type="math/tex; mode=display">\min[p(t_L)s^2(t_L)+p(t_R)s^2(t_R)]</script><p>实际上概率 $p$ 可以带入进去，再乘以 $N$，就得到李航书中的公式</p><script type="math/tex; mode=display">\min_{j,s} \left[\sum_{x_i \in t_L} (y_i-\overline{y}_{t_L})^2+ \sum_{x_i \in t_R} (y_i-\overline{y}_{t_R})^2\right]</script><p>依次选取切分变量 $j$，遍历空间中所有输入点确定最优切分值 $s$，找到最优切分变量和切分值使上式最小。</p><p>对每个区域依次重复上述过程，直到达到终止条件。与 AID 不同，CART 终止条件为节点中的样本个数小于特定阈值（通常为5），或者节点中样本均为一个类别，即该节点为纯节点。</p><p>至此回归的三个问题均已解决，归纳如下</p><p><strong>CART回归算法</strong></p><ul><li><strong>输入</strong>：训练数据集 $D$</li><li><strong>输出</strong>：CART 回归决策树</li><li><strong>步骤</strong>：<ol><li>从初始节点开始，选取特征 $j$，遍历数据集 $D$ 中每个实例特征 $j$ 的取值 $s$，将数据集分为两部分$t_L=\{D_1\,|\,\mathbf x^{(j)}\le s\}$ 和 $t_R=\{D_2\,|\,\mathbf x^{(j)}\ge s\}$，每部分的输出值即为该部分所有实例的平均值 $\overline{y}_t$，依次用 $\displaystyle \sum_{x_i \in t_L} (y_i-\overline{y}_{t_L})^2+ \sum_{x_i \in t_R} (y_i-\overline{y}_{t_R})^2$ 计算分类误差，误差最小的 $s$ 即为最优切分值。</li><li>对所有特征重复步骤 1，再在其中选取分类误差最小的特征作为最优特征。根据最优特征及其最优切分点将数据集进行切分，把该节点分为两个子节点 $t_L$ 和 $t_R$，节点中的数据集即为 $\{D_1\,|\,\mathbf x^{(j)}\le s\}$ 和 $\{D_2\,|\,\mathbf x^{(j)}\ge s\}$</li><li>对两个子节点递归地重复步骤 1 和步骤 2。</li><li>当某一节点满足终止条件时，则停止切分，返回父节点，继续遍历其他节点。终止条件为节点中的样本个数小于特定阈值（通常为5），或者节点中样本均为一个类别，即该节点为纯节点。</li><li>当所有节点均遍历之后，即生成 CART 回归决策树，结束算法。</li></ol></li></ul><h3 id="3-2-CART-剪枝"><a href="#3-2-CART-剪枝" class="headerlink" title="3.2 CART 剪枝"></a>3.2 CART 剪枝</h3><p>随着决策树生成终端节点的增加，训练数据集的误分类率会下降，极端情况一个实例一个节点，则训练集的准确率会达到百分之百。但是，测试集的误分类率会随着决策树的变大先减少后增加，即决策树应当在一定大的时候停止分裂，这时预测效果才是最好的。产生这样的现象的原因是偏差和方差之间的权衡。</p><p>在早期决策树的停止规则是设定阈值 $\beta$，当不纯值的最大减少小于 $\beta$ 则停止分裂节点。这样做的结果通常不会令人满意，主要有两个问题，第一如果 $\beta$ 设的太小则会导致决策树过大，如前所述，导致预测准确率下降；第二，如果 $\beta$ 过大，可能有节点的不纯值减少的很小，但其两个后代节点可能有分裂，且不纯值大幅减少，例如二维空间中一三象限同类，二四象限同类，且分布均匀，第一次无论怎么分割不纯值都不会减少很多，但第二次分割就可以区分出两个类别。</p><p>最终，Breiman 等人认为寻找正确的停止规则本身就是一个错误的方式，并发现了一个更令人满意的方法：</p><ol><li>采用修剪而不是停止。不加约束的使决策树尽可能的生长，然后以正确的方式向上修剪，直到最终修剪回根节点。</li><li>使用更准确的误分类率估计从修剪的子树中选择合适大小的树。</li></ol><p>对于更准确误分类率估计的方法，对于大样本量就是使用独立的测试样本，而对于小样本量，则应采用交叉验证的方法。</p><p>进行修剪的前置条件是要求决策树足够的大，但两个足够大的树结构其实并没有区别，无论是从一个最大的树 $T_{max}$ 开始，还是一个较小但依然足够大的数 $T’_{max}$ 开始，如果从 $T_{max}$ 开始的剪枝过程产生的子树包含在 $T’_{max}$ 中，那么两个树结构将修剪出完全相同的子树。</p><p>如前所述，CART 终止条件为节点中的样本个数小于特定阈值（通常为5，偶尔设置为1），或者节点中样本均为一个类别，即该节点为纯节点，或仅包含相同的测量向量（应该是特征值相同，但类别不同）。这样就可以保证生成一颗足够大的决策树。</p><p>假设 CART 最终生成的决策树为 $T_{max}$，则对于任意一颗子树 $T\preceq T_{max}$ 的误分类率（或者基尼指数）重新带入估计为</p><script type="math/tex; mode=display">\begin{aligned}    R(T)&=\sum_{t\in \widetilde{T}}r(t)p(t)\\    &=\sum_{t\in \widetilde{T}}R(t)\end{aligned}</script><p>定义一个新的损失函数</p><script type="math/tex; mode=display">R_\alpha(T)=R(T)+\alpha|\widetilde{T}|</script><p>其中，$\alpha$ 称为复杂度参数且 $\alpha\ge 0$，$|\widetilde{T}|$ 是子树 $T$ 中终端节点的个数，$R_\alpha(T)$ 是损失值。如果将 $\alpha$ 视为每个终端节点的复杂度成本，那么 $R_\alpha(T)$ 实际上就是在树的错误分类成本上增加复杂度成本惩罚形成的。$\alpha$ 的作用就是权衡训练数据的拟合程度与模型的复杂度。</p><p>现在，对任意取值的 $\alpha$，都可以找到一个子树 $T(\alpha)\preceq T_{max}$ 使损失值 $R_\alpha(T)$ 最小</p><script type="math/tex; mode=display">R_\alpha(T(\alpha))=\min_{T\preceq T_{max}}R_\alpha(T)</script><p>在 $\alpha$ 固定的情况下，$T(\alpha)$ 在损失值 $R_\alpha(T)$ 最小的意义下是最优的，且是唯一的。当 $\alpha$ 较小时，具有大量终端节点的惩罚较小，最优子树 $T(\alpha)$ 较大。极端情况下，$\alpha=0$ ，那么 $T_{max}$ 就是最优的，无需进行剪枝。随着 $\alpha$ 的增大，最优子树 $T(\alpha)$ 将具有更少的终端节点。最后，对于足够大的 $\alpha$，最优子树 $T(\alpha)$ 将仅包含根节点 $\{t_1\}$。</p><blockquote><p>在这里，子树 $T(\alpha)$ 与 $T_{max}$ 是具有相同根节点的树。</p></blockquote><p>尽管 $\alpha$ 是连续取值的，但 $T_{max}$ 的子树的数量是有限的。那么随着 $\alpha$ 增加，剪枝过程会产生一个有限序列的子树 $T_1,T_2,T_3,\dots,\{t_1\}$ 终端节点不断减少。每个子树对应着 $\alpha$ 的一个区间，即在一定区间内，该子树都是最优子树。</p><p>现在的问题在于，如何找到这些最优子树，如果确定 $\alpha$ 去找最优子树，那么 $\alpha$ 的增长步长是难以决定的，太大了容易跳过某些子树，太小则搜索效率太低，毕竟对应一个 $\alpha$ 值，每个子树都需要遍历一遍。同时，在理论上，一个 $\alpha$ 值对应的最优子树是否是唯一的，以及 $T_1,T_2,T_3,\dots$ 序列中，每个子树是否都是前一个子树修剪而成的，即嵌套 $T_1\succ T_2\succ T_3\dots\succ \{t_1\}$ 是否成立。</p><p>Breiman 等人给出了如下的解决办法。</p><p>从 $T_0 = T_{max}$ 开始，对任意节点 $t \in T_0$，以该单节点 $\{t\}$ 为子树的损失函数为</p><script type="math/tex; mode=display">R_\alpha(\{t\})=R(t)+\alpha</script><p>以 $t$ 为根节点的子树 $T_t$ 的损失函数为</p><script type="math/tex; mode=display">R_\alpha(T_t)=R(T_t)+\alpha|\widetilde{T}_t|</script><p>当 $\alpha$ 较小时，子树 $T_t$ 的成本复杂度比单个节点 $\{t\}$ 要小</p><script type="math/tex; mode=display">R_\alpha(T_t)<R_\alpha(\{t\})</script><p>但当 $\alpha$ 达到某个临界值时，两个成本复杂度会变得相等，此时，单节点 $\{t\}$ 比 $T_t$ 的终端节点更少，因此 $\{t\}$ 比 $T_t$ 更可取。求解</p><script type="math/tex; mode=display">R_\alpha(T_t)=R_\alpha(\{t\})</script><p>可以得到 $\alpha$ 的值</p><script type="math/tex; mode=display">\alpha = \frac{R(t)-R(T_t)}{|\widetilde{T}_t|-1}</script><p>定义一个函数 $g(t)$，对 $T_0$ 中的每个点带入计算</p><script type="math/tex; mode=display">{\displaystyle g(t)={    \begin{cases}        \displaystyle\frac{R(t)-R(T_t)}{|\widetilde{T}_t|-1}&t\notin \widetilde{T}_t\\        +\infty&t\in \widetilde{T}_t    \end{cases}    }}</script><p>找到 $t_{min}$ 最小化该函数</p><script type="math/tex; mode=display">g(t_{min})=\min g(t)</script><p>就可以得到剪枝之后的树</p><script type="math/tex; mode=display">T_1=T_0-T_{t_{min}}</script><p>剪枝方法是保留 $t_{min}$ 节点，剔除其所有后代节点。</p><p>同时，将 $g(t_{min})$ 设为 $\alpha_1$。至此，我们就得到了区间 $[\alpha_1,\alpha_2)$ 的最优子树 $T_1$。（区间 $[\alpha_0,\alpha_1)$ 的最优子树就是 $T_0$，也就是 $T_{max}$）</p><p>进一步地，再在 $T_1$ 的基础上得到 $T_2$，直到得到根节点 $\{t_0 \}$。最终我们得到一连串的子树序列 $T_0,T_1,T_2,T_3,\dots,\{t_1\}$ ，且它们之间满足嵌套关系 $T_0\succ T_1\succ T_2\succ T_3\dots\succ \{t_1\}$ 。</p><p>最后，通过独立验证数据集，在$T_0,T_1,T_2,T_3,\dots,\{t_1\}$ 中选取平方误差或基尼指数最小的子树作为最优的子树。</p><p><a href="https://holypython.com/dt/decision-tree-history/">https://holypython.com/dt/decision-tree-history/</a><br><a href="https://www.explorium.ai/blog/the-complete-guide-to-decision-trees/">https://www.explorium.ai/blog/the-complete-guide-to-decision-trees/</a><br><a href="https://en.wikipedia.org/wiki/C4.5_algorithm">https://en.wikipedia.org/wiki/C4.5_algorithm</a><br><a href="https://www.analyticsvidhya.com/blog/2021/05/implement-of-decision-tree-using-chaid/">https://www.analyticsvidhya.com/blog/2021/05/implement-of-decision-tree-using-chaid/</a><br><a href="https://www.cnblogs.com/fushengweixie/p/8039991.html">https://www.cnblogs.com/fushengweixie/p/8039991.html</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;h1 id=&quot;决策树&quot;&gt;&lt;a href=&quot;#决策树&quot; class=&quot;headerlink&quot; title=&quot;决策树&quot;&gt;&lt;/a&gt;决策树&lt;/h1&gt;&lt;h2 id=&quot;1-历史背景&quot;&gt;&lt;a href=&quot;#1-历史背景&quot; class=&quot;head</summary>
      
    
    
    
    <category term="Machine learning" scheme="http://example.com/categories/Machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>4. Naive Bayes Classifier</title>
    <link href="http://example.com/2021/12/05/MachineLearning/4.NaiveBayesClassifier/"/>
    <id>http://example.com/2021/12/05/MachineLearning/4.NaiveBayesClassifier/</id>
    <published>2021-12-04T16:00:00.000Z</published>
    <updated>2022-03-16T08:13:48.121Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><h1 id="朴素贝叶斯分类器"><a href="#朴素贝叶斯分类器" class="headerlink" title="朴素贝叶斯分类器"></a>朴素贝叶斯分类器</h1><p>朴素贝叶斯分类器是基于贝叶斯定理与特征条件独立假设的分类方法。</p><h2 id="1-历史背景"><a href="#1-历史背景" class="headerlink" title="1. 历史背景"></a>1. 历史背景</h2><p>朴素贝叶斯分类器最早的出现时间在 1964 年，由 Mosteller 和 Wallace 第一次应用在文本信息检索领域。</p><p>朴素贝叶斯分类器的核心就是贝叶斯定理，而贝叶斯定理最早由托马斯·贝叶斯所发现。</p><p>贝叶斯于 1701 年至 1761 年间居住在英国，他出生于赫特福德郡，1719 年至 1722 年间就读于爱丁堡大学，学习逻辑学和神学。</p><p>1734 年搬到肯特后，他继承了家族传统并一直担任西恩山教堂的牧师直到 1752 年。</p><p>贝叶斯在 30 多岁时只发表了两篇论文，一篇神学领域的，另一篇是数学领域的，并未产生多大影响。作为长老会牧师，他继续过着简朴的生活。</p><p>直到贝叶斯去世后，他的朋友理查德·普莱斯收集并发表了贝叶斯有关概率的研究内容。普莱斯非常重视贝叶斯的想法，并对遗留手稿进行编辑、纠正、阐述说明，在 1763 年发表文章“An Essay towards solving X Problem in the Doctine of Chances”。可以说，没有普莱斯的工作，贝叶斯理论将不会闻名于世。</p><p>但将贝叶斯理论推广开来，最终成为贝叶斯定理的是法国人拉普拉斯。</p><p>补充一点，理论（theory）和定理（theorem）是不同的。前者是一种可验证但尚待证明（或目前在文明的段时间跨度内无法证明）的解释或陈述，后者是由公理证明的结果（被普遍接受为真理的数学逻辑或定律）。</p><h2 id="2-基本原理"><a href="#2-基本原理" class="headerlink" title="2. 基本原理"></a>2. 基本原理</h2><p>假设训练数据集：</p><script type="math/tex; mode=display">T=\{(\mathbf x_1,y_1),(\mathbf x_2,y_2),...,(\mathbf x_N,y_N)\}</script><p>其中，${\displaystyle \mathbf x_i\in \mathcal{X}\subseteq R^n}$ 表示实例的特征向量，$y\in \mathcal{Y}=\{c_1,c_2,\cdots,c_k\}$ 表示实例的类别，也就是标记（label）。给定实例特征向量$\mathbf x$，输出所属的类 $y$ 。</p><p>从概率的角度来看，$X$ 是定义在输入空间 $\mathcal{X}$ 上的随机向量，$Y$ 是定义在输出空间 $\mathcal{Y}$ 上的随机变量。$P(X,Y)$ 是 $X$ 和 $Y$ 的联合概率分布。因此，训练数据集就是由 $P(X,Y)$ 独立同分布产生的。</p><p>我们再简单回顾一下贝叶斯定理。贝叶斯定理实际是由条件概率和全概率公式得到的。</p><p>从两个事件的条件概率开始，在 $y$ 事件已经发生的情况下，事件 $x$ 发生的概率：</p><script type="math/tex; mode=display">P(x|y)=\frac{P(xy)}{P(y)}</script><p>而在事件 $x$ 已经发生，而 $y$ 事件发生的概率：</p><script type="math/tex; mode=display">P(y|x)=\frac{P(xy)}{P(x)}</script><p>联立两个公式就可以得到：</p><script type="math/tex; mode=display">P(y|x)P(x) = P(x|y)P(y)</script><script type="math/tex; mode=display">P(y|x) = \frac{P(x|y)P(y)}{P(x)}</script><p>在机器学习的场景中，$P(x|y)$ 就是当标签是 $y$ 的情况下，特征是 $x$ 的概率。在现实情况中，$P(x|y)$、$P(y)$、$P(x)$ 是可以求得的，这样就可以计算在某个特征的情况下，属于哪个类标签的概率 $P(y|x)$。这就是贝叶斯方程。</p><p>$P(x)$ 可以通过全概率公式进一步分解</p><script type="math/tex; mode=display">\begin{aligned}    P(x)&= P(xy)+P(x\overline{y})\\    &= P(x|y)P(y)+P(x|\overline{y})P(\overline{y})\\\end{aligned}</script><p>如果标签的空间不仅仅分为 $y$ 和 $\overline{y}$，而是多个分割，那就可以得到更一般的贝叶斯公式</p><p><strong>（贝叶斯公式）</strong>　设 $y_1,y_2,\cdots,y_n$ 是基本空间 $\Omega$ 的一个分割，且它们各自概率 $P(y_1),P(y_2),\cdots,P(y_n)$ 皆已知且为正，又设 $x$ 是 $\Omega$ 中的一个事件，$P(x)&gt;0$，且在诸 $y_i$ 下事件 $x$ 的条件概率 $P(x|y_1),P(x|y_2),\cdots,P(x|y_n)$ 可通过试验等手段获得，则在 $x$ 给定下，事件 $y_k$ 的条件概率为</p><script type="math/tex; mode=display">P(y_k|x)=\frac{P(x|y_k)P(y_k)}{\sum\limits^n_{i=1}P(x|y_i)P(y_i)},k=1,2,\cdots,n</script><p>上述公式是在一个特征 $x$ 的情况下，如果是多个特征，则需要求这多个特征的条件概率分布。</p><script type="math/tex; mode=display">P(X=\mathbf{x}|Y=c_k)=P(X^{(1)}=x^{(1)},\cdots,X^{(n)}=x^{(n)}|Y=c_k),k=1,2,\cdots,K</script><p>条件联合概率分布 $P(X=\mathbf{x}|Y=c_k)$ 有指数级数量的参数，假设 $x^{(j)}$ 可取值有 $N_j$ 个，$j=1,2,\cdots,n$，Y可取值有 $K$ 个，那么参数个数为 $K\prod \limits_{j=1}^nN_j$。如果一个特征空间和类别都是二元的，维度是10，那么需要估计的参数就有2048个，平均每个参数需要100个观测值的话，那就需要20万组数据，随着特征维度的增加，这个值还会随指数增长。</p><p>除此之外，如果数据量不够大的情况下，由于数据的稀疏性，很容易统计到某个参数估计为0的情况，这也是不对的。</p><blockquote><p>也就是不同特征组合情况很多，可能很多组合下都没有样本实例，不能简单认为这种可能性就不存在。</p></blockquote><p>朴素贝叶斯在求解条件概率分布时做了一个非常强的假设，条件独立性（conditional independence）。它的意思是在给定的类别下，不同维度特征的取值之间是相互独立的。朴素贝叶斯也因此得名。</p><script type="math/tex; mode=display">\begin{aligned}    P(X=\mathbf{x}|Y=c_k)&=P(X^{(1)}=x^{(1)},\cdots,X^{(n)}=x^{(n)}|Y=c_k),k=1,2,\cdots,K\\    &= \prod \limits_{j=1}^n P(X^{(j)}=x^{(j)}|Y=c_k)\\\end{aligned}</script><p>朴素贝叶斯法实际上学习到生成数据的机制，所以属于生成模型。条件独立假设等于是说用于分类的特征在类确定的条件下都是条件独立的。这一假设使朴素贝叶斯法变得简单，但有时会牺牲一定的分类准确率。</p><p>将上式带入贝叶斯公式，可以得到后验概率分布 $P(Y=c_k|X=\mathbf{x})$</p><script type="math/tex; mode=display">P(Y=c_k|X=\mathbf{x})=\frac{P(Y=c_k)\prod \limits_{j=1}^n P(X^{(j)}=x^{(j)}|Y=c_k)}{\sum\limits_k P(Y=c_k)\prod \limits_{j=1}^n P(X^{(j)}=x^{(j)}|Y=c_k)},k=1,2,\cdots,n</script><p>朴素贝叶斯实际是一个概率分类器，求出在不同类别下某一特征的概率分布，找到最大后验概率的类别即可。同时上式中的分母实际就是 $P(X=\mathbf{x})$，可以直接求得，并且由于同一特征分母均相同，可以省略分母，就是只比较分子的大小，选出最大的即可。</p><script type="math/tex; mode=display">\begin{aligned}    \hat{y}&=\arg\max_{c_k}P(Y=c_k|X=\mathbf{x})\\    &= \arg\max_{c_k} \frac{P(Y=c_k)\prod \limits_{j=1}^n P(X^{(j)}=x^{(j)}|Y=c_k)}{\sum\limits_k P(Y=c_k)\prod \limits_{j=1}^n P(X^{(j)}=x^{(j)}|Y=c_k)}\\    &= \arg\max_{c_k}  P(Y=c_k)\prod \limits_{j=1}^n P(X^{(j)}=x^{(j)}|Y=c_k)\end{aligned}</script><h2 id="3-最大化含义"><a href="#3-最大化含义" class="headerlink" title="3. 最大化含义"></a>3. 最大化含义</h2><p>朴素贝叶斯法将实例分到后验概率最大的类。这等价于期望风险最小化。假设损失函数：</p><script type="math/tex; mode=display">{\displaystyle L(Y,f(X))={    \begin{cases}        +1&Y\ne f(X)\\        -1&Y=f(X)    \end{cases}    }}</script><p>式中 $f(X)$ 是分类决策函数。这时，期望风险函数为</p><script type="math/tex; mode=display">R_{\exp}(f)=E[L(Y,f(X))]</script><p>期望是对联合分布 $P(X,Y)$ 取的。由此取条件期望</p><script type="math/tex; mode=display">R_{\exp}(f)=E_X\sum^{K}_{k=1}[L(c_k,f(X))]P(c_k|X)</script><p>为了使期望风险最小化，需要对 $X=x$ 逐个极小化，由此得到：</p><script type="math/tex; mode=display">\begin{aligned}    f(x)&=\arg\min_{y\in \mathcal Y}\sum^K_{k=1}L(c_k,y)P(c_k|X=x)\\    &=\arg\min_{y\in \mathcal Y}\sum^K_{k=1}P(y\not ={c_k}|X=x)\\    &=\arg\min_{y\in \mathcal Y}(1-P(y=c_k|X=x))\\    &=\arg\max_{y\in \mathcal Y}P(y=c_k|X=x)\end{aligned}</script><p>这样一来，根据期望风险最小化准则就得到了后验概率最大化准则：</p><script type="math/tex; mode=display">f(x)=\arg\max_{c_k}P(c_k|X=x)</script><h2 id="4-参数估计"><a href="#4-参数估计" class="headerlink" title="4. 参数估计"></a>4. 参数估计</h2><p>以上可以知道要对哪些参数需要估计，那么具体如何对参数进行估计？可以用到极大似然估计或者贝叶斯估计。</p><p>需要估计的参数有先验概率 $P(Y=c_k)$ 、条件概率 $P(X^{(j)}=a_{jl}|Y=c_k)$。</p><p>先验概率 $P(Y=c_k)$ 的极大似然估计：</p><script type="math/tex; mode=display">P(Y=c_k)=\frac{\sum\limits^N_{i=1}I(y_i=c_k)}{N},k=1,2,\cdots,K</script><p>条件概率 $P(X^{(j)}=a_{jl}|Y=c_k)$ 的极大似然估计：</p><script type="math/tex; mode=display">P(X^{(j)}=a_{jl}|Y=c_k)=\frac{\sum\limits^N_{i=1}I(x_i^{(j)}=a_{jl},y_i=c_k)}{\sum\limits^N_{i=1}I(y_i=c_k)}</script><p>式中，$x_i^{(j)}$ 是样本的第 $j$ 个特征，$a_{jl}$ 是 $x^{(j)}$ 可能的取的第 $l$ 个值，$I$ 为指示函数，也就是计数。</p><p>用极大似然估计可能会出现所要估计的概率值为 $0$ 的情况，这会影响到后验概率的计算结果，使分类产生偏差。解决方法是采用贝叶斯估计：</p><script type="math/tex; mode=display">P(X^{(j)}=a_{jl}|Y=c_k)=\frac{\sum\limits^N_{i=1}I(x_i^{(j)}=a_{jl},y_i=c_k)+\lambda}{\sum\limits^N_{i=1}I(y_i=c_k)+S_j\lambda}</script><p>式中，$\lambda \ge 0$ ， $S_j$ 是 $l$ 的最大取值，即 第 $j$ 个特征的可选分类数量。</p><p>上式相当于在随机变量各个取值的频数上赋予一个正数 $\lambda&gt;0$ 。当 $\lambda=0$ 时就是极大似然估计。当 $\lambda=1$ 时，称为拉普拉斯平滑（Laplacian smoothing）。显然，对于任何 $l=1,2,\cdots,S_j$ ， $k=1,2,\cdots,K$ ，都满足</p><script type="math/tex; mode=display">P_\lambda(X^{(j)}=a_{jl}|Y=c_k)>0</script><script type="math/tex; mode=display">\sum^{S_j}_{l=1}P(X^{(j)}=a_{jl}|Y=c_k)=1</script><p>满足概率的公理化定义，表明条件概率 $P_\lambda(X^{(j)}=a_{jl}|Y=c_k)$ 是一种概率分布。</p><p>同样，先验概率的贝叶斯估计是</p><script type="math/tex; mode=display">P_\lambda(Y=c_k)=\frac{\sum\limits^N_{i=1}I(y_i=c_k)+\lambda}{N+K\lambda},k=1,2,\cdots,K</script><h2 id="5-算法流程"><a href="#5-算法流程" class="headerlink" title="5. 算法流程"></a>5. 算法流程</h2><p>以下给出朴素贝叶斯的完整算法。有些时候朴素贝叶斯计算会把后验概率映射到对数空间进行计算，这样做的好处是避免值太小以及加快计算速度（avoid underflow and increase speed）。</p><p><strong>算法输入：</strong> 训练数据集 $T$ 和实例 $\mathbf x$。</p><script type="math/tex; mode=display">T=\{(\mathbf x_1,y_1),(\mathbf x_2,y_2),...,(\mathbf x_N,y_N)\}</script><p>其中 $\mathbf x_i=(x_i^{(1)},x_i^{(2)},\cdots,x_i^{(n)})^T$，$x_i^{(j)}$ 是第 $i$ 个样本的第 $j$ 个特征，$x_i^{(j)}\in\{a_{j1},a_{j2},\cdots,a_{jS_j}\}$，$a_{jl}$ 是第 $j$ 个特征可能取的第 $l$ 个值，$j=1,2,\cdots,n$，$l=1,2,\cdots,S_j$，$y_i\in\{c_1,c_2,\cdots,c_K\}$</p><p><strong>算法输出：</strong> 实例 $\mathbf x$ 的分类。</p><p><strong>算法流程：</strong></p><ol><li>计算先验概率及条件概率<script type="math/tex; mode=display">P(Y=c_k)=\frac{\sum\limits^N_{i=1}I(y_i=c_k)}{N},k=1,2,\cdots,K</script><script type="math/tex; mode=display">P(X^{(j)}=a_{jl}|Y=c_k)=\frac{\sum\limits^N_{i=1}I(x_i^{(j)}=a_{jl},y_i=c_k)}{\sum\limits^N_{i=1}I(y_i=c_k)}</script></li><li>对于给定的实例 $\mathbf{x}=(x^{(1)},x^{(2)},\cdots,x^{(n)})^T$，计算映射到对数空间的后验概率<script type="math/tex; mode=display">P(Y=c_k|X=\mathbf{x})=\log P(Y=c_k)+\sum_{j=1}^n\log P(X^{(j)}=x^{(j)}|Y=c_k),k=1,2,\cdots,K</script></li><li>确定实例 $\mathbf{x}$ 的类别<script type="math/tex; mode=display">y=\arg\max_{c_k} P(Y=c_k|X=\mathbf{x})</script></li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><blockquote><p><a href="https://www.cnblogs.com/bonheur/p/12469873.html">1. 机器学习之朴素贝叶斯详解-cnblog</a><br><a href="https://holypython.com/nbc/naive-bayes-classifier-history/">2. Naive Bayes Classifier History-holy python</a><br><a href="https://www.zhihu.com/question/20138060">3. 朴素贝叶斯分类器和一般的贝叶斯分类器有什么区别？-zhihu</a><br><a href="https://web.stanford.edu/~jurafsky/slp3/4.pdf">4. Naive Bayes and Sentiment Classification - Stanford University</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;h1 id=&quot;朴素贝叶斯分类器&quot;&gt;&lt;a href=&quot;#朴素贝叶斯分类器&quot; class=&quot;headerlink&quot; title=&quot;朴素贝叶斯分类器&quot;&gt;&lt;/a&gt;朴素贝叶斯分类器&lt;/h1&gt;&lt;p&gt;朴素贝叶斯分类器是基于贝叶斯定理与特征条件独</summary>
      
    
    
    
    <category term="Machine learning" scheme="http://example.com/categories/Machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>3. K-Nearest Neighbors</title>
    <link href="http://example.com/2021/11/09/MachineLearning/3.K-NearestNeighbors/"/>
    <id>http://example.com/2021/11/09/MachineLearning/3.K-NearestNeighbors/</id>
    <published>2021-11-08T16:00:00.000Z</published>
    <updated>2022-01-14T07:12:50.159Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><h1 id="k近邻算法"><a href="#k近邻算法" class="headerlink" title="k近邻算法"></a>k近邻算法</h1><p>k近邻算法是“最简单”的监督机器学习算法之一，并且在上个世纪在模式识别领域得到了广泛的研究。虽然现在 kNN 不像以前那样流行，但在实践中仍然被广泛使用。kNN 算法在分类项目中可以作为更复杂模型的预测性能基准。</p><h2 id="1-历史背景"><a href="#1-历史背景" class="headerlink" title="1. 历史背景"></a>1. 历史背景</h2><p>Evelyn Fix(1904-1965) 是一位数学家/统计学家，在伯克利攻读博士学位并继续在那里教授统计学。</p><p>Joseph Lawson Hodges Jr.(1922-2000) 也是伯克利的一名统计学家，并从1944年开始参与与美国空军第二十空军（Twentieth Air Force of USAF）的统计合作。</p><p>这两位天才在1951年为美国空军制作的一份技术分析报告中相遇，在那里他们引入了一种非参数分类方法（判别分析）。他们从未正式发表过这篇论文，可能是因为所涉及的工作性质和保密性，特别是考虑到二战后不久的全球气氛。</p><p>接下来，Thomas Cover 和 Peter Hart 在1967年证明了 kNN 分类的上限错误率<a href="#refer-anchor-1"><sup>[11]</sup></a>。</p><h2 id="2-算法模型"><a href="#2-算法模型" class="headerlink" title="2. 算法模型"></a>2. 算法模型</h2><p>kNN 算法在某些条件下是一个通用的函数逼近器，但潜在的概念相对简单。kNN 是一种监督学习算法，它在训练阶段简单地存储标记的训练样本。因此，kNN 也被称为惰性学习算法，它对训练样本的处理推迟到做预测的时候才进行。  </p><p>假设训练数据集：</p><script type="math/tex; mode=display">T=\{(\mathbf x_,y_1),(\mathbf x_2,y_2),...,(\mathbf x_N,y_N)\}</script><p>其中，${\displaystyle \mathbf x_i\in X\subseteq R^n}$ 表示实例的特征向量，$y\in Y$ 表示实例的类别。给定实例特征向量$\mathbf x$，输出所属的类 $y$ 。</p><p>具体过程：</p><ol><li>通过给定的距离度量，在训练集 $T$ 中找出与 $\mathbf x$ 最近邻的 $k$ 个点，涵盖这 $k$ 个点的 $\mathbf x$ 的领域记作 $N_k(\mathbf x)$</li><li>随后在 $N_k(\mathbf x)$ 中根据分类决策规则决定 $\mathbf x$ 的类别 $y$。</li></ol><p>可以看出，kNN 算法的主要三个要素分别为距离度量、$k$ 值和分类决策规则。</p><h3 id="2-1-距离度量"><a href="#2-1-距离度量" class="headerlink" title="2.1 距离度量"></a>2.1 距离度量</h3><p>距离度量有曼哈顿距离、欧式距离或更一般的闵式距离。</p><p>假设两个特征向量 $\mathbf{x}_i=(x_i^{(1)},x_i^{(2)},…,x_i^{(n)})^T$，$\mathbf{x}_j=(x_j^{(1)},x_j^{(2)},…,x_j^{(n)})^T$，$\mathbf{x}_i,\mathbf{x}_j$ 的 $L_p$距离定义为：</p><script type="math/tex; mode=display">L_p(\mathbf{x}_i,\mathbf{x}_j)=\left(\sum_{l=1}^{n} |x_i^{(l)} - x_j^{(l)}|^p \right)^{\frac{1}{p}}</script><p>当 $p=1$ 时，称为曼哈顿距离，即</p><script type="math/tex; mode=display">L_p(\mathbf{x}_i,\mathbf{x}_j)=\sum_{l=1}^{n} |x_i^{(l)} - x_j^{(l)}|</script><p>当 $p=2$ 时，称为欧式距离，即</p><script type="math/tex; mode=display">L_p(\mathbf{x}_i,\mathbf{x}_j)=\left(\sum_{l=1}^{n} |x_i^{(l)} - x_j^{(l)}|^2 \right)^{\frac{1}{2}}</script><p>当 $p=\infty$，它是各个坐标距离的最大值，即</p><script type="math/tex; mode=display">L_p(\mathbf{x}_i,\mathbf{x}_j)=\max_{l} |x_i^{(l)} - x_j^{(l)}|</script><p>下图给出了二维空间中不同 $p$ 值情况下，与原点距离为 $1$ 的图形。<br><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/MachineLearning/3.K-NearestNeighbor/img/distance.svg" alt="Minkowski distance"></p><p><center>Minkowski distance</center></p><blockquote><p>范数即为特征向量到原点的距离，表征自身的长度</p></blockquote><h3 id="2-2-k-值的选择"><a href="#2-2-k-值的选择" class="headerlink" title="2.2 $k$ 值的选择"></a>2.2 $k$ 值的选择</h3><p>如果选择较小的 $k$ 值，相当于用较小的领域中的训练数据进行预测，近似误差（approximation error）会减少，只有与输入实例较近的训练数据才会对预测结果产生影响。但缺点是估计误差（estimation error）会增大，预测结果对近邻的实例点非常敏感，容易发生过拟合。当 $k$ 为1时，称为最近邻算法，对于输入实例，将与其最近的数据点的类作为预测结果。</p><p>相反的，当使用较大的 $k$ 值时，意味着距离输入实例较远的训练数据也会对预测结果产生影响，使预测产生错误，容易发生欠拟合。当 $k$ 为 $N$ 时，无论输入实例是什么，预测结果都将是训练数据中存在最多的类。</p><p>在应用中，$k$ 一般选取一个比较小的值，采用交叉验证法来选取最优的 $k$ 值。</p><h3 id="2-3-决策规则"><a href="#2-3-决策规则" class="headerlink" title="2.3 决策规则"></a>2.3 决策规则</h3><p>kNN算法在分类问题中决策规则往往是“多数表决”，即由输入实例的 $k$ 个近邻的训练实例中的多数类决定输入实例的类。事实上，多数表决（Majority vote）分为简单多数表决和特定多数表决，是要求满足一半数量以上或者特定数量，而不是占比最多的（Plurality vote），在二分类问题中两者没有区别，而在多分类问题中，不需要某一类投票数过半，超过 $N$ 分之一（$N$ 是分类总数）就可以预测了。</p><p>在回归问题中，可使用“平均法”，即将这 $k$ 个样本的实值输出标记的平均值作为预测结果，还可基于距离远近进行加权平均或加权投票，距离越近的样本权重越大。</p><h2 id="3-模型优化"><a href="#3-模型优化" class="headerlink" title="3. 模型优化"></a>3. 模型优化</h2><p>在考虑 kNN 算法时间复杂度之前，先看一下特征维度对算法的影响。</p><p>假设我们有 $100$ 个训练实例均匀分布在 $(0,1]$ 区间， 它们的间隔为 $0.01$ 单元。假设 $k$ 值为 $3$，就是找到查询点的三个最近邻，期望覆盖特征轴 $0.03$ 的范围。当我们增加一个维度的时候，总体分布在 $1\times 1$ 的区域中，为了覆盖相同的领域，需要 $0.03^{1/2}\approx 0.17$ 范围的坐标轴区域。当维度为 $10$ 的时候，这一数值 $0.03^{1/10}\approx 0.704=70.4\%$。可以发现，在高维中我们需要考虑很大的超体积来找到 $k$ 个近邻样本，这些点与查询点的距离相对较远，变得越来越不“相似”。</p><p>这种现象在机器学习中被称为维度灾难，指的是训练样本大小固定但维度的数量和每个维度的特征值范围不断增加的场景。</p><p>kNN 算法的时间复杂度是 $O(k\ast N\ast m)$ ，$N$ 是训练样本的数量，$m$ 是训练数据集的特征维度，由于 $N\gg m$，时间复杂度简化为 $O(k\ast N)$，可以看出时间复杂度较高，通过数据结构的方法可以将时间进行优化。</p><h3 id="3-1-堆优化"><a href="#3-1-堆优化" class="headerlink" title="3.1 堆优化"></a>3.1 堆优化</h3><p>最暴力的解法是重复 $k$ 次找到 $k$ 个最近邻的训练实例，通过堆优化可以将时间复杂度降到 $O(n\log(k))$。</p><p>随机选取 $k$ 个训练数据集的点来初始化查询点的堆。通过维护一个堆来保存距离查询点最近的 $k$ 个点。通过遍历数据集，如果该点到查询点的距离比堆中保存的最大的距离还要小，则从堆中剔除最远的点并插入当前点。一旦完成了训练数据集的一次迭代，我们就有了一组 $k$ 个最近邻的点。</p><h3 id="3-2-桶优化"><a href="#3-2-桶优化" class="headerlink" title="3.2 桶优化"></a>3.2 桶优化</h3><p>上面的优化方法在每次查询时都还是要对训练数据集进行遍历，如果要快速查询还是需要对数据的存储方式进行优化。</p><p>最简单的方法就是分桶（bucketing），我们将搜索空间划分为相同大小的单元格，类似于网格。</p><blockquote><p>突然发现，工作中要把热力点匹配到距离最近的道路点上，同事就是用的种方法，取热力点所在单元格周围的九个格子中的link，再将取到的道路点和热力点进行匹配。</p></blockquote><h3 id="3-3-KD-树优化"><a href="#3-3-KD-树优化" class="headerlink" title="3.3 KD-树优化"></a>3.3 KD-树优化</h3><p>找到 $k$ 个最近邻的点，本质还是搜索，而提高搜索效率很自然的就会想到二叉树，KD-树就是二叉搜索树（BST）的一种推广。KD-树的时间复杂度平均为 $O(\log(N))$ ，它在笛卡尔坐标系中垂直于特征轴划分搜索空间，这在较低的维度上表现较好，随着特征轴的增多，KD-树将变得低效。</p><p><strong>KD-树构建</strong></p><p>构造KD-树相当于不断用垂直于坐标轴的超平面将k维空间切分，构造一系列的k维超矩形区域。KD-树的每个结点存储一个训练实例点，每一颗子树对应于一个k维超矩形空间。</p><p>二叉搜索树是KD-树在一维空间的特例，任何一个节点相当于一个分割点，左边的比它小，右边的所有节点比它大。在二维空间，一个节点就相当于一条分割线，以此类推，三维空间就是一个面。这种分割方式意味着垂直于一条坐标轴进行分割。分割维度的方式是通过二叉树的深度，第一层根结点分割x轴，第二层分割y轴，以此类推，如果维度遍历完了，下一层又回到x轴，不断重复。</p><p>KD-树构建步骤：</p><ol><li>初始化数据集 $T=\{x_1, x_2,…,x_N\}$，KD树深度 $j=1$，数据集的维度为 $k$。</li><li>选择第 $l=j\bmod k + 1$ 维进行分割，找到数据集中所有实例的第 $l$ 维坐标的中位数，把该点作为切分点。</li><li>（可选）不按照固定顺序选择切割维度，而是选取方差最大特征作为分割特征。</li><li>把切分点记录到KD-树节点上，把数据集中该特征值小于中位数的传递给左子树，把大于中位数的传递给右子树。</li><li>递归执行步骤2-4，直到所有数据都被建立到KD-树节点上。</li></ol><p><strong>KD-树搜索</strong></p><p>KD-树构建完成之后，每次进行查找最近邻时就可以通过KD-树进行查找，类似于二分查找，但由于存在每一层只有一个节点的树形情况，时间复杂度介于 $O(\log(N))$、$O(N)$。相较于二叉搜索树，KD-树多了一个回溯的过程。</p><p>KD-树搜索步骤：</p><ol><li>从根节点起始，根据当前节点的分割维度查看查询点相应的特征值，与节点同一维度的特征值对比，根据大小相应的向左或向右移动。</li><li>当移动到叶子结点时，记录当前节点为“当前最近点”。</li><li>回溯，再从叶子结点返回根节点。</li><li>如果当前节点比当前最近点距离查询点更近，则记录当前节点为“当前最近点”。</li><li>判断查询点到当前节点的父节点所在的将数据集分割为两部分的超平面的距离，如果该距离比到“当前最近点”的距离要小，意味着兄弟节点所在的子树中可能包含更近的点。进入到兄弟节点，重复进行1-4步骤。</li><li>当回溯到根节点时，结束搜索。</li></ol><p>用查询点到“当前最近点”的距离可以形成一个圆或者一个超球体，如果到超平面的距离更小，意味着超球体与另一半空间相交，那么另一半空间可能存在比当前最近点更近的点，否则的话，另一半空间一定不存在更近的点，可以略去搜索。</p><h2 id="4-KD-树实现"><a href="#4-KD-树实现" class="headerlink" title="4. KD-树实现"></a>4. KD-树实现</h2><p><strong>KD-树的构建</strong></p><pre><code class="lang-python">import numpy as npclass Node():    def __init__(self, feature):        self.father = None        self.feature = feature        self.left = None        self.right = None        self.divide = None    @property    def brother(self):        if self == self.father.left:            return self.father.right        else:            return self.father.left    def __str__(self):        return &#39;feature: &#123;&#125;&#39;.format(self.feature)class KDTree():    def __init__(self, points):        self.root = self.build_tree(points)    def build_tree(self, points, dim = 0, father = None):        if not points:            return None        points = sorted(points, key = lambda x: x[dim])        mid = len(points) // 2        curNode = Node(points[mid])        curNode.divide = dim        curNode.father = father        curNode.left  = self.build_tree(points[:mid], (dim + 1) % len(points[0]), curNode)        curNode.right = self.build_tree(points[mid + 1:], (dim + 1) % len(points[0]), curNode)        return curNode    def __str__(self):        def inorder(root, depth = 0):            if not root:                return            ret.append(&#39;depth: &#123;&#125;, &#123;&#125;&#39;.format(str(depth), str(root)))            inorder(root.left, depth + 1)            inorder(root.right, depth + 1)        ret = []        inorder(self.root)        return &#39;\n&#39;.join(ret)pnts = [[2,3], [5,4], [9,6], [4,7], [8,1], [7,2]]tree = KDTree(pnts)print(tree)</code></pre><blockquote><p>depth: 0, feature: [7, 2]<br>depth: 1, feature: [5, 4]<br>depth: 2, feature: [2, 3]<br>depth: 2, feature: [4, 7]<br>depth: 1, feature: [9, 6]<br>depth: 2, feature: [8, 1]</p></blockquote><p><strong>KD-树的搜索</strong></p><pre><code class="lang-python">    def _search(self, root, target):        if not root:            return None        if target[root.divide] &lt; root.feature[root.divide]:            res = self._search(root.left, target)        else:            res = self._search(root.right, target)        return res if res else root    def _get_distance(self, x, y):        return np.sqrt(np.sum((np.array(x) - np.array(y)) ** 2))    def _get_hyper_plane_distance(self, node, target):        return abs(target[node.divide] - node.feature[node.divide])    def nearest_neighbour_search(self, target, root):        nearest_node = self._search(root, target)        nearest_distance = self._get_distance(nearest_node.feature, target)        currnode = nearest_node        while currnode != root:            tempnode = currnode            currnode = currnode.father  #如果currnode没有父节点，它一定等于root，就不会进入这一层            if self._get_distance(currnode.feature, target) &lt; nearest_distance:                nearest_node = currnode                nearest_distance = self._get_distance(currnode.feature, target)            if self._get_hyper_plane_distance(currnode, target) &lt; nearest_distance:                bro_distance, bro_nearest_node = self.nearest_neighbour_search(target, tempnode.brother)                if bro_distance &lt; nearest_distance:                    nearest_node = bro_nearest_node                    nearest_distance = bro_distance        return nearest_distance, nearest_nodepnts = [[2,3], [5,4], [9,6], [4,7], [8,1], [7,2]]tree = KDTree(pnts)dis, node = tree.nearest_neighbour_search([6,2], tree.root)print(dis, node)</code></pre><blockquote><p>1.0 feature: [7, 2]</p></blockquote><h2 id="5-算例"><a href="#5-算例" class="headerlink" title="5. 算例"></a>5. 算例</h2><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><blockquote><p><a href="http://www.atyun.com/37601.html">1. K近邻算法KNN的简述</a><br><a href="https://zhuanlan.zhihu.com/p/110066200">2. KNN（K近邻算法）基本介绍</a><br><a href="https://blog.csdn.net/sinat_30353259/article/details/80901746">3. 机器学习之KNN（k近邻）算法详解</a><br><a href="https://zh.wikipedia.org/wiki/K-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95">4. K-近邻算法-维基百科</a><br><a href="http://www.scholarpedia.org/article/K-nearest_neighbor">5. K-nearest neighbor</a><br><a href="https://zhuanlan.zhihu.com/p/45346117">6. KD Tree的原理及Python实现-李小文</a><br><a href="https://sebastianraschka.com/pdf/lecture-notes/stat479fs18/02_knn_notes.pdf">7. STAT 479: Machine Learning Lecture Notes</a><br><a href="https://zhuanlan.zhihu.com/p/23966698">8. 【数学】kd 树算法之详细篇</a><br><a href="https://zhuanlan.zhihu.com/p/53826008">9. KD树简介</a><br><a href="https://www.cnblogs.com/eyeszjwang/articles/2429382.html">10. k-d tree算法</a><br><a href="https://isl.stanford.edu/~cover/papers/transIT/0021cove.pdf">11. Nearest Neighbor Pattern Classification</a> <div id="refer-anchor-1"></div></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;h1 id=&quot;k近邻算法&quot;&gt;&lt;a href=&quot;#k近邻算法&quot; class=&quot;headerlink&quot; title=&quot;k近邻算法&quot;&gt;&lt;/a&gt;k近邻算法&lt;/h1&gt;&lt;p&gt;k近邻算法是“最简单”的监督机器学习算法之一，并且在上个世纪在模式识</summary>
      
    
    
    
    <category term="Machine learning" scheme="http://example.com/categories/Machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>2. Perceptron</title>
    <link href="http://example.com/2021/10/10/MachineLearning/2.Perceptron/"/>
    <id>http://example.com/2021/10/10/MachineLearning/2.Perceptron/</id>
    <published>2021-10-09T16:00:00.000Z</published>
    <updated>2022-03-28T00:31:09.386Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><h1 id="感知机"><a href="#感知机" class="headerlink" title="感知机"></a>感知机</h1><p>感知机（英语：Perceptron）是弗兰克·罗森布拉特（Frank Rosenblatt）在1957年就职于康奈尔航空实验室（Cornell Aeronautical Laboratory）时所发明的一种人工神经网络。在人工神经网络领域中，感知机也被指为单层的人工神经网络，以区别于较复杂的多层感知机（Multilayer Perceptron）。</p><p>感知机作为一种二分分类的线性分类模型，其输入为实例的特征向量，输出为实例的类别，取 $+1$ 或 $-1$ 二值。感知机学习旨在求出将训练数据进行线性划分的分离超平面，因此，导入基于误分类的损失函数，利用梯度下降法对损失函数进行极小化，求得感知机模型。（单层）感知机可说是最简单的前向人工神经网络形式。尽管结构简单，感知机能够学习并解决相当复杂的问题。感知机主要的本质缺陷是它不能处理线性不可分问题。</p><p>感知机是生物神经细胞的简单抽象。神经细胞结构大致可分为：树突、突触、细胞体及轴突。单个神经细胞可被视为一种只有两种状态的机器——激活时为“是”，而未激活时为“否”。神经细胞的状态取决于从其它的神经细胞收到的输入信号量，及突触的强度（抑制或加强）。当信号量总和超过了某个阈值时，细胞体就会激活，产生电脉冲。电脉冲沿着轴突并通过突触传递到其它神经元。为了模拟神经细胞行为，与之对应的感知机基础概念被提出，如权量（突触）、偏置（阈值）及激活函数（细胞体）。</p><h2 id="1-历史背景"><a href="#1-历史背景" class="headerlink" title="1. 历史背景"></a>1. 历史背景</h2><p>1943年，心理学家沃伦·麦卡洛克和数理逻辑学家沃尔特·皮茨在合作的《A logical calculus of the ideas immanent in nervous activity》论文中提出并给出了人工神经网络的概念及人工神经元的数学模型，从而开创了人工神经网络研究的时代。</p><p>1949年，心理学家唐纳德·赫布在《The Organization of Behavior》论文中描述了神经元学习法则——赫布型学习。</p><p>人工神经网络更进一步被美国神经学家弗兰克·罗森布拉特所发展。他提出了可以模拟人类感知能力的机器，并称之为“感知机”。1957年，在 Cornell 航空实验室中，他成功在 IBM 704 机上完成了感知机的仿真。两年后，他又成功实现了能够识别一些英文字母、基于感知机的神经计算机——Mark1，并于1960年6月23日，展示与众。</p><p>为了“教导”感知机识别图像，弗兰克·罗森布拉特在 Hebb 学习法则的基础上，发展了一种迭代、试错、类似于人类学习过程的学习算法——感知机学习。除了能够识别出现较多次的字母，感知机也能对不同书写方式的字母图像进行概括和归纳。但是，由于本身的局限，感知机除了那些包含在训练集里的图像以外，不能对受干扰（半遮蔽、不同大小、平移、旋转）的字母图像进行可靠的识别。</p><p>首个有关感知机的成果，由弗兰克·罗森布拉特于1958年发表在《The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain》的文章里。1962年，他又出版了《Principles of Neurodynamics: Perceptrons and the theory of brain mechanisms》一书，向大众深入解释感知机的理论知识及背景假设。此书介绍了一些重要的概念及定理证明，例如感知机收敛定理。</p><p>虽然最初被认为有着良好的发展潜能，但感知机最终被证明不能处理诸多的模式识别问题。1969年，马文·明斯基和西摩尔·派普特在《Perceptrons》书中，仔细分析了以感知机为代表的单层神经网络系统的功能及局限，证明感知机不能解决简单的异或（XOR）等线性不可分问题，但弗兰克·罗森布拉特和马文·明斯基和西摩尔·派普特等人在当时已经了解到多层神经网络能够解决线性不可分的问题。</p><p>由于弗兰克·罗森布拉特等人没能够及时推广感知机学习算法到多层神经网络上，又由于《Perceptrons》在研究领域中的巨大影响，及人们对书中论点的误解，造成了人工神经领域发展的长年停滞及低潮，直到人们认识到多层感知机没有单层感知机固有的缺陷及反向传播算法在80年代的提出，才有所恢复。1987年，书中的错误得到了校正，并更名再版为《Perceptrons - Expanded Edition》。</p><p>近年，在Freund及Schapire（1998）使用核技巧改进感知机学习算法之后，愈来愈多的人对感知机学习算法产生兴趣。后来的研究表明除了二元分类，感知机也能应用在较复杂、被称为structured learning类型的任务上（Collins, 2002），又或使用在分布式计算环境中的大规模机器学习问题上（McDonald, Hall and Mann, 2011）。</p><h2 id="2-感知机模型"><a href="#2-感知机模型" class="headerlink" title="2. 感知机模型"></a>2. 感知机模型</h2><p>假设输入空间（特征空间）是 ${\displaystyle X\subseteq R^n}$ （代表n维的实数空间），输出空间是 $Y=\{+1, -1\}$ 。输入 $\mathbf x\in X$ 表示实例的特征向量，对应于输入空间（特征空间）的点；输出 $\mathbf y\in Y$ 表示实例的类别。把矩阵上的输入 $x$ 映射到输出值$f(x)$上。</p><script type="math/tex; mode=display">{\displaystyle f(x)=\text{sign}(\mathbf w\cdot \mathbf x+b)}</script><p>$\mathbf w$ 是实数的表示权重的向量，与 $\mathbf x$ 维度相同，$\mathbf {w\cdot x}$ 是点积，$b$ 是偏置，一个不依赖于任何输入值的常数。偏置可以认为是激励函数的偏移量，或者给神经元一个基础活跃等级。sign是符号函数：</p><script type="math/tex; mode=display">{\displaystyle \text{sign}(n)={    \begin{cases}        +1&n\geq 0\\        -1&n<0    \end{cases}    }}</script><p>映射函数同样可以写成如下的表述形式：</p><script type="math/tex; mode=display">{\displaystyle y=\text{sign}(\sum_{i=1}^{n}{ {w}_{i}{x}_{i}+b})=\text{sign}( {W}^{T} {X})}</script><h2 id="3-感知机学习算法"><a href="#3-感知机学习算法" class="headerlink" title="3. 感知机学习算法"></a>3. 感知机学习算法</h2><p>假设训练数据是线性可分的，感知机的学习目标是寻找模型参数 $w,b$ 来将数据集正负实例点通过超平面进行区分，因此需要一个损失函数并得到损失函数的极小值。</p><blockquote><p>我们很自然的想到能否还用最小二乘法中的损失函数呢？</p><script type="math/tex; mode=display">Q=min{||\text{sign}(\mathbf w\cdot \mathbf x+b)-y||}^2</script><p>感知机与最小二乘法的不同之处在于 $y$ 即映射函数 $f(x)$ 的不同。最小二乘法是线性函数，用于线性回归；而感知机是sign函数，用于分类。很明显sign是个阶跃的不连续函数，这就导致损失函数同样是不连续的，就无法通过微分来得到极值点。</p></blockquote><p>损失函数还有一个自然选择是误分类点的总数，但同样这种损失函数也不是参数 $\mathbf w,b$ 的连续可导函数。损失函数的另一个选择是误分类点到超平面的距离，通过距离公式可以得到任一点 $x_0$ 到超平面 $S$ 的距离：</p><script type="math/tex; mode=display">\frac{1}{\left\|\mathbf w\right\|}|\mathbf w\cdot x_0+b|</script><blockquote><p>在一维空间，一个线性函数如 $Ax+By+C=0$ 的法向量就是 $(A,B)$，点到直线距离相当于该点到法向量投影的长度，假设点 $Q$ 坐标 $(x_0,y_0)$，直线上任意一点坐标 $P(x,y)$</p><script type="math/tex; mode=display">d=|PQ|\cdot \cos\theta</script><script type="math/tex; mode=display">d=\frac{|n|\cdot|PQ|\cdot \cos\theta}{|n|}</script><script type="math/tex; mode=display">d=\frac{\vec{n}\cdot \vec{PQ}}{|n|}</script><p>同理可以推广到多维空间</p><p><strong>记住一点：</strong></p><p><strong>权重向量是超平面的法线</strong></p></blockquote><p>对于误分类的数据$(\mathbf x_i,y_i)$，当$\mathbf w\cdot \mathbf x_i+b&gt;0$，$y_i=-1$；反之，$y_i=+1$，因此任一点$x_i$到超平面$S$的距离是</p><script type="math/tex; mode=display">-\frac{1}{\left\|\mathbf w\right\|}y_i(\mathbf w\cdot \mathbf x_i+b)</script><p>不考虑$\displaystyle \frac{1}{\left|\mathbf w\right|}$， 感知机学习的损失函数定义为</p><script type="math/tex; mode=display">L(\mathbf w,b)=-\sum_{\mathbf x_i\in M}y_i(\mathbf w\cdot \mathbf x_i+b)</script><p>$M$ 是误分类点的集合。</p><p>显然，损失函数是非负的。如果没有误分类点，损失函数值是0。而且，误分类点越少，误分类点离超平面越近，损失函数值就越小。注意，在分类正确时，损失函数为0。因此，给定训练数据$T$，损失函数$L(\mathbf w,b)$ 是$\mathbf w,b$ 的连续可导函数。</p><p>感知机学习算法采用随机梯度下降法。首先选取一个超平面$\mathbf w_0,b_0$，然后用梯度下降法不断地极小化目标函数。极小化过程不是一次使$M$中所有误分类点的梯度下降，而是一次随机选取一个误分类点使其梯度下降。</p><p>损失函数 $L(\mathbf w,b)$ 的梯度：</p><script type="math/tex; mode=display">\bigtriangledown_\mathbf w L(\mathbf w,b)=-\sum_{\mathbf x_i\in M}y_i\mathbf x_i</script><script type="math/tex; mode=display">\bigtriangledown_b L(\mathbf w,b)=-\sum_{x_i\in M}y_i</script><p>随机选取一个误分类点$(x_i,y_i)$，对 $\mathbf w,b$ 进行更新：</p><script type="math/tex; mode=display">\mathbf w_{t+1}\leftarrow \mathbf w_{t}+ \eta y_i\mathbf x_i</script><script type="math/tex; mode=display">b_{t+1}\leftarrow b_{t}+ \eta y_i</script><p>式中$\eta$是步长，在统计学习中称为学习率。通过迭代可以期待损失函数不断减少。</p><p>为了便于推导，可以将偏置 $b$ 并入权重向量 $\mathbf w$，将 $d$ 维的输入转为 $(d+1)$ 维的输入，同时传入到对应的 $(d+1)$ 维感知机当中。</p><script type="math/tex; mode=display">\mathbf w\cdot x+b=[\mathbf w,b]\cdot [x,1]=\mathbf w\cdot \mathbf x</script><p>总结算法流程如下:</p><ol><li>初始化参数，迭代次数$t=1$并且$\mathbf w_1$为全是0的权重向量。</li><li>对每一个样本 $\mathbf x_t$ 预测，$f(x_t)=+1$ if $\mathbf w_t\cdot \mathbf x_t\ge 0$ else $-1$</li><li>对一个分类错误的样本 $y_i(\mathbf w_t \cdot \mathbf x_i) \le 0$ 进行学习，$\mathbf w_{t+1}\leftarrow \mathbf w_{t}+ \eta y_i\mathbf x_i$ </li><li>$t\leftarrow t + 1$</li></ol><h2 id="4-算法收敛性"><a href="#4-算法收敛性" class="headerlink" title="4. 算法收敛性"></a>4. 算法收敛性</h2><p>在证明感知机算法收敛性之前，先证明两个假设。</p><p><strong>定理1(线性可分性).</strong> 对于线性可分的数据集，存在 $\mathbf w^\ast$ 满足 $\left|\mathbf w^\ast \right|=1$ ,使得超平面 $\mathbf w^\ast \cdot \mathbf x=0$ 能够将所有训练数据完全正确分开，且存在 $\gamma &gt; 0$，对于所有 $i\in \{1,2,…,n\}$，</p><script type="math/tex; mode=display">y_i(\mathbf w^\ast \cdot \mathbf x_i) > \gamma</script><p>证明：由于训练数据集是线性可分的，则存在超平面将数据集完全分开，取此超平面为 $\mathbf w^\ast \cdot \mathbf x=0$，通过向量单位化使 $\left|\mathbf w^*\ast \right|=1$ 。由于对于有限的数据集 $i\in \{1,2,…,n\}$，均有</p><script type="math/tex; mode=display">y_i(\mathbf w^\ast \cdot \mathbf x_i) > 0</script><p>所以存在</p><script type="math/tex; mode=display">y_i(\mathbf w^\ast \cdot \mathbf x_i) \ge \min_i(y_i(\mathbf w^\ast \cdot \mathbf x_i)) > \gamma</script><p><strong>定理2(有界性).</strong> 存在 ${R \in R^n}$ 对于有限的数据集 $i\in \{1,2,…,n\}$，均有</p><script type="math/tex; mode=display">\left\|\mathbf x_i \right\| \le R</script><p><strong>定理3(收敛性).</strong> 感知机学习算法最多迭代次数（之后得到一个分离超平面），满足不等式：</p><script type="math/tex; mode=display">k\le \left( \frac{R}{\gamma}\right) ^2</script><p>证明：我们需要推导出 $k$ 的上边界是上式，策略是根据 $k$ 推导出 $\mathbf w_{k+1}$ 长度的上下限并将它们关联起来。</p><p>注意到 $\mathbf w_{1}=0$，对于 $k\ge1$ ，如果 $\mathbf{x}_j$ 是迭代 $k$ 期间的误分类点，由定理1，我们有:</p><script type="math/tex; mode=display">\begin{aligned}    \mathbf w_{k+1} \cdot \mathbf{w}^*&=(\mathbf{w}_k + \eta y_j\mathbf{x}_j)\cdot \mathbf{w}^* \\    &=\mathbf w_{k} \cdot \mathbf{w}^* + \eta y_j(\mathbf{x}_j \cdot \mathbf{w}^*) \\    &>\mathbf w_{k} \cdot \mathbf{w}^* + \eta \gamma \\    &>\mathbf w_{k-1} \cdot \mathbf{w}^* + 2\eta \gamma \\    &>k\eta \gamma\end{aligned}</script><p>由于</p><script type="math/tex; mode=display">\begin{aligned}\mathbf w_{k+1} \cdot \mathbf{w}^* &= \left\|\mathbf w_{k+1} \right\|\left\|\mathbf w^* \right\| \cos \theta \\&\le \left\|\mathbf w_{k+1} \right\| \left\|\mathbf w^* \right\| = \left\|\mathbf w_{k+1} \right\|\end{aligned}</script><p>我们有：</p><script type="math/tex; mode=display">\left\|\mathbf w_{k+1} \right\| >k\eta \gamma</script><p>至此我们得到了$\left|\mathbf w_{k+1} \right|$的下界，为了得到上界，我们推断：</p><script type="math/tex; mode=display">\begin{aligned}\left\|\mathbf w_{k+1} \right\|^2 &=\left\|\mathbf w_{k}+\eta y_j\mathbf{x}_j \right\|^2 \\&=\left\|\mathbf w_{k}\right\|^2 + \left\| \eta y_j\mathbf{x}_j \right\|^2 + 2(\mathbf w_{k}\cdot \mathbf x_{j})\eta y_j \\&=\left\|\mathbf w_{k}\right\|^2 + \left\| \eta \mathbf{x}_j \right\|^2 + 2(\mathbf w_{k}\cdot \mathbf x_{j})\eta y_j \\&\le \left\|\mathbf w_{k}\right\|^2 + \left\| \eta \mathbf{x}_j \right\|^2 \\&\le \left\|\mathbf w_{k}\right\|^2 + \eta ^2R^2 \\&\le \left\|\mathbf w_{k-1}\right\|^2 + 2\eta ^2R^2 \\&\le k\eta ^2R^2 \\\end{aligned}</script><p>联立$\left|\mathbf w_{k+1} \right|$的上下界，我们得到不等式：</p><script type="math/tex; mode=display">(k\eta \gamma)^2<\left\|\mathbf w_{k+1} \right\|\le k\eta ^2R^2</script><p>最终得到：</p><script type="math/tex; mode=display">k\le \left( \frac{R}{\gamma}\right) ^2</script><h2 id="5-算例"><a href="#5-算例" class="headerlink" title="5. 算例"></a>5. 算例</h2><pre><code class="lang-python">import numpy as npimport matplotlib.pyplot as pltclass Perceptron(object):    def __init__(self, train_data, lable):        self.data_pos = train_data        self.train_data = np.array(train_data)        self.lable = np.array(lable)        self.length = len(train_data)        self.train_data = np.append(self.train_data, np.ones((self.length, 1)), axis = 1)        self.weights = np.zeros(len(train_data[0]) + 1)        self.eta = 0.2    def sign(self, x):        return 1 if x &gt;= 0 else -1    def predict(self, input_data):        return self.sign(np.sum(self.weights * input_data))    def train(self):        for idx in range(100):            flag = True            for i, inpute_data in enumerate(self.train_data):                if self.lable[i] * self.predict(inpute_data) &lt;= 0:                    self.vectorA = self.eta * self.lable[i] * inpute_data                    Y = lambda x,y: (- y[2] - (x) * y[0]) / y[1]                    plt.cla()                    plt.figure().set_size_inches(6, 6)                    plt.style.use(&#39;Solarize_Light2&#39;)                    plt.subplots_adjust(top = 0.93, bottom = 0.07, right = 0.93, left = 0.07, hspace = 0, wspace = 0)                    plt.ylim((-5, 10))                    plt.xlim((-5, 10))                                   plt.scatter([x[0] for x in self.data_pos[:5]], [x[1] for x in self.data_pos[:5]], c=&#39;r&#39;)                    plt.scatter([x[0] for x in self.data_pos[5:]], [x[1] for x in self.data_pos[5:]], c=&#39;b&#39;)                    plt.scatter(inpute_data[0], inpute_data[1], c=&#39;k&#39;)                    plt.scatter(0, -self.weights[2] / self.weights[1], c=&#39;k&#39;)                    plt.plot([0, self.vectorA[0]], [Y(0, self.weights), Y(0, self.weights) + self.vectorA[1]])                    plt.plot([0, self.weights[0]], [Y(0, self.weights), Y(0, self.weights) + self.weights[1]])                    plt.plot([-5,10], [Y(-5, self.weights), Y(10, self.weights)])                    self.vectorB = self.weights + self.vectorA                    plt.plot([0, self.vectorB[0]], [Y(0, self.weights), Y(0, self.weights) + self.vectorB[1]])                    plt.plot([-5,10], [Y(-5, self.vectorB), Y(10, self.vectorB)])                    print(self.weights, self.eta * self.lable[i] * inpute_data, self.predict(inpute_data), self.lable[i])                    plt.savefig(&#39;img_&#123;&#125;_&#123;&#125;.jpg&#39;.format(idx,i))                    flag = False                    self.weights = self.vectorB                    # plt.pause(0.5)            if flag:                return self.weightstrain_data = [[2, 3], [1, 4], [3, 5], [2, 6], [4, 5], [3, 1], [4, 3], [6, 2], [2, 1]]lable = [1, 1, 1, 1, 1, -1, -1, -1 ,-1]plt.ion()ptron = Perceptron(train_data, lable)ptron.train()</code></pre><p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/MachineLearning/2.Perceptron/img/perceptron_iteration.gif" alt="感知机迭代过程图"></p><center>感知机迭代过程图</center><h2 id="6-思考"><a href="#6-思考" class="headerlink" title="6. 思考"></a>6. 思考</h2><p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/MachineLearning/2.Perceptron/img/img_1_0.jpg" alt="感知机迭代过程图1"></p><center>感知机迭代过程图1</center><p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/MachineLearning/2.Perceptron/img/img_1_6.jpg" alt="感知机迭代过程图2"></p><center>感知机迭代过程图2</center><p>对两个过程图进行进一步分析，以下为自己理解：</p><ol><li><p>不同的系数可能绘制出同一条直线或同一个平面，例如 $[1,1,1]$ 和 $[-1,-1,-1]$ 都可以表示直线 $x+y+1=0$，但权重代表的法向量的方向相反。如上述图中垂直于直线的即为法向量也就是 $w$，当实例点与法向量点乘之后再加上位移量 $b$，就可以用来判断该点在直线的哪一侧。原理有很多中解释，其中一种就是$\mathbf w\cdot\mathbf x$ 的正负决定了它们之间的夹角大小是否超过 $90$ 度，确定相对角度之后还不足以判断该点相对于直线的位置，</p></li><li><p>误分类的点改变的是直线法向量的方向和大小以及 $b$ 即直线的位置，误分类点也可以理解为一个向量，乘以衰减系数后作用在法向量上，作用可能是吸引或者排斥。当分类为正时为吸引作用，如图1，反之则为排斥作用如图2。前提都是错误的分类数据，即正分类点不会和法向量处在同一侧，因此正分类点希望法向量“转过来”，同理，负分类点会与法向量处于同一侧，它希望法向量“转过去”。</p></li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><blockquote><p><a href="https://zh.wikipedia.org/wiki/%E6%84%9F%E7%9F%A5%E5%99%A8">1. 感知器-维基百科</a><br><a href="https://www.cnblogs.com/graphics/archive/2010/07/10/1774809.html">2. 点到平面的距离公式</a><br><a href="https://blog.csdn.net/song430/article/details/88718602">3. 用Python实现单层感知机</a><br><a href="https://www.cnblogs.com/xym4869/p/11282469.html">4. 深度学习基础——感知机</a><br><a href="https://www.cnblogs.com/huangyc/p/9706575.html">5. 感知机原理</a><br><a href="https://github.com/SmallVagetable/machine_learning_python">6. machine_learning_python</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;h1 id=&quot;感知机&quot;&gt;&lt;a href=&quot;#感知机&quot; class=&quot;headerlink&quot; title=&quot;感知机&quot;&gt;&lt;/a&gt;感知机&lt;/h1&gt;&lt;p&gt;感知机（英语：Perceptron）是弗兰克·罗森布拉特（Frank Rosenbl</summary>
      
    
    
    
    <category term="Machine learning" scheme="http://example.com/categories/Machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>1. Least Sqaure</title>
    <link href="http://example.com/2021/09/18/MachineLearning/1.LeastSqaure/"/>
    <id>http://example.com/2021/09/18/MachineLearning/1.LeastSqaure/</id>
    <published>2021-09-17T16:00:00.000Z</published>
    <updated>2022-02-22T07:06:39.351Z</updated>
    
    <content type="html"><![CDATA[<span id="more"></span><h1 id="最小二乘法"><a href="#最小二乘法" class="headerlink" title="最小二乘法"></a>最小二乘法</h1><p>最小二乘法又称为最小平方法，是一种数学优化建模方法。它通过最小化误差的平方和寻找数据的最佳函数匹配。最小二乘法是对线性方程组，即方程个数比未知数更多的方程组，以回归分析求得近似解的标准方法。在这个解决方案中，最小二乘法演算为每一方程的结果中，将残差平方和的总和最小化。</p><p>最小二乘法分为线性和非线性，取决于所有未知数中的残差是否为线性。线性的最小二乘问题发生在统计回归分析中，具有一个封闭形式的解决方案。非线性的问题通常由迭代细致化来解决，每次迭代中，系统由线性近似，因此这两种情况下核心演算是相同的。</p><h2 id="1-历史背景"><a href="#1-历史背景" class="headerlink" title="1. 历史背景"></a>1. 历史背景</h2><p>最小二乘法发展于天文学和大地测量学领域，科学家和数学家尝试为大航海探索时期的海洋航行挑战提供解决方案。准确描述天体的行为是船舰在大海洋上航行的关键，水手不能再依靠陆上目标导航作航行。</p><p>这个方法是在十八世纪期间一些进步的集大成：</p><ul><li>不同观测值的组合是真实值的最佳估计；多次观测会减少误差而不是增加，也许在1722年由Roger Cotes首先阐明。</li><li>在相同条件下采取的不同观察结果，与只尝试记录一次最精确的观察结果是对立的。这个方法被称为平均值方法。托马斯·马耶尔（Tobias Mayer）在1750年研究月球的天平动时，特别使用这种方法，而拉普拉斯（Pierre-Simon Laplace）在1788年他的工作成果中以此解释木星和土星的运动差异。</li><li>在不同条件下进行的不同观测值组合。该方法被称为最小绝对偏差法，出现在Roger Joseph Boscovich在1757年他对地球形体的著名作品，而拉普拉斯在1799年也表示了同样的问题。</li><li>评定对误差达到最小的解决方案标准，拉普拉斯指明了误差的概率密度的数学形式，并定义了误差最小化的估计方法。为此，拉普拉斯使用了一双边对称的指数分布，现在称为拉普拉斯分布作为误差分布的模型，并将绝对偏差之和作为估计误差。他认为这是他最简单的假设，他期待得出算术平均值而成为最佳的估计。可相反地，他的估计是后验中位数。</li></ul><p>1801年，意大利天文学家朱塞普·皮亚齐发现了第一颗小行星谷神星。经过40天的追踪观测后，由于谷神星运行至太阳背后，使得皮亚齐失去了谷神星的位置。随后全世界的科学家利用皮亚齐的观测数据开始寻找谷神星，但是根据大多数人计算的结果来寻找谷神星都没有结果。当年24岁的高斯也计算了谷神星的轨道。奥地利天文学家海因里希·奥伯斯根据高斯计算出来的轨道重新发现了谷神星。</p><p>高斯使用的最小二乘法的方法发表于1809年他的著作《天体运动论》中，而法国科学家勒让德于1806年独立发现“最小二乘法”，但因不为世人所知而没没无闻。两人曾为谁最早创立最小二乘法原理发生争执。</p><p>1829年，高斯提供了最小二乘法的优化效果强于其他方法的证明，见高斯-马尔可夫定理。</p><h2 id="2-问题引入"><a href="#2-问题引入" class="headerlink" title="2. 问题引入"></a>2. 问题引入</h2><p>如果对同一目标例如手机宽度通过尺子测量长度，通过同一尺子不同测量员或者不同尺子同一测量员得到的结果都有可能不同，那么如何通过所有的测量结果来得到准确的真值呢？</p><p>假设测量结果分别为72.5mm、72.2mm、72.9mm、72.4mm、72.5mm。</p><p>只要做过初中物理实验的都知道，通常都会对同一实验进行多次重复操作，把得到的结果进行平均求和，最后的结果作为实验的准确结果</p><script type="math/tex; mode=display">\overline{x}=\frac{72.5+72.2+72.9+72.4+72.5}{5}=72.5</script><p>直觉告诉我们取平均值是正确的，那么这么做得依据是什么呢？</p><p>再比如，我们知道营业税税收总额与社会商品零售总额有关，假设收集了如下数据</p><div class="table-container"><table><thead><tr><th style="text-align:center">序号</th><th style="text-align:center">社会商品零售总额</th><th style="text-align:center">营业税税收总额</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">142.08</td><td style="text-align:center">3.93</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">177.30</td><td style="text-align:center">5.96</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">204.68</td><td style="text-align:center">7.85</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">242.88</td><td style="text-align:center">9.82</td></tr><tr><td style="text-align:center">5</td><td style="text-align:center">316.24</td><td style="text-align:center">12.50</td></tr><tr><td style="text-align:center">6</td><td style="text-align:center">341.99</td><td style="text-align:center">15.55</td></tr><tr><td style="text-align:center">7</td><td style="text-align:center">332.69</td><td style="text-align:center">15.79</td></tr><tr><td style="text-align:center">8</td><td style="text-align:center">389.29</td><td style="text-align:center">16.39</td></tr><tr><td style="text-align:center">9</td><td style="text-align:center">453.40</td><td style="text-align:center">18.45</td></tr></tbody></table></div><p>如何通过这些已有数据在给定社会商品零售总额的情况下预测营业税税收总额呢？</p><h2 id="3-问题求解"><a href="#3-问题求解" class="headerlink" title="3. 问题求解"></a>3. 问题求解</h2><p>我们将第一个问题用公式进行描述，假设要猜测的真实值是$y$，测量值则为$y_i$，上述求平均公式则为：</p><script type="math/tex; mode=display">\displaystyle{\frac{\sum y_i}{n}}=y</script><p>公式可以转化为：</p><script type="math/tex; mode=display">\sum (y_i-y)=0</script><p>满足上式时，误差平方和取得最小值，因为导数为0</p><script type="math/tex; mode=display">\frac{d}{dy}S_{\epsilon^2}=\frac{d}{dy}\sum (y_i-y)^2=0</script><p>至此，我们明白求平均的实质是希望预测值与测量值的误差平方和最小，最小二乘法也就是最小平方法，二乘实际上也是日语中平方的意思。</p><p>第二个问题中，社会商品零售总额$x$是自变量，其值是可以控制或精确测量的，是非随机变量；营业税税收总额$y$是因变量，取值不能事先确定，是随机变量。假定它们具有线性相关关系，$y_i$的表达式：</p><script type="math/tex; mode=display">{\displaystyle{y_i=\beta_0+\beta_1x_i+\epsilon_i}}</script><p>其中$\beta_0,\beta_1$称为回归系数，由于它们未知，因此需要从收集到的数据出发进行估计，记为$\hat{\beta_0},\hat{\beta_1}$。</p><p>通过最小二乘法估计回归系数，目标是希望偏差平方和$Q$达到最小：</p><script type="math/tex; mode=display">Q(\beta_0,\beta_1)=\sum_{i=1}^n (y_i-\beta_0-\beta_1x_i)^2</script><p>由于$Q$是一个非负二次型，因此可通过令$Q$对$\beta_0,\beta_1$的偏导为零来求：</p><script type="math/tex; mode=display">\begin{cases}    {\displaystyle \frac{\partial Q}{\partial \beta_0}=-2\sum(y_i-\beta_0-\beta_1x_i)} \\    \\    {\displaystyle \frac{\partial Q}{\partial \beta_1}=-2\sum(y_i-\beta_0-\beta_1x_i)x_i}\end{cases}</script><p>经整理有</p><script type="math/tex; mode=display">\begin{cases}    {\displaystyle n\beta_0 + n\overline{x}\cdot\beta_1}=n\overline{y} \\    \\    {\displaystyle n\overline{x}\beta_0+\sum{x_i^2\beta_1}=\sum{x_iy_i}}\end{cases}</script><p>两式合并后</p><script type="math/tex; mode=display">\begin{aligned}    \left( \sum{x_i^2} -n\overline{x}^2 \right)\beta_1&=\sum{x_iy_i}-n\overline{x}\overline{y}\\    \left( \sum{x_i^2} + \sum{\overline{x}^2}-2n\overline{x}^2 \right)\beta_1&=\sum{x_iy_i}-\sum{x_i}\overline{y}\\    \left( \sum{x_i^2} + \sum{\overline{x}^2}-2\sum{x_i}\overline{x} \right)\beta_1&=\sum{x_iy_i}-\sum{x_i}\overline{y}+n\overline{x}\overline{y}-n\overline{x}\overline{y}\\    \left( \sum{(x_i -\overline{x})^2} \right)\beta_1&=\sum{x_iy_i}-\sum{x_i}\overline{y}+\sum{\overline{x}y_i}-\sum\overline{x}\overline{y}\\    \left( \sum{(x_i -\overline{x})^2} \right)\beta_1&=\sum{(x_i-\overline{x})(y_i-\overline{y})}\\    \beta_1&=\frac{cov(x,y)}{Var(x)}\end{aligned}</script><p>实际上 $\beta_1$ 是 $x$ 与 $y$ 的协方差与 $x$ 方差的商</p><p>通过以上的方法可以推导出更多特征的求解方法，通过高斯消元法可以求解多元线性方程组，求得解析解。</p><p>同时也可以通过矩阵法求解，将多个方程看做一个整体进行求解。</p><script type="math/tex; mode=display">{\displaystyle     {\begin{pmatrix}    1& x_{11}& \cdots & x_{1j}\cdots & x_{1q}\\    1& x_{21}& \cdots & x_{2j}\cdots & x_{2q}\\    \vdots \\    1& x_{i1}& \cdots & x_{ij}\cdots & x_{iq}\\    \vdots \\    1& x_{n1}& \cdots & x_{nj}\cdots & x_{nq}    \end{pmatrix}}     \cdot     {\begin{pmatrix}\beta_{0}\\\beta_{1}\\\beta_{2}\\\vdots \\\beta_{j}\\\vdots \\\beta_{q}\end{pmatrix}}=    {\begin{pmatrix}y_{1}\\y_{2}\\\vdots \\y_{i}\\\vdots \\y_{n}\end{pmatrix}}}</script><p>矩阵表达式为：</p><script type="math/tex; mode=display">    Q=min{||Xw-y||}^2</script><p>求 $w$ 的最小二乘估计，即求 $\frac{\partial Q}{\partial w}$ 的零点。其中 $y$ 是 $m\times 1$ 列向量，$X$ 是 $m\times n$ 矩阵，$w$是$n\times 1$列向量，$Q$是标量。</p><p>将向量模平方改写成向量与自身的内积：</p><script type="math/tex; mode=display">Q=(Xw-y)^T(Xw-y)</script><p>求微分：</p><script type="math/tex; mode=display">\begin{aligned}    dQ&=(Xdw)^T(Xw-y)+(Xw-y)^T(Xdw)\\    &=2(Xw-y)^T(Xdw)\end{aligned}</script><p>这里是因为两个向量的内积满足$u^Tv=v^Tu$。</p><p>导数与微分的关系式</p><script type="math/tex; mode=display">dQ={\frac{\partial Q}{\partial w}}^Tdw</script><p>得到</p><script type="math/tex; mode=display">{\frac{\partial Q}{\partial w}}=(2(Xw-y)^TX)^T=2X^T(Xw-y)=0</script><p>求解可得</p><script type="math/tex; mode=display">\begin{aligned}    X^TXw&=X^Ty\\    w&=(X^TX)^{-1}X^Ty\end{aligned}</script><h2 id="4-思考"><a href="#4-思考" class="headerlink" title="4. 思考"></a>4. 思考</h2><p>为什么损失函数不用误差的绝对值？</p><script type="math/tex; mode=display">Q(\beta_0,\beta_1)=\sum_{i=1}^n |y_i-\beta_0-\beta_1x_i|</script><p>网上有人说是太麻烦，但我觉得主要原因是<strong>绝对值函数连续但不可导</strong>，无法通过求导数的为零的极值点，也无法通过梯度下降法进行求解。</p><p>一元一次线性回归拟合的是条直线，多元一次线性回归拟合的是个平面，一元多次线性回归拟合的是条曲线，多元多次线性回归应该拟合的是个曲面，就是不知道具体拟合的函数是什么样子了，我猜可能$\beta_0+\beta_1x_1+\beta_2x_1^2+\beta_3x_2+\beta_2x_2^2$。下面算例中的都是一元线性回归。</p><h2 id="5-算例"><a href="#5-算例" class="headerlink" title="5. 算例"></a>5. 算例</h2><pre><code class="lang-python">import matplotlib.pyplot as pltimport numpy as np%matplotlib inlinex = np.array([142.08, 177.30, 204.68, 242.88, 316.24, 332.69, 341.99, 389.29, 453.40])y = np.array([3.93,   5.96,   7.85,   9.82,   12.50,  15.79,  15.55,  16.39,  18.45])# 通过代数方法求解# numpy的协方差默认是样本方差，无偏的，自由度n-1，因此要加bias = Truebeta_0 = np.cov(x, y, bias = True)[0,1] / np.var(x)  beta_1 = np.sum(y) / 9 - np.sum(x) / 9 * beta_0print(beta_0, beta_1)# 通过公式计算，与上面相同# a = np.sum(np.multiply(x, y)) - np.sum(x) * np.sum(y) / 9# b = np.sum(np.multiply(x, x)) - np.sum(x) * np.sum(x) / 9</code></pre><blockquote><p>计算结果<br>0.04867773628668675 -2.2609874555936926</p></blockquote><pre><code class="lang-python"># 通过矩阵法实现最小二乘法def least_sqaure(X, Y):    return (X.T * X).I * X.T * Y# 生成多项式def polynomial(x, n):    X = np.mat(x)    X = np.append(np.ones((1, 9)), X, axis = 0)    for i in range(1, n):        X = np.append(X, np.mat(x**(i + 1)), axis = 0)    return X.TY = np.mat(y).T# 线性拟合X = polynomial(x, 1)beta = np.array(least_sqaure(X, Y)).flatten()[::-1]print(&#39;beta:&#39;, beta)plt.subplot(221)plt.plot(x, y, &#39;bo&#39;, label=&#39;noise&#39;)plt.plot(x, np.poly1d(beta)(x), label=&#39;fitted curve&#39;)# 二次拟合X = polynomial(x, 2)beta = np.array(least_sqaure(X, Y)).flatten()[::-1]print(&#39;beta:&#39;, beta)plt.subplot(222)plt.plot(x, y, &#39;bo&#39;, label=&#39;noise&#39;)plt.plot(x, np.poly1d(beta)(x), label=&#39;fitted curve&#39;)# 三次拟合X = polynomial(x, 3)beta = np.array(least_sqaure(X, Y)).flatten()[::-1]print(&#39;beta:&#39;, beta)plt.subplot(223)plt.plot(x, y, &#39;bo&#39;, label=&#39;noise&#39;)plt.plot(x, np.poly1d(beta)(x), label=&#39;fitted curve&#39;)# 六次拟合X = polynomial(x, 6)beta = np.array(least_sqaure(X, Y)).flatten()[::-1]print(&#39;beta:&#39;, beta)plt.subplot(224)plt.plot(x, y, &#39;bo&#39;, label=&#39;noise&#39;)plt.plot(x, np.poly1d(beta)(x), label=&#39;fitted curve&#39;)plt.show()</code></pre><p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/MachineLearning/1.LeastSquare/img/least_square.png" alt="最小二乘法拟合图"></p><center>最小二乘法拟合图</center><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><blockquote><p><a href="https://www.zhihu.com/question/37031188">1. 最小二乘法的本质是什么？</a><br><a href="https://www.cnblogs.com/pinard/p/5976811.html">2. 最小二乘法小结-刘建平Pinard</a><br><a href="https://zh.wikipedia.org/wiki/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95">3. 最小二乘法-维基百科</a><br><a href="https://zhuanlan.zhihu.com/p/84133777">4. 最小二乘法详细推导 - 知乎</a><br><a href="https://zhuanlan.zhihu.com/p/89373759">5. 最小二乘法 - 知乎</a><br><a href="https://zhuanlan.zhihu.com/p/87582571">6. 矩阵形式下的最小二乘法推导 - 知乎</a><br><a href="https://zhuanlan.zhihu.com/p/24709748">7. 矩阵求导术（上）- 知乎</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;span id=&quot;more&quot;&gt;&lt;/span&gt;
&lt;h1 id=&quot;最小二乘法&quot;&gt;&lt;a href=&quot;#最小二乘法&quot; class=&quot;headerlink&quot; title=&quot;最小二乘法&quot;&gt;&lt;/a&gt;最小二乘法&lt;/h1&gt;&lt;p&gt;最小二乘法又称为最小平方法，是一种数学优化建模方法。它通过最小化误差</summary>
      
    
    
    
    <category term="Machine learning" scheme="http://example.com/categories/Machine-learning/"/>
    
    
  </entry>
  
</feed>
