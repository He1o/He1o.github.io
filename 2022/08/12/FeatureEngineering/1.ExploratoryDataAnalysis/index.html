<!DOCTYPE html>
<html lang="zh-Hans">

<!-- Head tag -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="icon" href="https://s3.bmp.ovh/imgs/2022/01/7b8dab551214d77c.png" type="image/png">
    <link rel="shortcut icon" href="https://s3.bmp.ovh/imgs/2022/01/7b8dab551214d77c.png" type="image/png">


    <!--Description-->
    
        <meta name="description" content="Exploratory Data Analysis1. 概述[1]数据科学家使用探索性数据分析 (Exploratory Data Analysis) 来分析和调查数据集并总结其主要特征，通常采用数据可视化方法。它有助于确定如何最好地操纵数据源以获得所需的答案，从而使数据科学家更容易发现模式、发现异">
    

    <!--Author-->
    
        <meta name="author" content="He1o">
    

    <!-- Title -->
    
    <title>1. EDA | He1o</title>

    <!-- Bootstrap Core CSS -->
    <link href="//cdn.jsdelivr.net/npm/bootstrap@3.3.6/dist/css/bootstrap.min.css" rel="stylesheet">
    <!-- <link href="//cdn.bootcss.com/bootstrap/3.3.6/css/bootstrap.min.css" rel="stylesheet"> -->

    <!-- Custom CSS -->
    
<link rel="stylesheet" href="/css/style.css">


    <!-- Custom Fonts -->
    <link href="//cdn.jsdelivr.net/npm/font-awesome@4.5.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <!-- <link href="//cdn.bootcss.com/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet" type="text/css"> -->
    <link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Noto+Serif:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

    <!-- jQuery -->
    <script src="//cdn.bootcss.com/jquery/2.2.1/jquery.min.js"></script>
    <!-- Bootstrap -->
    <script src="//cdn.jsdelivr.net/npm/bootstrap@3.3.6/dist/js/bootstrap.min.js"></script>
    <!-- <script src="//cdn.bootcss.com/bootstrap/3.3.6/js/bootstrap.min.js"></script> -->

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
    <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->
    <link rel="stylesheet"
        href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/styles/base16/tomorrow.min.css">
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/highlight.min.js"></script>
    <script >hljs.initHighlightingOnLoad();</script> 
<meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="He1o" type="application/atom+xml">
</head>

<body>

    <!-- Content -->
    <section class="article-container">
    <!-- Back Home -->
    <a class="nav-back" href="/">
    <!-- <i class="fa fa-puzzle-piece"></i> -->
    <!-- <svg t="1641282408158" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1990" width="20" height="20"><path d="M176.01639 524.791207s-27.260759-212.767201-4.060113-284.047483c13.969751-42.859491 33.233691-71.366668 76.352339-70.132591 70.490473 2.048568 194.416477 193.34283 194.416476 193.34283L192.478976 529.591766z" fill="#C95065" p-id="1991"></path><path d="M193.490919 536.329826l-23.077238-6.812104-0.518312-3.998409c-1.12301-8.737265-27.149692-214.914494-3.813298-286.688408 12.291406-37.614664 31.654073-75.846367 82.399315-74.390156 31.098738 0.900876 74.229726 34.430746 128.220592 99.664051a1175.61869 1175.61869 0 0 1 71.206238 96.480133l3.319666 5.121419z m-11.847138-16.36386l9.872615 2.900081L434.172939 362.201574c-9.058125-13.574846-35.380985-52.078046-67.047398-90.309749-50.86865-61.444689-92.012775-94.332839-119.002037-95.122648-34.788628-0.999602-54.521518 17.462188-70.342384 65.887366-20.781855 63.86348 0.296178 247.839666 3.862661 277.309423z" fill="#A5213D" p-id="1992"></path><path d="M847.971269 524.791207s27.310122-212.705497 4.072454-283.985779c-13.982091-42.921195-33.184328-71.428372-76.37702-70.194295-70.502814 2.048568-194.428818 193.34283-194.428818 193.34283l250.270798 165.637803z" fill="#C95065" p-id="1993"></path><path d="M830.49674 536.329826l-2.394109-1.591959-255.330513-169.068537 3.319666-5.121419a1170.361522 1170.361522 0 0 1 71.23092-96.443111c53.990865-65.233306 97.134194-98.726153 128.220591-99.664051 50.782265-1.468552 70.132591 36.775492 82.399316 74.390156 23.447461 71.773913-2.690288 277.951143-3.813298 286.688408l-0.505972 3.998409z m-240.644998-174.128252l242.668884 160.664473 9.872616-2.900081c3.566482-29.482097 24.681538-213.495306 3.825638-277.309423-15.783844-48.425178-35.504393-66.886969-70.342384-65.887366-26.989262 0.789809-68.133386 33.677959-119.002037 95.122648-31.666414 38.231703-58.001615 76.747243-67.059739 90.309749z" fill="#A5213D" p-id="1994"></path><path d="M867.198187 614.434554c0 82.880605-27.75439 129.787869-99.108716 181.656122-63.530279 46.166817-165.144172 57.347554-258.045483 57.347554-102.428384 0-210.101594-18.794991-275.199151-73.612688-60.358702-50.794606-78.018342-101.453463-78.018343-176.806199 0-156.666064 155.987322-316.910951 353.242176-316.910952s357.129518 171.660099 357.129517 328.326163z" fill="#C95065" p-id="1995"></path><path d="M510.043988 859.596274c-56.384974 0-107.870663-5.516324-153.025537-16.413223-52.559336-12.686311-95.023922-32.40686-126.172024-58.630994-30.691493-25.841571-50.831628-51.744845-63.357508-81.523121-11.501597-27.347144-16.857491-59.124625-16.857491-99.96023 0-78.610699 38.120636-159.418056 104.600359-221.714258a375.801102 375.801102 0 0 1 114.041048-73.415236 367.471082 367.471082 0 0 1 140.771153-27.951842 353.63708 353.63708 0 0 1 141.474577 29.728913 387.426106 387.426106 0 0 1 115.36151 77.364281c32.554949 31.493643 59.470166 68.602336 77.82089 107.364692 18.757969 39.490461 28.667607 81.066512 28.667607 120.038661 0 42.970558-7.490847 76.512769-23.570869 105.451872-15.72214 28.383769-39.79898 53.373826-78.080046 81.189921-54.175976 39.330031-139.771551 58.470564-261.673669 58.470564z m0-567.317498c-91.408077 0-178.941152 34.81331-246.371115 98.03507-63.999229 59.963797-100.700676 137.50085-100.700676 212.705497 0 78.980922 20.547381 125.567326 75.821686 172.092025s151.606349 72.144136 271.250105 72.144137c119.199489 0 202.388614-18.363064 254.417296-56.162841 71.292623-51.83123 96.566518-98.047411 96.566519-176.65811 0-74.599949-38.404474-156.271159-102.724562-218.431613-69.145329-66.91165-157.307784-103.724165-248.259253-103.724165z" fill="#A5213D" p-id="1996"></path><path d="M323.673693 613.89156m-86.237295 0a86.237295 86.237295 0 1 0 172.474589 0 86.237295 86.237295 0 1 0-172.474589 0Z" fill="#FFFFFF" p-id="1997"></path><path d="M337.828555 595.42977m-44.61188 0a44.61188 44.61188 0 1 0 89.22376 0 44.61188 44.61188 0 1 0-89.22376 0Z" fill="#42393B" p-id="1998"></path><path d="M342.024416 587.605722m-16.265133 0a16.265134 16.265134 0 1 0 32.530267 0 16.265134 16.265134 0 1 0-32.530267 0Z" fill="#FFFFFF" p-id="1999"></path><path d="M700.326307 613.89156m-86.237294 0a86.237295 86.237295 0 1 0 172.474589 0 86.237295 86.237295 0 1 0-172.474589 0Z" fill="#FFFFFF" p-id="2000"></path><path d="M686.159104 595.42977m-44.61188 0a44.61188 44.61188 0 1 0 89.223761 0 44.61188 44.61188 0 1 0-89.223761 0Z" fill="#42393B" p-id="2001"></path><path d="M681.975584 587.605722m-16.265134 0a16.265134 16.265134 0 1 0 32.530267 0 16.265134 16.265134 0 1 0-32.530267 0Z" fill="#FFFFFF" p-id="2002"></path></svg> -->
    <svg t="1641282544096" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2285" width="25" height="25"><path d="M169.607158 516.323824s-28.478046-221.801895-4.233745-296.130495c14.56717-44.705255 34.654938-74.457285 79.617564-73.144695 73.505014 2.136175 202.717873 201.598311 202.717873 201.598311L186.77377 521.394023z" fill="#647471" p-id="2286"></path><path d="M187.828989 528.407369l-24.064141-7.103426-0.540478-4.156533c-1.171036-9.123784-28.375097-224.105361-3.976374-298.948702 12.791314-39.223264 33.033503-79.064217 85.92314-77.584336 32.428683 0.939402 77.404177 35.903184 133.703974 103.926207a1228.416518 1228.416518 0 0 1 74.251389 100.606127l3.461633 5.353307z m-12.353784-17.063664l10.29482 3.024104 253.033805-167.535326c-9.445497-14.155377-36.894061-54.292307-69.914695-94.171865-53.04406-64.072385-95.947722-98.367004-124.091186-99.177722-36.263503-1.068088-56.853143 18.208963-73.350592 68.705055-21.670596 66.633222 0.308845 258.374243 4.027848 289.155754z" fill="#283330" p-id="2287"></path><path d="M870.298339 516.323824s28.478046-221.801895 4.246613-296.130495c-14.580039-44.705255-34.667806-74.457285-79.617564-73.144695-73.517883 2.136175-202.74361 201.598311-202.743609 201.598311l260.947947 172.747078z" fill="#647471" p-id="2288"></path><path d="M852.076507 528.407369l-2.496493-1.647171-266.249781-176.298791 3.461634-5.353306A1222.908789 1222.908789 0 0 1 661.030387 244.501973c56.299796-68.023023 101.288159-102.948199 133.703973-103.926207 52.966848-1.518486 73.131827 38.361073 85.923141 77.584337 24.450197 74.843341-2.805338 289.824918-3.976374 298.948701l-0.52761 4.156534z m-250.936235-181.574886l253.046673 167.535326 10.29482-3.024104c3.719004-30.730037 25.73705-222.625481 3.989243-289.155754-16.510317-50.470355-37.099957-69.773142-73.311986-68.705055-28.143464 0.810717-71.047126 35.105336-124.091186 99.177722-33.05924 39.879559-60.520673 80.042225-69.96617 94.171865z" fill="#283330" p-id="2289"></path><path d="M892.380727 609.852263c0 86.425013-28.928444 135.338276-103.334255 189.424687-66.247166 48.15402-172.219469 59.800035-269.093724 59.800035-106.744414 0-219.086636-19.598763-286.968105-76.747883-62.939955-52.966848-81.367683-105.792143-81.367683-184.380224 0-163.353055 162.658155-330.463719 368.348657-330.46372s372.41511 179.01405 372.41511 342.367105z" fill="#647471" p-id="2290"></path><path d="M519.952748 865.511247c-58.79629 0-112.483776-5.765099-159.569708-17.128006-54.807048-13.215975-99.087642-33.792746-131.55493-61.138362-32.01689-26.933823-53.005454-53.944856-66.079876-85.009475-11.993465-28.503783-17.578405-61.653103-17.578405-104.235052 0-81.959635 39.763742-166.235605 109.073617-231.18305a391.975268 391.975268 0 0 1 118.930907-76.567723 383.121723 383.121723 0 0 1 146.778395-29.147209 368.760449 368.760449 0 0 1 147.52477 31.051751 404.290447 404.290447 0 0 1 120.294971 80.685651c33.960037 32.827607 62.02629 71.523261 81.161786 111.956166 19.547289 41.243622 29.880715 84.520472 29.880715 125.159274 0 44.808204-7.798326 79.784854-24.566014 109.961545-16.407369 29.597607-41.513861 55.65637-81.419157 84.674894-56.505693 40.960515-145.761781 60.919597-272.877071 60.919596z m0-591.591826c-95.304295 0-186.593611 36.314977-256.907231 102.24043-66.73617 62.528162-105.007163 143.368236-105.007163 221.789027 0 82.358559 21.426094 130.950109 79.077086 179.451579s158.089828 75.242265 282.837308 75.242265c124.30995 0 211.043808-19.161234 265.310378-58.564656 74.341468-54.047805 100.683339-102.24043 100.683339-184.225803 0-77.790233-40.033981-162.954131-107.117601-227.77289-72.102345-69.760273-164.035087-108.159952-258.876116-108.159952z" fill="#283330" p-id="2291"></path><path d="M516.735617 428.328851a117.42529 117.42529 0 0 1-5.031593-23.536532 199.886797 199.886797 0 0 1 0-47.060195 116.614573 116.614573 0 0 1 5.05733-23.536532 117.541106 117.541106 0 0 1 5.070199 23.536532 201.739865 201.739865 0 0 1 0 47.060195 117.463895 117.463895 0 0 1-5.095936 23.536532zM586.959158 381.255787a48.2441 48.2441 0 0 1 0.527609 15.056174 71.343102 71.343102 0 0 1-2.959761 13.949481 70.468042 70.468042 0 0 1-5.559202 13.113027 47.201749 47.201749 0 0 1-9.110916 12.006334 47.870913 47.870913 0 0 1-0.540478-15.056174 73.350592 73.350592 0 0 1 8.583306-27.023903 47.973861 47.973861 0 0 1 9.059442-12.044939zM615.591625 452.495941a67.482545 67.482545 0 0 1 7.721115-16.201473 105.521904 105.521904 0 0 1 10.436374-13.769322 103.37286 103.37286 0 0 1 12.495338-11.916254 65.758162 65.758162 0 0 1 15.236333-9.471234 65.809636 65.809636 0 0 1-7.721115 16.201473 101.494056 101.494056 0 0 1-10.449242 13.756453 104.453817 104.453817 0 0 1-12.508206 11.916254 66.517405 66.517405 0 0 1-15.210597 9.484103zM661.467917 469.611079a25.865735 25.865735 0 0 1 4.169402-9.741473 32.338603 32.338603 0 0 1 14.605775-11.581673 25.634102 25.634102 0 0 1 10.449243-1.82733 25.608365 25.608365 0 0 1-4.156534 9.76721 31.566492 31.566492 0 0 1-6.434262 6.858924 32.171312 32.171312 0 0 1-8.158645 4.70988 25.73705 25.73705 0 0 1-10.474979 1.814462zM690.692337 501.846734a38.682786 38.682786 0 0 1 10.397768-8.493227 55.21884 55.21884 0 0 1 11.478724-5.018724 54.356649 54.356649 0 0 1 12.30231-2.367809 38.20665 38.20665 0 0 1 13.383266 1.158167 38.258125 38.258125 0 0 1-10.397768 8.506095 53.790434 53.790434 0 0 1-11.478725 4.992988 54.61402 54.61402 0 0 1-12.302309 2.35494 38.747128 38.747128 0 0 1-13.383266-1.13243zM446.524945 381.255787a48.282705 48.282705 0 0 1 9.085179 12.019202 73.003142 73.003142 0 0 1 8.570437 27.023903 47.124538 47.124538 0 0 1-0.540478 15.056174 47.446251 47.446251 0 0 1-9.098047-12.006334 70.519516 70.519516 0 0 1-5.546334-13.08729 72.269636 72.269636 0 0 1-2.946892-13.949481 48.2441 48.2441 0 0 1 0.476135-15.056174zM417.879609 452.495941a66.144218 66.144218 0 0 1-15.210597-9.484103 108.095609 108.095609 0 0 1-22.957448-25.672707 66.73617 66.73617 0 0 1-7.721115-16.201473 65.629477 65.629477 0 0 1 15.236334 9.471234 107.272024 107.272024 0 0 1 22.918842 25.73705 66.517405 66.517405 0 0 1 7.733984 16.149999zM372.003318 469.611079a25.64697 25.64697 0 0 1-10.436374-1.827331 31.720914 31.720914 0 0 1-8.158645-4.70988 31.257647 31.257647 0 0 1-6.434262-6.858923 25.608365 25.608365 0 0 1-4.156534-9.767211 25.634102 25.634102 0 0 1 10.449242 1.827331 32.171312 32.171312 0 0 1 14.592908 11.581672 25.659839 25.659839 0 0 1 4.143665 9.754342zM342.791766 501.846734a38.772866 38.772866 0 0 1-13.383266 1.13243 54.472466 54.472466 0 0 1-12.30231-2.35494 53.507327 53.507327 0 0 1-11.478724-4.992988 38.258125 38.258125 0 0 1-10.397768-8.506095 38.20665 38.20665 0 0 1 13.383266-1.158167 54.485334 54.485334 0 0 1 12.30231 2.367809 55.514816 55.514816 0 0 1 11.478724 5.018724 38.682786 38.682786 0 0 1 10.397768 8.493227zM520.467489 722.168749a73.955413 73.955413 0 0 1 5.031594 18.196094 118.519114 118.519114 0 0 1 1.3898 18.157488 116.884812 116.884812 0 0 1-1.364063 18.183226 72.835851 72.835851 0 0 1-5.057331 18.183226 72.333978 72.333978 0 0 1-5.070198-18.183226 116.884812 116.884812 0 0 1-1.364064-18.183226 118.519114 118.519114 0 0 1 1.389801-18.183225 73.440672 73.440672 0 0 1 5.044461-18.170357zM590.678161 758.522331a33.535376 33.535376 0 0 1-9.007967-8.5447 45.374419 45.374419 0 0 1-5.572071-9.934501 44.821072 44.821072 0 0 1-3.011235-10.976852 33.213663 33.213663 0 0 1 0.411792-12.366652 33.007766 33.007766 0 0 1 9.007968 8.5447 44.422148 44.422148 0 0 1 5.546334 9.921633 45.631789 45.631789 0 0 1 2.998366 10.98972 33.728404 33.728404 0 0 1-0.373187 12.366652zM619.323498 703.496519a53.584538 53.584538 0 0 1 14.760198 6.125418 81.277603 81.277603 0 0 1 12.379521 8.866413 79.656169 79.656169 0 0 1 10.565059 10.963984 52.490713 52.490713 0 0 1 8.158644 13.730716 53.082665 53.082665 0 0 1-14.773066-6.086813 80.428281 80.428281 0 0 1-12.366653-8.89215 81.30334 81.30334 0 0 1-10.565059-10.976852 53.700354 53.700354 0 0 1-8.158644-13.730716zM665.18692 690.319149a23.240556 23.240556 0 0 1 9.94737 0.167291 27.023902 27.023902 0 0 1 8.02996 3.294343 26.547767 26.547767 0 0 1 6.588684 5.649282 22.777289 22.777289 0 0 1 4.658406 8.789203 23.047528 23.047528 0 0 1-9.947369-0.154423 27.358484 27.358484 0 0 1-14.605776-9.007967 23.008923 23.008923 0 0 1-4.671275-8.737729zM694.41134 665.36708a37.486013 37.486013 0 0 1 13.061553-2.058964 52.760952 52.760952 0 0 1 12.21223 1.492749 51.911629 51.911629 0 0 1 11.581673 4.169402 37.524619 37.524619 0 0 1 10.719481 7.721115 37.537487 37.537487 0 0 1-13.074421 2.071832 52.001709 52.001709 0 0 1-12.199362-1.505617 53.314299 53.314299 0 0 1-11.581672-4.195139 37.666172 37.666172 0 0 1-10.719482-7.695378zM450.282555 758.522331a33.728404 33.728404 0 0 1-0.386056-12.366652 45.631789 45.631789 0 0 1 2.998366-10.98972 44.936889 44.936889 0 0 1 5.546334-9.921633 33.007766 33.007766 0 0 1 9.007968-8.5447 33.213663 33.213663 0 0 1 0.411793 12.366652 44.821072 44.821072 0 0 1-3.011235 10.976852 45.374419 45.374419 0 0 1-5.572071 9.934501 33.535376 33.535376 0 0 1-8.995099 8.5447zM421.598613 703.496519a53.700354 53.700354 0 0 1-8.158645 13.730716 81.30334 81.30334 0 0 1-10.565059 10.976852 80.428281 80.428281 0 0 1-12.366653 8.89215 53.082665 53.082665 0 0 1-14.773066 6.086813 52.851032 52.851032 0 0 1 8.158645-13.743585 79.656169 79.656169 0 0 1 10.565059-10.963983 81.277603 81.277603 0 0 1 12.379521-8.866414 53.584538 53.584538 0 0 1 14.760198-6.112549zM375.73519 690.319149a23.008923 23.008923 0 0 1-4.671275 8.776334 27.229799 27.229799 0 0 1-14.605775 9.007968 23.047528 23.047528 0 0 1-9.94737 0.154422 22.777289 22.777289 0 0 1 4.684143-8.930756 26.547767 26.547767 0 0 1 6.588685-5.649283 27.023902 27.023902 0 0 1 8.029959-3.294342 23.240556 23.240556 0 0 1 9.921633-0.064343zM346.51077 665.36708a37.666172 37.666172 0 0 1-10.719481 7.721115 53.314299 53.314299 0 0 1-11.581673 4.195139 52.001709 52.001709 0 0 1-12.199361 1.505617 37.537487 37.537487 0 0 1-13.074422-2.071832 37.524619 37.524619 0 0 1 10.719482-7.721115 51.911629 51.911629 0 0 1 11.581672-4.169402 52.760952 52.760952 0 0 1 12.21223-1.492749 37.434539 37.434539 0 0 1 13.061553 2.033227z" fill="#4B5451" p-id="2292"></path><path d="M331.248699 594.114057m-74.740392 0a74.740393 74.740393 0 1 0 149.480785 0 74.740393 74.740393 0 1 0-149.480785 0Z" fill="#E8BE48" p-id="2293"></path><path d="M708.656797 594.114057m-74.740392 0a74.740393 74.740393 0 1 0 149.480785 0 74.740393 74.740393 0 1 0-149.480785 0Z" fill="#E8BE48" p-id="2294"></path></svg>
</a>


        <!-- Page Header -->
        <header class="intro-header">
            <div class="container">
                <div class="row">
                    <div class="col-lg-8  col-md-10 ">
                        <div class="post-heading">
                            <h1>
                                1. EDA
                            </h1>
                        </div>
                    </div>
                </div>
            </div>
        </header>

        <!-- Post Content -->
        <article>
            <div class="container">
                <div class="row">
                    <!-- Post Main Content -->
                    <div class="post-content col-lg-10  col-md-10 ">
                        <span id="more"></span>
<h1 id="Exploratory-Data-Analysis"><a href="#Exploratory-Data-Analysis" class="headerlink" title="Exploratory Data Analysis"></a>Exploratory Data Analysis</h1><h2 id="1-概述-1"><a href="#1-概述-1" class="headerlink" title="1. 概述[1]"></a>1. 概述<a href="refer-anchor-1"><sup>[1]</sup></a></h2><p>数据科学家使用探索性数据分析 (Exploratory Data Analysis) 来分析和调查数据集并总结其主要特征，通常采用数据可视化方法。它有助于确定如何最好地操纵数据源以获得所需的答案，从而使数据科学家更容易发现模式、发现异常、检验假设或检查假设。</p>
<p>EDA 主要用于查看在正式建模或假设检验任务之外可以揭示哪些数据，并提供对数据集变量及其之间关系的更好理解。它还可以帮助确定您正在考虑用于数据分析的统计技术是否合适。</p>
<p>EDA 技术最初由美国数学家 John Tukey 在 1970 年代开发，在今天的数据发现过程中仍然是一种广泛使用的方法。</p>
<p>EDA 的主要目的是帮助在做出任何假设之前查看数据。它可以帮助识别明显的错误，更好地理解数据中的模式，检测异常值或异常事件，找到变量之间的有趣关系。</p>
<p>EDA 是任何数据分析中重要的第一步。了解异常值出现的位置以及变量之间的关系有助于设计能够产生有意义结果的统计分析。</p>
<p>数据科学家可以使用探索性分析来确保他们产生的结果是有效的并且适用于任何期望的业务成果和目标。EDA 还通过确认他们提出正确的问题来帮助利益相关者。EDA 可以帮助回答有关标准差、分类变量和置信区间的问题。一旦 EDA 完成并得出见解，它的功能就可以用于更复杂的数据分析或建模，包括机器学习。</p>
<h2 id="2-数据总览"><a href="#2-数据总览" class="headerlink" title="2. 数据总览"></a>2. 数据总览</h2><p>本文实例数据使用 kaggle 的 Spaceship Titanic 数据集。</p>
<p>训练数据共有如下字段</p>
<ul>
<li>PassengerId - A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always.</li>
<li>HomePlanet - The planet the passenger departed from, typically their planet of permanent residence.</li>
<li>CryoSleep - Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins.</li>
<li>Cabin - The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard.</li>
<li>Destination - The planet the passenger will be debarking to.</li>
<li>Age - The age of the passenger.</li>
<li>VIP - Whether the passenger has paid for special VIP service during the voyage.</li>
<li>RoomService, FoodCourt, ShoppingMall, Spa, VRDeck - Amount the passenger has billed at each of the Spaceship Titanic’s many luxury amenities.</li>
<li>Name - The first and last names of the passenger.</li>
<li>Transported - Whether the passenger was transported to another dimension. This is the target, the column you are trying to predict.</li>
</ul>
<p>数据都是虚拟的，主要目的是预测 Transported，是否被送到了异次元。</p>
<p>首先导入数据</p>
<pre><code class="lang-python">import pandas as pd
train_data = pd.read_csv(&#39;Data/train.csv&#39;)
test_data = pd.read_csv(&#39;Data/test.csv&#39;)
</code></pre>
<p>然后获取数据简明摘要，包括索引 dtype 、列名、非空值和内存使用情况。</p>
<pre><code class="lang-python">train_data.info()
</code></pre>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/1.png" width = 40%/></p>
<p>可以看出来大部分字段缺失几乎200条数据，同时存在字符和数字型的数据。</p>
<p>然后生成描述性统计，包括数据集分布的集中趋势、离散度和形状的统计数据，不包括 NaN 的值，即不包括缺失值。</p>
<pre><code class="lang-python">train_data.describe()
</code></pre>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/2.png" width = 70% /></p>
<p>% 指的是百分位数，50% 即为中位数。</p>
<p>由于字符型和布尔型数据还没有数字化，因此只统计了年龄和和各项消费情况，可以看出消费情况的方差非常大，可见贫富差距很明显。</p>
<p>最后查看前五条数据</p>
<pre><code class="lang-python">train_data.head()
</code></pre>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/3.png" width = 100% /></p>
<h2 id="3-数据拆分"><a href="#3-数据拆分" class="headerlink" title="3. 数据拆分"></a>3. 数据拆分</h2><p>PassengerId 和 Cabin 中包含了多个信息，PassengerId 中有 group 和个人的编号，而 Cabin 中有客舱编号与位置，因此需要进行拆分。</p>
<p>可以使用 pandas 内置函数 pandas.Series.str.split</p>
<pre><code class="lang-python">combine_data = [train_data, test_data]
for df in combine_data:
    df[[&#39;Deck&#39;, &#39;Num&#39;, &#39;Side&#39;]] = df[&#39;Cabin&#39;].str.split(&#39;/&#39;, expand = True)
    df[[&#39;PGroup&#39;,&#39;PNr&#39;]] = df[&#39;PassengerId&#39;].str.split(&#39;_&#39;, expand=True)

    df[&#39;Num&#39;] = df[&#39;Num&#39;].astype(&#39;float&#39;)
    df[&#39;PNr&#39;] = df[&#39;PNr&#39;].astype(&#39;float&#39;)
    df[&#39;PGroup&#39;] = df[&#39;PGroup&#39;].astype(&#39;float&#39;)

train_data[[&#39;Deck&#39;, &#39;Num&#39;, &#39;Side&#39;, &#39;PGroup&#39;,&#39;PNr&#39;]].head()
</code></pre>
<p>expand 选择是否将拆分的字符串展开为单独的列，如果 False 的话则返回一个字符串列表。</p>
<p>astype 指定 series 的数据类型，将 str 转换为 float。</p>
<p>拆分后的结果如下</p>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/4.png" width = 30% /></p>
<h2 id="4-数据可视化"><a href="#4-数据可视化" class="headerlink" title="4. 数据可视化"></a>4. 数据可视化</h2><p>数据分为连续数据和分类数据，无论哪种数据，都可以通过各种图形了解其自身分布情况以及与其他变量之间的相关关系等等。</p>
<p>seaborn 库是对 matplotlib 进行封装而成的，功能强大并且操作简单，完美契合 pandas 数据结构。</p>
<p>导入 seaborn 库，并且设置默认参数，这样就不用每次设置 figure 的dpi，同时设置一个好看的主题。 </p>
<pre><code class="lang-python">import seaborn as sns
plt.rcParams[&#39;figure.dpi&#39;] = 240
sns.set_theme(style=&quot;darkgrid&quot;)
</code></pre>
<h3 id="4-1-直方图"><a href="#4-1-直方图" class="headerlink" title="4.1 直方图"></a>4.1 直方图</h3><p>直方图是经典的可视化工具，它通过计算落在离散区间内的观察数来表示一个或多个变量的分布。</p>
<p>首先看一下 Age 的分布情况。</p>
<pre><code class="lang-python">plt.title(&quot;Age in counts&quot;)
sns.histplot(data=train_data, x=&quot;Age&quot;)
plt.savefig(&#39;img/5.png&#39;)
</code></pre>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/5.png" width = 60% /></p>
<p>可以看出比较符合正态分布，但是由于 bin 值设置过小，导致中间会有缺失值。通过 binwidth 设置区间的宽度，或者 bins 设置总的划分区间，我们采取第一种方式。</p>
<pre><code class="lang-python">sns.histplot(data=train_data, x=&quot;Age&quot;, binwidth=5)
</code></pre>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/6.png" width = 60% /></p>
<p>bin 值改进之后可以发现分布更趋于正态了。</p>
<blockquote>
<p>小孩异常多，本来以为是把缺失值当成 0 处理了，但实际并不是，seaborn 是把缺失值忽略了。Age 为 0 的数据本身就有 175 条，有些不合理。</p>
</blockquote>
<p>可以同时在图中加入核密度估计来平滑直方图。默认使用的是高斯核。</p>
<p>计算公式为</p>
<script type="math/tex; mode=display">{\displaystyle {\widehat {f}}_{h}(x)={\frac {1}{n}}\sum _{i=1}^{n}K_{h}(x-x_{i})={\frac {1}{nh}}\sum _{i=1}^{n}K{\Big (}{\frac {x-x_{i}}{h}}{\Big )}}</script><pre><code class="lang-python">sns.histplot(data=train_data, x=&quot;Age&quot;, binwidth=5, kde=True)
</code></pre>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/7.png" width = 60% /></p>
<p>从拟合的核密度函数来看，似乎更像是正偏态分布。</p>
<p>计算一下偏度值</p>
<pre><code class="lang-python">train_data[&quot;Age&quot;].skew()
</code></pre>
<p>结果为 0.419，确实有一定程度正偏。</p>
<p>接下来再看一下有关消费金额的直方图。</p>
<pre><code class="lang-python">sns.histplot(data=train_data, x=&quot;FoodCourt&quot;, bins=30)
</code></pre>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/8.png" width = 60% /></p>
<p>可以看出来数据偏斜非常严重，后面的数据几乎显示不出来，这时可以对数值进行取对数，将其映射到 log 空间。</p>
<pre><code class="lang-python">plt.title(&quot;FoodCourt histogram&quot;)
tmp_df = train_data[[&quot;FoodCourt&quot;]] + 1
sns.histplot(data=tmp_df, x=&quot;FoodCourt&quot;, bins=30, log_scale=True)
</code></pre>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/9.png" width = 60% /></p>
<p>由于取对数时值不能为 0，因此需要将所有值 +1。</p>
<p>从图中差不多可以看出数据的分布情况了，但还是会有偏斜，因此我们直接剔除值为0的数据，然后再看一下分布情况。</p>
<pre><code class="lang-python">sns.histplot(data=train_data[train_data[&quot;FoodCourt&quot;]!=0], x=&quot;FoodCourt&quot;, bins=30, log_scale=True)
</code></pre>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/10.png" width = 60% /></p>
<p>差不多满足正态分布了，对于这种数据严重偏斜的，后面数据预处理的时候就需要进行取对数。</p>
<p>histplot 也支持色调映射，通过颜色来反映其他数据的分布情况，例如</p>
<pre><code class="lang-python">sns.histplot(data=train_data, x=&quot;Num&quot;, hue=&#39;Transported&#39;)
</code></pre>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/11.png" width = 60% /></p>
<p>可以看出来编号的初段和中段被送往异次元的人数更多。</p>
<p>最后对所有连续数值型的特征进行直方图汇总。</p>
<pre><code class="lang-python">columns=[&#39;Age&#39;, &#39;Num&#39;, &#39;RoomService&#39;, &#39;FoodCourt&#39;, &#39;ShoppingMall&#39;, &#39;Spa&#39;, &#39;VRDeck&#39;]
row, col = divmod(len(columns), 3)
fig, ax = plt.subplots(row + 1, 3, figsize=(16,14))
for idx, column in enumerate(columns):
    row, col = divmod(idx, 3)
    if column in [&#39;Age&#39;, &#39;Num&#39;]:
        sns.histplot(data=train_data, x=column, hue=&#39;Transported&#39;, ax=ax[row, col], kde=True, bins=30)
    else:
        tmp_df = train_data[[column]] + 1
        tmp_df[&#39;Transported&#39;] = train_data[&#39;Transported&#39;]
        sns.histplot(data=tmp_df, x=column, hue=&#39;Transported&#39;, ax=ax[row, col], log_scale=True, kde=True, bins=30)
plt.savefig(&#39;img/12.png&#39;, bbox_inches=&#39;tight&#39;, pad_inches = 0.5) #调整margins
</code></pre>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/12.png" width = 100% /></p>
<h3 id="4-2-计数图"><a href="#4-2-计数图" class="headerlink" title="4.2 计数图"></a>4.2 计数图</h3><p>计数图实际上是应用于分类变量而不是连续变量的直方图，目的是对分类变量的分布情况进行可视化。</p>
<pre><code class="lang-python">plt.title(&quot;HomePlanet in counts&quot;)
sns.countplot(data=train_data, x=&quot;HomePlanet&quot;)
</code></pre>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/13.png" width = 60% /></p>
<p>类似于上面的 histplot，可以通过设置 hue 来引入第二个变量。</p>
<pre><code class="lang-python">plt.title(&quot;HomePlanet in counts&quot;)
sns.countplot(data=train_data, x=&quot;HomePlanet&quot;, hue=&quot;Transported&quot;)
</code></pre>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/14.png" width = 60% /></p>
<p>我们对所有分类变量进行计数图汇总。</p>
<pre><code class="lang-python">columns=[&#39;HomePlanet&#39;, &#39;CryoSleep&#39;, &#39;Destination&#39;, &#39;VIP&#39;, &#39;Deck&#39;, &#39;Side&#39;]
row, col = divmod(len(columns), 3)
fig, ax = plt.subplots(row, 3, figsize=(16,7))
for idx, column in enumerate(columns):
    row, col = divmod(idx, 3)
    sns.countplot(data=train_data, x=column, hue=&#39;Transported&#39;, ax=ax[row, col])
plt.savefig(&#39;img/15.png&#39;, bbox_inches=&#39;tight&#39;, pad_inches = 0.2)
</code></pre>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/15.png" width = 100% /></p>
<p>可以看出不同分类变量与预测值之间相关性最大的是 cryoSleep，睡眠的人大概率进入了异次元。</p>
<p>最后看一眼 Transported 的分布情况。</p>
<pre><code class="lang-python">plt.title(&quot;Transported in counts&quot;)
sns.countplot(data=train_data, x=&quot;Transported&quot;)
</code></pre>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/16.png" width = 60% /></p>
<h3 id="4-3-箱线图"><a href="#4-3-箱线图" class="headerlink" title="4.3 箱线图"></a>4.3 箱线图</h3><p>箱线图(Boxplot) 也称箱须图(Box-whisker Plot)，它是用一组数据中的最小值、第一四分位数、中位数、第三四分位数和最大值来反映数据分布的中心位置和散布范围，可以粗略地看出数据是否具有对称性，分布的离散程度等信息；如果将多组数据的箱线图画在同一坐标上，则可以清晰地显示出各组数据的分布差异，为发现问题、改进问题提供支持。</p>
<p>通过分位数之间的距离可以计算出数据的上下限，超出上下限的数据称为离群点，通常用叉号或别的符号标注在数轴上。</p>
<pre><code class="lang-python">plt.title(&quot;Age Box Plot&quot;)
sns.boxplot(data=train_data, x=&quot;Age&quot;)
</code></pre>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/17.png" width = 60% /></p>
<p>我们对所有连续变量进行箱线图汇总。</p>
<pre><code class="lang-python">columns=[&#39;Age&#39;, &#39;Num&#39;, &#39;RoomService&#39;, &#39;FoodCourt&#39;, &#39;ShoppingMall&#39;, &#39;Spa&#39;, &#39;VRDeck&#39;]
row, col = divmod(len(columns), 3)
fig, ax = plt.subplots(row + 1, 3, figsize=(16,7))
for idx, column in enumerate(columns):
    row, col = divmod(idx, 3)
    sns.boxplot(data=train_data, x=column, ax=ax[row, col])
plt.savefig(&#39;img/18.png&#39;, bbox_inches=&#39;tight&#39;, pad_inches = 0.2)
</code></pre>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/18.png" width = 100% /></p>
<p>可以看出来几项金额的离群点非常多，这也表示需要对数据进行处理。</p>
<h3 id="4-4-散点图"><a href="#4-4-散点图" class="headerlink" title="4.4 散点图"></a>4.4 散点图</h3><p>散点图主要用来判断两变量之间是否存在相关关系或者关联趋势，并且可以看出是线性或者非线性。对于离群值，通过散点图也可以做到一目了然。</p>
<pre><code class="lang-python">sns.scatterplot(data=train_data, x=&quot;RoomService&quot;, y=&quot;FoodCourt&quot;)
</code></pre>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/19.png" width = 60% /></p>
<p>从图中似乎没有明显的相关关系，但对于大部分人，某一项消费高的人，另外一项消费就会很少。</p>
<p>散点图通过对点的形状、大小或者点的颜色的不同，可以引入第三个分类变量。</p>
<pre><code class="lang-python">sns.scatterplot(data=train_data, x=&quot;RoomService&quot;, y=&quot;FoodCourt&quot;, hue=&quot;Transported&quot;)
</code></pre>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/20.png" width = 60% /></p>
<p>可以看出，RoomService 消费高的几乎都没有被传送。这也可以从直方图中得到印证。</p>
<p>最后，对两两变量之间绘制散点图，seaborn 中可以通过 pairplot 来实现。</p>
<pre><code class="lang-python">sns.pairplot(train_data[[&#39;Age&#39;, &#39;Num&#39;, &#39;RoomService&#39;, &#39;FoodCourt&#39;, &#39;ShoppingMall&#39;, &#39;Spa&#39;, &#39;VRDeck&#39;, &quot;Transported&quot;]], hue=&quot;Transported&quot;)
</code></pre>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/21.png" width = 100% /></p>
<h3 id="4-5-热力图"><a href="#4-5-热力图" class="headerlink" title="4.5 热力图"></a>4.5 热力图</h3><p>热力图是将矩阵数据绘制成颜色编码的矩阵，通过颜色的不同体现值的高低。</p>
<p>在 EDA 中，通常用热力图来绘制不同变量之间的相关系数。</p>
<p>相关系数是由皮尔逊提出的统计指标，反映了变量之间相关关系的密切程度。它是两个变量的协方差与其标准差的乘积之比，本质上是协方差的归一化测量。</p>
<script type="math/tex; mode=display">\begin{aligned}
    \displaystyle \rho _{X,Y}& ={\frac {\operatorname {cov} (X,Y)} {\sigma _{X}\sigma _{Y} } } \\
    &= { {\frac {\operatorname {\mathbb {E} } [\,X\,Y\,]-\operatorname {\mathbb {E} } [\,X\,]\operatorname {\mathbb {E} } [\,Y\,]}{ {\sqrt {\operatorname {\mathbb {E} } [\,X^{2}\,]-\left(\operatorname {\mathbb {E} } [\,X\,]\right)^{2} } }~{\sqrt {\operatorname {\mathbb {E} } [\,Y^{2}\,]-\left(\operatorname {\mathbb {E} } [\,Y\,]\right)^{2} } } } }.}
\end{aligned}</script><p>通过 DataFame 的 corr 方法可以很容易的计算。</p>
<pre><code class="lang-python">train_data.corr()
</code></pre>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/22.png" width = 100% /></p>
<p>将上述矩阵数据绘制成热力图，</p>
<pre><code class="lang-python">plt.figure(figsize=(15,18))
sns.heatmap(train_data.corr(), annot=True)
</code></pre>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/23.png" width = 100% /></p>
<p>可以看出 Group 序号和 Num 序号相关性是最大的。</p>
<h2 id="5-数据预处理"><a href="#5-数据预处理" class="headerlink" title="5. 数据预处理"></a>5. 数据预处理</h2><p>数据处理主要分为特征选择、缺失值处理、特征编码、归一化、降维等等</p>
<h3 id="5-1-缺失值"><a href="#5-1-缺失值" class="headerlink" title="5.1 缺失值"></a>5.1 缺失值</h3><p>首先查看一下数据缺失情况</p>
<pre><code class="lang-python">train_data.isnull().sum()
</code></pre>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/24.png" width = 20% /></p>
<p>再看一下数据的类型。</p>
<pre><code class="lang-python">train_data.info()
</code></pre>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/25.png" width = 50% /></p>
<p>object 属于分类变量，它的值都是离散的；float 则属于连续变量，它的值都是连续的。</p>
<p><strong>1. 简单策略</strong></p>
<p>对于连续值的处理，主要是使用平均值或者中位数进行填充；而对于离散值则是使用众数进行填充，也就是出现最多的类别值。</p>
<p>通过 pandas 和 sklearn 的内置方法都可以实现。</p>
<p>pandas 方法，首先通过 select_dtypes 选择指定的数据列，然后通过 fillna 进行缺失值填充。</p>
<pre><code class="lang-python">df = train_data.copy()

df_numeric = df.select_dtypes(include = np.number)
df_categorical = df.select_dtypes(include = object)

for col in df_numeric.columns:
    df[col] = df[col].fillna(value = df[col].mean())

for col in df_categorical.columns:
    df[col] = df[col].fillna(value = df[col].mode()[0])
</code></pre>
<p>sklearn 方法，sklearn 的方法相对麻烦一点，需要实例化 imputer，通过 fit 去拟合数据，然后用 transform 对数据进行缺失值填充，同时返回的是填充后的数组，最后还需要转换成 DataFrame，拼接之后就可以了。</p>
<pre><code class="lang-python">from sklearn.impute import SimpleImputer
start = time.time()

df_numeric = df.select_dtypes(include = np.number)
df_categorical = df.select_dtypes(include = object)

imputer = SimpleImputer(missing_values=np.nan, strategy=&#39;mean&#39;)
imputer.fit(df_numeric)
values = imputer.transform(df_numeric)
df_numeric = pd.DataFrame(values, columns = df_numeric.columns)

imputer = SimpleImputer(missing_values=np.nan, strategy=&#39;most_frequent&#39;)
imputer.fit(df_categorical)
values = imputer.transform(df_categorical)
df_categorical = pd.DataFrame(values, columns = df_categorical.columns)

df_sklearn = pd.concat([df_numeric, df_categorical], axis = 1)
</code></pre>
<p>最后看一下数据，可以看出来结果是一样的。</p>
<pre><code class="lang-python">train_data[train_data.isnull().T.any()].select_dtypes(include = np.number).head(10)
df[train_data.isnull().T.any()].select_dtypes(include = np.number).head(10)
df_numeric[train_data.isnull().T.any()].head(10)
</code></pre>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/26.png" width = 60% /></p>
<center>缺失值</center>
<img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/27.png" width = 60% />
<center>pandas 缺失值估计</center>
<img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/28.png" width = 60% />
<center>sklearn 缺失值估计</center>

<p><strong>2. KNN 策略<a href="refer-anchor-1"><sup>[2]</sup></a></strong></p>
<p>用简单策略的单变量方法可能无法准确的填补缺失值，例如某段道路的空气污染情况缺失，但是已知其车辆密度和或其他与空气质量相关的特征，利用空气污染情况的平均值或者中无数去填补就不是一个好的策略。更好的方法是，通过其他特征去找一个最相似的也就是最近邻的一个或多个样本，利用该样本的平均值去填补缺失的情况。</p>
<p>具体方法是，每个样本的缺失值使用来自训练集中找到的 n_neighbors 个最近邻的平均值进行估算。如果两个样本<strong>都没有缺失的</strong>特征是接近的，那么两个样本是接近的。</p>
<script type="math/tex; mode=display">L_p(\mathbf{x}_i,\mathbf{x}_j)=\left(\sum_{l=1}^{n} |x_i^{(l)} - x_j^{(l)}|^2 \right)^{\frac{1}{2}} \text{if } x_i^{(l)}\text{ and } x_j^{(l)} \text{ not null}</script><p>KNN 插补只能用在数值型变量中，如果是分类变量则需要 one-hot 后才能使用。</p>
<pre><code class="lang-python">from sklearn.impute import KNNImputer

x = [[1, np.nan, 5], [1, 0, 0], [3, 3, 3]]

imputer = KNNImputer(n_neighbors = 1)
print(imputer.fit_transform(x))

imputer = KNNImputer(n_neighbors = 2)
print(imputer.fit_transform(x))

y = [[1, np.nan, 5], [1, 0, np.nan], [3, 3, 3]]

imputer = KNNImputer(n_neighbors = 1)
print(imputer.fit_transform(y))
</code></pre>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/29.png" width = 20% /></p>
<p>数据集 x 有三个样本，距离第一个样本最近的是样本3，因此填充值是3。当 n_neighbors = 2 时，填充值则是另外两个样本该特征的平均值。</p>
<p>最后观察一下用 KNN 插补后的结果</p>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/30.png" width = 60% /></p>
<center>KNNImputer 缺失值估计</center>

<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/28.png" width = 60% /></p>
<center>SimpleImputer 缺失值估计</center>

<p>可以看出来比平均值填补要合理的多，毕竟，年龄是1岁的人，情理上讲是不会有消费的。</p>
<h3 id="5-2-特征编码"><a href="#5-2-特征编码" class="headerlink" title="5.2 特征编码"></a>5.2 特征编码</h3><p>编码过程主要是将离散的数值或字符串映射到连续的整数空间。</p>
<p>在分类问题中，首先要对标签值进行编码。</p>
<p>通过 pandas 进行编码，需要用 unique 得到分类值，然后用 map 进行映射。</p>
<pre><code class="lang-python">df = train_data.copy()
labels = df[&#39;Transported&#39;].unique()
print(&#39;labels:  &#39;, labels)
print(&#39;labels map:  &#39;, dict(zip(labels, range(len(labels)))))
df[&#39;Transported&#39;] = df[&#39;Transported&#39;].map(dict(zip(labels, range(len(labels)))))
df[[&#39;PassengerId&#39;, &#39;Transported&#39;]].head()
</code></pre>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/31.png" width = 30% /></p>
<p>sklearn 中的 LabelEncoder 同样可以实现上述操作。</p>
<pre><code class="lang-python">from sklearn.preprocessing import LabelEncoder

df = train_data.copy()
le = LabelEncoder()
df[&#39;Transported&#39;] = le.fit_transform(df[&#39;Transported&#39;])
print(le.classes_)
df[[&#39;PassengerId&#39;, &#39;Transported&#39;]].head()
</code></pre>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/32.png" width = 20% /></p>
<p>在对特征值进行编码的时候，不仅仅要映射到整数空间，还需要进行 ont hot 编码。</p>
<p>pandas 中可以使用 get_dummies 方法。</p>
<pre><code class="lang-python">df = train_data.copy()
df = pd.get_dummies(df, columns=[&#39;HomePlanet&#39;, &#39;CryoSleep&#39;, &#39;Destination&#39;, &#39;VIP&#39;, &#39;Deck&#39;, &#39;Side&#39;])
</code></pre>
<p>部分变量转换结果如下。</p>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/33.png" width = 80% /></p>
<p>sklearn 中需要使用 OneHotEncoder，返回的是一个数组，需要另外取出列名后再生成 DataFrame。</p>
<pre><code class="lang-python">from sklearn.preprocessing import OneHotEncoder

df = train_data[[&#39;HomePlanet&#39;, &#39;CryoSleep&#39;, &#39;Destination&#39;, &#39;VIP&#39;, &#39;Deck&#39;, &#39;Side&#39;]].copy()
encoder = OneHotEncoder(handle_unknown=&#39;ignore&#39;)
encoder.fit(df)
print(encoder.categories_)
values = encoder.transform(df).toarray()
print(encoder.get_feature_names_out())
pd.DataFrame(values, columns = encoder.get_feature_names_out())
</code></pre>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/34.png" width = 80% /></p>
<p>可以看出 OneHotEncoder 默认对 NaN 值也进行编码的，会单独生成一列，而 get_dummies 默认则不会，可以通过传参使它们的结果相同。</p>
<p>one hot 编码也可以少输出一列，例如一个变量有三个类别，可以使用两个变量去表示，当属于第三个类别时，这两个变量的值都为0，在以上两个接口中都有相应参数进行设置。</p>
<h3 id="5-3-标准化和归一化"><a href="#5-3-标准化和归一化" class="headerlink" title="5.3 标准化和归一化"></a>5.3 标准化和归一化</h3><p>在标准化之前，在以上操作的基础上，先把不需要的列去掉。</p>
<pre><code class="lang-python">df.drop([&#39;PassengerId&#39;, &#39;Cabin&#39;, &#39;Name&#39;], axis = 1, inplace = True)
</code></pre>
<p><strong>1. 正态化</strong></p>
<p>如前所述，对于金额类的类别由于方差过大、异常值过多，需要进行对数处理。</p>
<p>对于哪些类别需要进行对数处理，一是通过之前的箱线图看哪些异常值过多然后进行处理，二是分别计算每个类别的偏度，超过阈值则进行处理。</p>
<p>事实上，右偏的数据可以进行取对数、平方根、三次方根等等方式进行正态化处理，这些函数随着自变量的增大逐渐变缓，左偏的则需要进行指数计算。</p>
<p>偏度<a href="refer-anchor-1"><sup>[3]</sup></a>的计算公式为</p>
<script type="math/tex; mode=display">S_k=\left[\frac{n}{(n-1)(n-2)} \right] \times \frac{\displaystyle \sum_{i=1}^n(x_i-\overline{x})^3}{\sigma^3}</script><p>首先查看一下各列的偏度值</p>
<pre><code class="lang-python">df.skew()
</code></pre>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/35.png" width = 30% /></p>
<p>只对数值型的变量进行处理，通过 numpy 的 log1p 方法进行取对数，log1p 自动将输入加 1 后取对数，避免了 0 值报错的情况。</p>
<pre><code class="lang-python">for column in [&#39;Age&#39;, &#39;RoomService&#39;, &#39;FoodCourt&#39;, &#39;ShoppingMall&#39;, &#39;Spa&#39;, &#39;VRDeck&#39;, &#39;Num&#39;, &#39;PGroup&#39;, &#39;PNr&#39;]:
    skew = df[column].skew()
    if skew &gt;= 0.5:
      df[column] = np.log1p(df[column])
</code></pre>
<p>在 sklearn 中有更专业的方法对数据进行正态化处理，分别为 Box-Cox<a href="refer-anchor-1"><sup>[4]</sup></a> 和 Yeo–Johnson 变换。</p>
<p>Box-Cox 变换形式如下</p>
<script type="math/tex; mode=display">{\displaystyle y_{i}^{(\lambda )}={\begin{cases}{\dfrac {y_{i}^{\lambda }-1}{\lambda }}&{\text{if }}\lambda \neq 0,\\\ln y_{i}&{\text{if }}\lambda =0,\end{cases}}}</script><p>式中，$\lambda$ 的值不用直接给出，是通过最大似然估计，判定不同的 $\lambda$ 的值的情况下，哪一个得到的结果更符合正态分布。从公式中可以看出，Box-Cox 要求 $y$ 的值严格为正。</p>
<p>Yeo–Johnson 变换则为</p>
<script type="math/tex; mode=display">{\displaystyle y_{i}^{(\lambda )}={\begin{cases}((y_{i}+1)^{\lambda }-1)/\lambda &{\text{if }}\lambda \neq 0,y\geq 0\\[4pt]\log(y_{i}+1)&{\text{if }}\lambda =0,y\geq 0\\[4pt]-((-y_{i}+1)^{(2-\lambda )}-1)/(2-\lambda )&{\text{if }}\lambda \neq 2,y<0\\[4pt]-\log(-y_{i}+1)&{\text{if }}\lambda =2,y<0\end{cases}}}</script><p>Yeo–Johnson 变换支持 $y$ 为 0 或负，解决方法也正是取值加 1。</p>
<p>在 sklearn 中，以上两种变换都通过 PowerTransformer<a href="refer-anchor-1"><sup>[5]</sup></a> 实现。变换后默认标准化数据，可以通过 standardize = False 关闭。</p>
<pre><code class="lang-python">df_tmp = df[[&#39;Age&#39;, &#39;RoomService&#39;, &#39;FoodCourt&#39;, &#39;ShoppingMall&#39;, &#39;Spa&#39;, &#39;VRDeck&#39;, &#39;Num&#39;, &#39;PGroup&#39;, &#39;PNr&#39;]].copy()
pt = PowerTransformer(&#39;yeo-johnson&#39;, standardize = False)
pt.fit(df_tmp)
values = pt.transform(df_tmp)
df_lambdas = pd.Series(pt.lambdas_, index = df_tmp.columns)
df_power = pd.DataFrame(values, columns = df_tmp.columns).head()
</code></pre>
<p>lambdas_ 属性显示最优的 lambdas 值，变换的结果也是根据这个值。看一下每列的 lambdas 值为</p>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/36.png" width = 30% /></p>
<p>转换后的结果为，这里没有进行标准化。</p>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/37.png" width = 70% /></p>
<p>最后再画图看一下变换前和变换后的数据分布</p>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/38.png" width = 100% /></p>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/39.png" width = 100% /></p>
<p>感觉变换后也不是特别正态分布。</p>
<p>再看一下变换前后的箱线图</p>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/40.png" width = 100% /></p>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/41.png" width = 100% /></p>
<p>可以发现异常值减少了许多。</p>
<p><strong>2. 标准化</strong></p>
<p>上面的正态化属于非线性变换，而标准化和归一化就属于线性变换了，只是统一量纲不会改变数据的分布类型。</p>
<p>标准化<a href="refer-anchor-1"><sup>[6]</sup></a>通过均值去除和方差缩放来对样本进行统一标准。</p>
<script type="math/tex; mode=display">s=\frac{X_i-\mu}{\sigma}</script><p>pandas 中有广播机制，因此利用下式即可计算出结果。</p>
<pre><code class="lang-python">(df_tmp - df_tmp.mean()) / df_tmp.std()
</code></pre>
<p>计算结果为</p>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/42.png" width = 70% /></p>
<p>sklearn 方法</p>
<pre><code class="lang-python">(df_tmp - df_tmp.mean()) / df_tmp.std()
</code></pre>
<p>计算结果为</p>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/43.png" width = 70% /></p>
<p>结果有一点不同，可能是 pandas 使用的是样本方差，方差结果乘以了 $\frac{n}{n - 1}$</p>
<p>我们调整一下自由度的值</p>
<pre><code class="lang-python">(df_tmp - df_tmp.mean()) / df_tmp.std(ddof = 0)
</code></pre>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/44.png" width = 70% /></p>
<p>果然结果一样了。</p>
<p><strong>3. 归一化</strong></p>
<p>归一化是将数据线性映射到 $[0,1]$ 区间，使用的是数据中最大与最小值。</p>
<script type="math/tex; mode=display">s=\frac{X_i-X_{min}}{X_{max}-X_{min}}</script><p>pandas 方法</p>
<pre><code class="lang-python">(df_tmp - df_tmp.min()) / (df_tmp.max() - df_tmp.min())
</code></pre>
<p>计算结果为</p>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/45.png" width = 70% /></p>
<p>sklearn 方法</p>
<pre><code class="lang-python">from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
scaler.fit(df_tmp)
print(scaler.data_min_)
print(scaler.data_max_)
values = scaler.transform(df_tmp)
df_scaler = pd.DataFrame(values, columns = df_tmp.columns)
df_scaler.head()
</code></pre>
<p>计算结果为</p>
<p><img src="https://raw.githubusercontent.com/He1o/Cyrus_NoteBook/main/Kaggle/img/46.png" width = 70% /></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><blockquote>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/bashendixie5/article/details/123036834">1. 机器学习笔记 - 探索性数据分析(EDA) 概念理解 - csdn</a><br><a target="_blank" rel="noopener" href="https://www.analyticsvidhya.com/blog/2020/07/knnimputer-a-robust-way-to-impute-missing-values-using-scikit-learn/">2. KNNImputer: A robust way to impute missing values (using Scikit-Learn)</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/346810231">3. Python统计学（五）——切比雪夫、偏度及峰度 - zhihu</a><br><a target="_blank" rel="noopener" href="https://baike.baidu.com/item/box-cox%E5%8F%98%E6%8D%A2/10278422">4. box-cox变换</a><br><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Power_transform">5. Power transform - wiki</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_36604953/article/details/102652160">6. 标准化和归一化 - csdn</a><br><a target="_blank" rel="noopener" href="http://www.360doc.com/content/16/0422/07/3448857_552751124.shtml">7. 样本分布不正态？</a><br><a target="_blank" rel="noopener" href="https://www.analyticsvidhya.com/blog/2016/01/guide-data-exploration/">8. A Comprehensive Guide to Data Exploration</a></p>
<div id="refer-anchor-1"></div></blockquote>


                            <!-- Meta -->
                            <div class="post-meta">
                                <hr>
                                <br>
                                <div class="post-tags">
                                    
                                                

<a href="/categories/Feature-Engineering/">Feature Engineering</a>

                                                    
                                </div>
                                <div class="post-date">
                                    
                                        2022-08-12
                                    
                                </div>
                            </div>
                    </div>

                    <!-- Comments -->
                    <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                        <!-- Disqus Comments -->


                    </div>
                </div>
            </div>
        </article>
</section>

<!-- Image viewer-->

    <!-- Custom picture view-->
    <link href="/css/viewer.min.css" rel="stylesheet" />
    <script
      src="/js/viewer.min.js"
      type="text/javascript"
      charset="utf-8"
    ></script>
    
    <script type="text/javascript">
      // set image viewer
      Viewer.setDefaults({
        zoomRatio: [0.5],
        navbar: false,
        toolbar: false,
        button: false,
        title: [2, (image, imageData) => `${image.alt}`],
        show: function() {
          this.viewer.zoomTo(0.5);
        }
      });
      var imageList = document.getElementsByTagName("img");
      Array.prototype.forEach.call(imageList, element => {
        var viewer = new Viewer(element);
      });
    </script>

    

<!-- TOC -->

    <aside id="article-toc" role="navigation" class="fixed">
        <div id="article-toc-inner">
            <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Exploratory-Data-Analysis"><span class="toc-text">Exploratory Data Analysis</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E6%A6%82%E8%BF%B0-1"><span class="toc-text">1. 概述[1]</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E6%95%B0%E6%8D%AE%E6%80%BB%E8%A7%88"><span class="toc-text">2. 数据总览</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E6%95%B0%E6%8D%AE%E6%8B%86%E5%88%86"><span class="toc-text">3. 数据拆分</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="toc-text">4. 数据可视化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-%E7%9B%B4%E6%96%B9%E5%9B%BE"><span class="toc-text">4.1 直方图</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-%E8%AE%A1%E6%95%B0%E5%9B%BE"><span class="toc-text">4.2 计数图</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-%E7%AE%B1%E7%BA%BF%E5%9B%BE"><span class="toc-text">4.3 箱线图</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-%E6%95%A3%E7%82%B9%E5%9B%BE"><span class="toc-text">4.4 散点图</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-5-%E7%83%AD%E5%8A%9B%E5%9B%BE"><span class="toc-text">4.5 热力图</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-text">5. 数据预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-%E7%BC%BA%E5%A4%B1%E5%80%BC"><span class="toc-text">5.1 缺失值</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-%E7%89%B9%E5%BE%81%E7%BC%96%E7%A0%81"><span class="toc-text">5.2 特征编码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-%E6%A0%87%E5%87%86%E5%8C%96%E5%92%8C%E5%BD%92%E4%B8%80%E5%8C%96"><span class="toc-text">5.3 标准化和归一化</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83"><span class="toc-text">参考</span></a></li></ol></li></ol>
        </div>
    </aside>

    <!-- Scripts -->
    <script type="text/javascript">
    console.log("© He1o 2021-" + new Date().getFullYear());
</script>
  
    <!-- Google Analytics -->
    

    <!-- Service Worker -->
    <!-- if using service worker -->

    
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</body>

</html>